{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"refactor_20200823_dfc_vae_on_celeba_main.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"N95qVLzXOCDt","colab_type":"code","colab":{}},"source":["\n","#-------------------------------- CONFIGURING SCRIPT --------------------------------#\n","DRIVE_DIR = \"/content/drive/My Drive/VaeOnCelebA/\"\n","DIR_TO_CELEBA_ZIP_FILE = \"/content/drive/My Drive/VaeOnCelebA/celeba.zip\" #DIR TO THE ZIPFILE WITH DATA\n","DIR_FOR_UNPACKING_CELEBA_ZIP_FILE = \"data_faces\" #DIR TO WHICH THE DATA ZIPFILE SHOULD BE EXTRACTED\n","#For transforming data point paths to image data\n","IS_CROP = True #TRUE FOR TRAINING, FALSE FOR TESTING\n","IMAGE_SIZE = 148 #SIZE OF IMAGE TO USE (WILL BE CENTER CROPPED)\n","\n","# For configuring tf graph\n","OUTPUT_SIZE = 64 #SIZE OF GENERATOR OUTPUT IMAGES\n","C_DIM = 3 #DIMENSION OF IMAGE COLOR\n","BATCH_SIZE = 64 #NUMBER OF BATCH IMAGES\n","Z_DIM = 100 #DIMENSION OF LATENT SPACE\n","BETA1 = 0.5 #MOMENTUM TERM OF ADAM\n","\n","START_TF_SESSION = True\n","LOAD_VGG_WEIGHTS = True\n","LOAD_VGG_WEIGHTS_DIR = '/content/drive/My Drive/VaeOnCelebA/vgg16_weights.npz' #DIRECTORY TO LOAD VGG WEIGHTS FROM\n","\n","LOAD_PRETRAIN = True #SET TO TRUE IF STARTING FROM PRETRAINED NET\n","LOAD_PRETRAIN_DIR = '/content/drive/My Drive/VaeOnCelebA/dfc_training_params/training_20200831' #DIRECTORY TO LOAD PARAMETERS FROM IN CASE LOAD_PRETRAIN=True\n","LOAD_PRETRAIN_ENCODER1_PARAMS_NAME = '/net_e1.npz' #NAME OF THE FILE WITH PARAMETERS TO LOAD FOR ENCODER NET 1\n","LOAD_PRETRAIN_ENCODER2_PARAMS_NAME = '/net_e2.npz' #NAME OF THE FILE WITH PARAMETERS TO LOAD FOR ENCODER NET 2\n","LOAD_PRETRAIN_DECODER_PARAMS_NAME = '/net_g.npz' #NAME OF THE FILE WITH PARAMETERS TO LOAD FOR CODER\n","\n","TRAIN_MAIN_VAE = False #TRUE IF TRAINING ON MAIN VAE SHOULD BE PERFORMED, FALSE OTHERWISE\n","EPOCHS = 50 #EPOCHS TO TRAIN\n","NO_TRAIN_STEPS = None #IF INT, MAIN VAE IS TRAINED NO_TRAIN_STEPS NO OF STEPS, OTHERWISE, IT IS TRAINED NO OF EPOCHS SPECIFIED\n","LEARNING_RATE = 0.0005 #LEARNING RATE FOR ADAM\n","CHECKPOINT_STEP = 600 #TRAINING STEP INTERVAL FOR GENERATING SAMPLE AND CORRESPONDING PARAMETERS DURING TRAINING\n","TRAINING_PARAMETERS_DIR = \"/content/drive/My Drive/VaeOnCelebA/dfc_training_params/training_20200831\" #DIRECTORY NAME TO SAVE THE CHECKPOINTS TO DURING TRAINING\n","TRAINING_SAMPLES_DIR = \"/content/drive/My Drive/VaeOnCelebA/dfc_training_samples/training_20200831\" #DIRECTORY NAME TO SAVE IMAGE SAMPLES TO DURING TRAINING \n","\n","SAMPLE_IMAGES = False #TRUE IF SAMPLING FROM MAIN VAE SHOULD BE PERFORMED (RECONSTRUCTION AND RANDOM)\n","NO_SAMPLE_PICTURES = 100 #NO OF SAMPLES TO BE GENERATED\n","DIR_FOR_SAMPLING = '/content/drive/My Drive/VaeOnCelebA/dfc_samples/trained_20200824' #DIR FOR SAMPLING WITH PARAMETERS LOADED\n","\n","CREATE_NEW_TEST_FUNCTION = False #SET TO TRUE IF NEW TEST FUNCTION SHOULD BE CREATED. DEFINE BELOW HOW THIS SHOULD LOOK LIKE\n","CREATE_NEW_TEST_FUNCTION_LATENT_DIM = 100 #LATENT DIMENSION OF TEST FUNCTION CREATED\n","CREATE_NEW_TEST_FUNCTION_SAVE_DIR = '/content/drive/My Drive/VaeOnCelebA/dfc_test_functions/larger_net_20200901' #DIR TO WHICH THE CHOSEN TESTFUNCTION IS SAVED DURING TRAINING\n","LOAD_OLD_TEST_FUNCTION = True #TRUE IF TEST FUNCTION SHOULD BE LOADED\n","LOAD_OLD_TEST_FUNCTION_DIR = '/content/drive/My Drive/VaeOnCelebA/dfc_test_functions/larger_net_20200901' #DIR FROM WHICH TEST FUNCTION IS LOADED\n","\n","CREATE_LATENT_DATA = False #TRUE IF LATENT DATA SHOULD BE CREATED. LATENT DATA IS NEEDED FOR TRAINING OF TEST FUNCTION\n","CREATE_LATENT_DATA_SAVE_DIR = '/content/drive/My Drive/VaeOnCelebA/dfc_real_data_representations/latent_representations/test_func_train_20200824.npy' #DIR TO WHICH LATENT REPRESENTATIONS ARE SAVED\n","LOAD_OLD_LATENT_DATA = False #TRUE IF LATENT DATA SHOULD BE LOADED. LATENT DATA IS NEEDED FOR TRAINING OF TEST FUNCTION\n","LOAD_OLD_LATENT_DATA_DIR = '/content/drive/My Drive/VaeOnCelebA/dfc_real_data_representations/latent_representations/test_func_train_20200824.npy' #DIR FROM WHICH LATENT DATA IS LOADED\n","\n","TRAIN_TEST_FUNCTION = False #TRUE IF TEST FUNCTION TRAINING SHOULD BE PERFORMED\n","TRAIN_TEST_FUNCTION_EPOCHS = 5000 #NO OF EPOCHS TEST FUNCTION SHOULD BE TRAINED\n","TRAIN_TEST_FUNCTION_BATCH_SIZE = 50000 #BATCH SIZE WHEN TRAINING TEST FUNCTION\n","\n","CHECK_SOME_TEST_F_VALUES = False #IF TRUE, ONE BATCH IS ENCODED AND RECONSTRUCTED, WITH TEST FUNCTION VALUES BEING CALCULATED OVER LATENT REPRESENTATIONS, SAMS IS DONE FOR RANDOM \n","CHECK_SOME_TEST_F_VALUES_RECON_IMG = '/content/drive/My Drive/VaeOnCelebA/recon_tester.jpg'\n","CHECK_SOME_TEST_F_VALUES_RECON_ALPHAS = '/content/drive/My Drive/VaeOnCelebA/recon_tester_alphas.txt'\n","CHECK_SOME_TEST_F_VALUES_RANDOM_IMG = '/content/drive/My Drive/VaeOnCelebA/random_tester.jpg'\n","CHECK_SOME_TEST_F_VALUES_RANDOM_ALPHAS = '/content/drive/My Drive/VaeOnCelebA/random_tester_alphas.txt'\n","\n","SAMPLE_TEST_FUNCTION = False #TRUE IF SAMPLES SHOULD BE GENERATED FROM TEST FUNCTION\n","SAMPLE_TEST_FUNCTION_ALPHA = 0.999 #THRESHOLD FOR SAMPLING GOOD SAMPLES FROM TEST FUNCTION\n","SAMPLE_TEST_FUNCTION_BETA = 0.05 #THRESHOLD FOR SAMPLING BAD SAMPLES FROM TEST FUNCTION\n","SAMPLE_TEST_FUNCTION_GOOD_IMAGES = '/content/drive/My Drive/VaeOnCelebA/good_images.png'\n","SAMPLE_TEST_FUNCTION_BAD_IMAGES = '/content/drive/My Drive/VaeOnCelebA/bad_images.png'\n","SAMPLE_TEST_FUNCTION_GOOD_IMAGES_ALPHAS = '/content/drive/My Drive/VaeOnCelebA/good_images_alphas.txt'\n","SAMPLE_TEST_FUNCTION_BAD_IMAGES_ALPHAS = '/content/drive/My Drive/VaeOnCelebA/bad_images_alphas.txt'\n","\n","INTERPOLATION_START_PIC_IDX = 1 #IF DOING INTERPOLATION, CODE WILL CHOOSE BATCH_SIZE NUMBER OF PICS IN DATASET, STARTING FROM THIS INDEX, AS INTERPOLATION STARTING POINTS\n","INTERPOLATION_END_PIC_IDX = 100 #IF DOING INTERPOLATION, CODE WILL CHOOSE BATCH_SIZE NUMBER OF PICS IN DATASET, STARTING FROM THIS INDEX, AS INTERPOLATION ENDING POINTS\n","SAMPLE_LABEL = 'c'\n","\n","PERFORM_NORMAL_INTERPOLATION = False #TRUE IF GAUSSIAN PROCESS INTERPOLATION SHOULD BE PERFORMED\n","TIME = 1 #TIME PARAMETER OF GAUSSIAN PROCESS INTERPOLATION\n","PERFORM_NORMAL_INTERPOLATION_SAMPLES_PATH = '/content/drive/My Drive/VaeOnCelebA/dfc_interpolation_gaussian/gaussian_interpolation_{}{}.png'\n","PERFORM_NORMAL_INTERPOLATION_SAVE_MIDDLE = False\n","PERFORM_NORMAL_INTERPOLATION_SAVE_MIDDLE_ITERS = 1\n","PERFORM_NORMAL_INTERPOLATION_SAVE_MIDDLE_PATH = '/content/drive/My Drive/VaeOnCelebA/dfc_interpolation_gaussian_middle_images/'\n","\n","PERFORM_LINEAR_INTERPOLATION = False #TRUE IF LINEAR INTERPOLATION SHOULD BE PERFORMED\n","PERFORM_LINEAR_INTERPOLATION_SAMPLES_PATH = '/content/drive/My Drive/VaeOnCelebA/dfc_interpolation_linear/linear_interpolation_{}{}.png'\n","PERFORM_LINEAR_INTERPOLATION_SAVE_MIDDLE = False\n","PERFORM_LINEAR_INTERPOLATION_SAVE_MIDDLE_ITERS = 1\n","PERFORM_LINEAR_INTERPOLATION_SAVE_MIDDLE_PATH = '/content/drive/My Drive/VaeOnCelebA/dfc_interpolation_linear_middle_images/'\n","\n","PERFORM_PARTICLE_FILTER_INTERPOLATION = False #TRUE IF LINEAR INTERPOLATION SHOULD BE PERFORMED\n","PERFORM_PARTICLE_FILTER_INTERPOLATION_SAMPLES_PATH = '/content/drive/My Drive/VaeOnCelebA/dfc_interpolation_particle_filter/particle_interpolation_{}{}.png'\n","PERFORM_PARTICLE_FILTER_INTERPOLATION_ALPHA = 300\n","PERFORM_PARTICLE_FILTER_INTERPOLATION_SAVE_MIDDLE = False\n","PERFORM_PARTICLE_FILTER_INTERPOLATION_SAVE_MIDDLE_ITERS = 2\n","PERFORM_PARTICLE_FILTER_INTERPOLATION_SAVE_MIDDLE_PATH = '/content/drive/My Drive/VaeOnCelebA/dfc_interpolation_particle_filter_middle_images/'\n","\n","GET_SAMPLE_OF_VGG_REPS_ORIGINAL_DATA = False #TRUE IF SAMPLE OF VGG LAST MAXPOOL LAYER FROM ORIGINAL DATA SHOULD BE COLLECTED\n","GET_SAMPLE_OF_VGG_REPS_ORIGINAL_DATA_SAVE_PATH = '/content/drive/My Drive/VaeOnCelebA/dfc_real_data_representations/vgg_representations/'\n","GET_SAMPLE_OF_VGG_REPS_ORIGINAL_DATA_ITER = 156\n","\n","CALCULATE_WASSERSTEIN_DISTANCE = False #TRUE IF WASSERSTEIN DIFFERENCE SHOULD BE CALCULATED FROM VGG WEIGHTS IN PROVIDED DIRECTORIES\n","WASSERSTEIN_FAKE_DIRECTORIES = [\n","  '/content/drive/My Drive/VaeOnCelebA/dfc_interpolation_particle_filter_middle_images/vgg_representations/',\n","  '/content/drive/My Drive/VaeOnCelebA/dfc_interpolation_linear_middle_images/vgg_representations/',\n","  '/content/drive/My Drive/VaeOnCelebA/dfc_interpolation_gaussian_middle_images/vgg_representations/',\n","]\n","WASSERSTEIN_REAL_DIRECTORY = '/content/drive/My Drive/VaeOnCelebA/dfc_real_data_representations/vgg_representations/'\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gevEQRtSOD3l","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":340},"executionInfo":{"status":"ok","timestamp":1600879556318,"user_tz":-120,"elapsed":66746,"user":{"displayName":"WASP Drive","photoUrl":"","userId":"11895298268124410342"}},"outputId":"d7d108e0-5d81-4f75-9d45-940ff64fde03"},"source":["!pip3 install tensorlayer==1.7.1\n","!pip install scipy==1.1.0\n","!mkdir DIR_FOR_UNPACKING_CELEBA_ZIP_FILE\n","from google.colab import drive\n","drive.mount('/content/drive')\n","import zipfile\n","with zipfile.ZipFile(DIR_TO_CELEBA_ZIP_FILE, \"r\") as zip_ref:\n","  zip_ref.extractall(DIR_FOR_UNPACKING_CELEBA_ZIP_FILE + \"/\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: tensorlayer==1.7.1 in /usr/local/lib/python3.6/dist-packages (1.7.1)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from tensorlayer==1.7.1) (3.2.2)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from tensorlayer==1.7.1) (1.1.0)\n","Requirement already satisfied: scikit-image in /usr/local/lib/python3.6/dist-packages (from tensorlayer==1.7.1) (0.16.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from tensorlayer==1.7.1) (1.18.5)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->tensorlayer==1.7.1) (2.8.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->tensorlayer==1.7.1) (0.10.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->tensorlayer==1.7.1) (1.2.0)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->tensorlayer==1.7.1) (2.4.7)\n","Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->tensorlayer==1.7.1) (2.4.1)\n","Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->tensorlayer==1.7.1) (2.5)\n","Requirement already satisfied: pillow>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->tensorlayer==1.7.1) (7.0.0)\n","Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->tensorlayer==1.7.1) (1.1.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.1->matplotlib->tensorlayer==1.7.1) (1.15.0)\n","Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=2.0->scikit-image->tensorlayer==1.7.1) (4.4.2)\n","Requirement already satisfied: scipy==1.1.0 in /usr/local/lib/python3.6/dist-packages (1.1.0)\n","Requirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python3.6/dist-packages (from scipy==1.1.0) (1.18.5)\n","mkdir: cannot create directory ‘DIR_FOR_UNPACKING_CELEBA_ZIP_FILE’: File exists\n","Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"19Hgmo9ipxc-","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":122},"executionInfo":{"status":"ok","timestamp":1600879559216,"user_tz":-120,"elapsed":69637,"user":{"displayName":"WASP Drive","photoUrl":"","userId":"11895298268124410342"}},"outputId":"9add439b-09c2-4283-960f-94be6a35c67e"},"source":["import os\n","import scipy.misc\n","import pprint\n","import numpy as np\n","import time\n","import sys\n","sys.path.append('/content/drive/My Drive/VaeOnCelebA/')\n","import math\n","%tensorflow_version 1.x\n","import tensorflow as tf\n","import tensorlayer as tl\n","from tensorlayer.layers import *\n","from glob import glob\n","from random import shuffle\n","from google.colab import files\n","from utils import *\n","from vgg_loss import *"],"execution_count":null,"outputs":[{"output_type":"stream","text":["TensorFlow 1.x selected.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorlayer/layers.py:28: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorlayer/layers.py:4056: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"QlAVEsTiVhu6","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1600879559217,"user_tz":-120,"elapsed":69631,"user":{"displayName":"WASP Drive","photoUrl":"","userId":"11895298268124410342"}},"outputId":"013c8579-b5dd-45ce-86a8-8676b9ef5e55"},"source":["device_name = tf.test.gpu_device_name()\n","print(device_name)\n","os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n","os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""],"execution_count":null,"outputs":[{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"i_rEoMYqyQsq","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1600879561952,"user_tz":-120,"elapsed":72357,"user":{"displayName":"WASP Drive","photoUrl":"","userId":"11895298268124410342"}},"outputId":"c9bd68d4-6238-486a-b84c-6422ff126953"},"source":["\n","def encoder(input_imgs, is_train = True, reuse = False):\n","    '''\n","    input_imgs: the input images to be encoded into a vector as latent representation. size here is [b_size,64,64,3]\n","    '''\n","    z_dim = Z_DIM\n","    ef_dim = 32 # encoder filter number\n","\n","    w_init = tf.random_normal_initializer(stddev=0.02)\n","    gamma_init = tf.random_normal_initializer(1., 0.02)\n","\n","    with tf.variable_scope(\"encoder\", reuse = reuse):\n","        tl.layers.set_name_reuse(reuse)\n","\n","        net_in = InputLayer(input_imgs, name='en/in') # (b_size,64,64,3)\n","        net_h0 = Conv2d(net_in, ef_dim, (4, 4), (2, 2), act=None, padding='SAME', W_init=w_init, name='en/h0/conv2d')\n","        net_h0 = BatchNormLayer(net_h0, act=lambda x: tl.act.lrelu(x, 0.2), is_train=is_train, gamma_init=gamma_init, name='en/h0/batch_norm')\n","\n","        net_h1 = Conv2d(net_h0, ef_dim*2, (4, 4), (2, 2), act=None, padding='SAME', W_init=w_init, name='en/h1/conv2d')\n","        net_h1 = BatchNormLayer(net_h1, act=lambda x: tl.act.lrelu(x, 0.2), is_train=is_train, gamma_init=gamma_init, name='en/h1/batch_norm')\n","\n","        net_h2 = Conv2d(net_h1, ef_dim*4, (4, 4), (2, 2), act=None, padding='SAME', W_init=w_init, name='en/h2/conv2d')\n","        net_h2 = BatchNormLayer(net_h2, act=lambda x: tl.act.lrelu(x, 0.2), is_train=is_train, gamma_init=gamma_init, name='en/h2/batch_norm')\n","\n","        net_h3 = Conv2d(net_h2, ef_dim*8, (4, 4), (2, 2), act=None, padding='SAME', W_init=w_init, name='en/h3/conv2d')\n","        net_h3 = BatchNormLayer(net_h3, act=lambda x: tl.act.lrelu(x, 0.2), is_train=is_train, gamma_init=gamma_init, name='en/h3/batch_norm')\n","\n","        # mean of z\n","        net_h4 = FlattenLayer(net_h3, name='en/h4/flatten')\n","        net_out1 = DenseLayer(net_h4, n_units=z_dim, act=tf.identity, W_init = w_init, name='en/out1/lin_sigmoid')\n","        z_mean = net_out1.outputs # (b_size,100)\n","\n","        # log of variance of z(covariance matrix is diagonal)\n","        net_h5 = FlattenLayer(net_h3, name='en/h5/flatten')\n","        net_out2 = DenseLayer(net_h5, n_units=z_dim, act=tf.identity, W_init = w_init, name='en/out2/lin_sigmoid')\n","        z_log_sigma_sq = net_out2.outputs + 1e-6\n","\n","    return net_out1, net_out2, z_mean, z_log_sigma_sq\n","\n","def generator(inputs, is_train = True, reuse = False):\n","    image_size = OUTPUT_SIZE # 64 the output size of generator\n","    s2, s4, s8, s16 = int(image_size/2), int(image_size/4), int(image_size/8), int(image_size/16) # 32,16,8,4\n","    gf_dim = 32\n","    c_dim = C_DIM\n","    batch_size = BATCH_SIZE\n","\n","    w_init = tf.random_normal_initializer(stddev=0.02)\n","    gamma_init = tf.random_normal_initializer(1., 0.02)\n","\n","    with tf.variable_scope(\"generator\", reuse = reuse):\n","        tl.layers.set_name_reuse(reuse)\n","\n","        net_in = InputLayer(inputs, name='g/in')\n","        net_h0 = DenseLayer(net_in, n_units=gf_dim*8*s16*s16, W_init=w_init, act = tf.identity, name='g/h0/lin')\n","        net_h0 = ReshapeLayer(net_h0, shape=[-1, s16, s16, gf_dim*8], name='g/h0/reshape')\n","        net_h0 = BatchNormLayer(net_h0, act=lambda x: tl.act.lrelu(x, 0.2), is_train=is_train, gamma_init=gamma_init, name='g/h0/batch_norm')\n","\n","        # upsampling\n","        net_h1 = UpSampling2dLayer(net_h0, size=[8, 8], is_scale=False, method=1, align_corners=False, name='g/h1/upsample2d')\n","        net_h1 = Conv2d(net_h1, gf_dim*4, (3, 3), (1, 1), padding='SAME', W_init=w_init, name='g/h1/conv2d')\n","        net_h1 = BatchNormLayer(net_h1, act=lambda x: tl.act.lrelu(x, 0.2), is_train=is_train, gamma_init=gamma_init, name='g/h1/batch_norm')\n","\n","        net_h2 = UpSampling2dLayer(net_h1, size=[16, 16], is_scale=False, method=1, align_corners=False, name='g/h2/upsample2d')\n","        net_h2 = Conv2d(net_h2, gf_dim*2, (3, 3), (1, 1), padding='SAME', W_init=w_init, name='g/h2/conv2d')\n","        net_h2 = BatchNormLayer(net_h2, act=lambda x: tl.act.lrelu(x, 0.2), is_train=is_train, gamma_init=gamma_init, name='g/h2/batch_norm')\n","\n","        net_h3 = UpSampling2dLayer(net_h2, size=[32, 32], is_scale=False, method=1, align_corners=False, name='g/h3/upsample2d')\n","        net_h3 = Conv2d(net_h3, gf_dim, (3, 3), (1, 1), padding='SAME', W_init=w_init, name='g/h3/conv2d')\n","        net_h3 = BatchNormLayer(net_h3, act=lambda x: tl.act.lrelu(x, 0.2), is_train=is_train, gamma_init=gamma_init, name='g/h3/batch_norm')\n","        net_h4 = UpSampling2dLayer(net_h3, size=[64, 64], is_scale=False, method=1, align_corners=False, name='g/h4/upsample2d')\n","        net_h4 = Conv2d(net_h4, c_dim, (3, 3), (1, 1), padding='SAME', W_init=w_init, name='g/h4/conv2d')\n","        logits = net_h4.outputs\n","        net_h4.outputs = tf.nn.tanh(net_h4.outputs)\n","    return net_h4, logits\n","\n","#-------------------------------- Define model --------------------------------#\n","with tf.device(\"/gpu:0\"):\n","  # The input_imgs are input for both encoder and discriminator\n","  input_imgs = tf.placeholder(\n","        tf.float32,\n","        [BATCH_SIZE, OUTPUT_SIZE, OUTPUT_SIZE, C_DIM], name='real_images'\n","  )\n","\n","  # Normal distribution for generator\n","  z_p = tf.random_normal(shape=(BATCH_SIZE, Z_DIM), mean=0.0, stddev=1.0)\n","  # Normal distribution for reparameterization trick\n","  eps = tf.random_normal(shape=(BATCH_SIZE, Z_DIM), mean=0.0, stddev=1.0)\n","  lr_vae = tf.placeholder(tf.float32, shape=[])\n","\n","  # ----------------------encoder----------------------\n","  net_out1, net_out2, z_mean, z_log_sigma_sq = encoder(input_imgs, is_train=True, reuse=False)\n","\n","  # ----------------------decoder----------------------\n","  z = tf.add(z_mean, tf.multiply(tf.sqrt(tf.exp(z_log_sigma_sq)), eps)) # using reparameterization tricks\n","  gen0, gen0_logits = generator(z, is_train=True, reuse=False) # reconstruction\n","\n","  # ----------------------vgg net--------------------------\n","  vgg1_input = tf.image.resize_images(input_imgs,[224,224])\n","  net_in_real = InputLayer(vgg1_input, name='input1')\n","  conv1,l1_r,l2_r,l3_r,_,_ = conv_layers_simple_api(net_in_real, reuse=False)\n","  vgg1 = fc_layers(conv1,reuse=False)\n","\n","  vgg2_input = tf.image.resize_images(gen0.outputs,[224,224])\n","  net_in_fake = InputLayer(vgg2_input, name='input2')\n","  conv2,l1,l2,l3,_,_ = conv_layers_simple_api(net_in_fake, reuse=True)\n","  vgg2 = fc_layers(conv2,reuse=True)\n","\n","  # For generating FID-score\n","  input_imgs1 = tf.placeholder(\n","        tf.float32,\n","        [BATCH_SIZE, OUTPUT_SIZE, OUTPUT_SIZE, C_DIM], name='fidImages'\n","  )\n","  vgg3_input = tf.image.resize_images(input_imgs1,[224,224])\n","  net_in_real = InputLayer(vgg3_input, name='inputFid')\n","  conv1_fid,l1_fid,l2_fid,l3_fid,l4_fid,l5_fid = conv_layers_simple_api(net_in_real, reuse=True)\n","  l5_fid = fc_layers(conv1,reuse=True)\n","\n","\n","  # ----------------------for samples----------------------\n","  gen2, gen2_logits = generator(z, is_train=False, reuse=True)\n","  gen3, gen3_logits = generator(z_p, is_train=False, reuse=True)\n","  z_custom = tf.placeholder(tf.float32, [BATCH_SIZE, Z_DIM], name='z_custom')\n","  gen4, gen3_logits = generator(z_custom, is_train=False, reuse=True)\n","\n","  # ----------------------train ops----------------------\n","\n","  SSE_loss = tf.reduce_mean(tf.reduce_sum(tf.square(gen0.outputs - input_imgs),[1,2,3]))\n","  print(SSE_loss.get_shape(),type(SSE_loss))\n","\n","  # perceptual loss in feature space in VGG net\n","  p1_loss = tf.reduce_mean(tf.reduce_sum(tf.square(l1 - l1_r), [1,2,3]))\n","  p2_loss = tf.reduce_mean(tf.reduce_sum(tf.square(l2 - l2_r), [1,2,3]))\n","  p3_loss = tf.reduce_mean(tf.reduce_sum(tf.square(l3 - l3_r), [1,2,3]))\n","  p_loss = p1_loss + p2_loss + p3_loss\n","\n","  # train_vae\n","  KL_loss = tf.reduce_mean(- 0.5 * tf.reduce_sum(1 + z_log_sigma_sq - tf.square(z_mean) - tf.exp(z_log_sigma_sq),1))\n","  print(KL_loss.get_shape(), type(KL_loss))\n","\n","  style_content_weight = 3e-5 # you may need to tweak this weight for a different dataset\n","  VAE_loss = KL_loss + style_content_weight * p_loss\n","\n","  e_vars = tl.layers.get_variables_with_name('encoder', True, True)\n","  g_vars = tl.layers.get_variables_with_name('generator', True, True)\n","  vae_vars = e_vars + g_vars\n","\n","  print(\"-------encoder-------\")\n","  net_out1.print_params(False)\n","  print(\"-------generator-------\")\n","  gen0.print_params(False)\n","\n","  vae_optim = tf.train.AdamOptimizer(lr_vae, beta1=BETA1).minimize(VAE_loss, var_list=vae_vars)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorlayer/layers.py:288: The name tf.get_variable_scope is deprecated. Please use tf.compat.v1.get_variable_scope instead.\n","\n","  [TL] InputLayer  encoder/en/in: (64, 64, 64, 3)\n","  [TL] Conv2dLayer encoder/en/h0/conv2d: shape:[4, 4, 3, 32] strides:[1, 2, 2, 1] pad:SAME act:identity\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorlayer/layers.py:1385: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n","\n","  [TL] BatchNormLayer encoder/en/h0/batch_norm: decay:0.900000 epsilon:0.000010 act:<lambda> is_train:True\n","  [TL] Conv2dLayer encoder/en/h1/conv2d: shape:[4, 4, 32, 64] strides:[1, 2, 2, 1] pad:SAME act:identity\n","  [TL] BatchNormLayer encoder/en/h1/batch_norm: decay:0.900000 epsilon:0.000010 act:<lambda> is_train:True\n","  [TL] Conv2dLayer encoder/en/h2/conv2d: shape:[4, 4, 64, 128] strides:[1, 2, 2, 1] pad:SAME act:identity\n","  [TL] BatchNormLayer encoder/en/h2/batch_norm: decay:0.900000 epsilon:0.000010 act:<lambda> is_train:True\n","  [TL] Conv2dLayer encoder/en/h3/conv2d: shape:[4, 4, 128, 256] strides:[1, 2, 2, 1] pad:SAME act:identity\n","  [TL] BatchNormLayer encoder/en/h3/batch_norm: decay:0.900000 epsilon:0.000010 act:<lambda> is_train:True\n","  [TL] FlattenLayer encoder/en/h4/flatten: 4096\n","  [TL] DenseLayer  encoder/en/out1/lin_sigmoid: 100 identity\n","  [TL] FlattenLayer encoder/en/h5/flatten: 4096\n","  [TL] DenseLayer  encoder/en/out2/lin_sigmoid: 100 identity\n","  [TL] InputLayer  generator/g/in: (64, 100)\n","  [TL] DenseLayer  generator/g/h0/lin: 4096 identity\n","  [TL] ReshapeLayer generator/g/h0/reshape: (64, 4, 4, 256)\n","  [TL] BatchNormLayer generator/g/h0/batch_norm: decay:0.900000 epsilon:0.000010 act:<lambda> is_train:True\n","  [TL] UpSampling2dLayer g/h1/upsample2d: is_scale:False size:[8, 8] method:1 align_corners:False\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorlayer/layers.py:1670: The name tf.image.resize_images is deprecated. Please use tf.image.resize instead.\n","\n","  [TL] Conv2dLayer generator/g/h1/conv2d: shape:[3, 3, 256, 128] strides:[1, 1, 1, 1] pad:SAME act:identity\n","  [TL] BatchNormLayer generator/g/h1/batch_norm: decay:0.900000 epsilon:0.000010 act:<lambda> is_train:True\n","  [TL] UpSampling2dLayer g/h2/upsample2d: is_scale:False size:[16, 16] method:1 align_corners:False\n","  [TL] Conv2dLayer generator/g/h2/conv2d: shape:[3, 3, 128, 64] strides:[1, 1, 1, 1] pad:SAME act:identity\n","  [TL] BatchNormLayer generator/g/h2/batch_norm: decay:0.900000 epsilon:0.000010 act:<lambda> is_train:True\n","  [TL] UpSampling2dLayer g/h3/upsample2d: is_scale:False size:[32, 32] method:1 align_corners:False\n","  [TL] Conv2dLayer generator/g/h3/conv2d: shape:[3, 3, 64, 32] strides:[1, 1, 1, 1] pad:SAME act:identity\n","  [TL] BatchNormLayer generator/g/h3/batch_norm: decay:0.900000 epsilon:0.000010 act:<lambda> is_train:True\n","  [TL] UpSampling2dLayer g/h4/upsample2d: is_scale:False size:[64, 64] method:1 align_corners:False\n","  [TL] Conv2dLayer generator/g/h4/conv2d: shape:[3, 3, 32, 3] strides:[1, 1, 1, 1] pad:SAME act:identity\n","  [TL] InputLayer  input1: (64, 224, 224, 3)\n","  [TL] Conv2dLayer vgg_conv/conv1_1: shape:[3, 3, 3, 64] strides:[1, 1, 1, 1] pad:SAME act:relu\n","  [TL] Conv2dLayer vgg_conv/conv1_2: shape:[3, 3, 64, 64] strides:[1, 1, 1, 1] pad:SAME act:relu\n","  [TL] PoolLayer   vgg_conv/pool1: ksize:[1, 2, 2, 1] strides:[1, 2, 2, 1] padding:SAME pool:max_pool\n","  [TL] Conv2dLayer vgg_conv/conv2_1: shape:[3, 3, 64, 128] strides:[1, 1, 1, 1] pad:SAME act:relu\n","  [TL] Conv2dLayer vgg_conv/conv2_2: shape:[3, 3, 128, 128] strides:[1, 1, 1, 1] pad:SAME act:relu\n","  [TL] PoolLayer   vgg_conv/pool2: ksize:[1, 2, 2, 1] strides:[1, 2, 2, 1] padding:SAME pool:max_pool\n","  [TL] Conv2dLayer vgg_conv/conv3_1: shape:[3, 3, 128, 256] strides:[1, 1, 1, 1] pad:SAME act:relu\n","  [TL] Conv2dLayer vgg_conv/conv3_2: shape:[3, 3, 256, 256] strides:[1, 1, 1, 1] pad:SAME act:relu\n","  [TL] Conv2dLayer vgg_conv/conv3_3: shape:[3, 3, 256, 256] strides:[1, 1, 1, 1] pad:SAME act:relu\n","  [TL] PoolLayer   vgg_conv/pool3: ksize:[1, 2, 2, 1] strides:[1, 2, 2, 1] padding:SAME pool:max_pool\n","  [TL] Conv2dLayer vgg_conv/conv4_1: shape:[3, 3, 256, 512] strides:[1, 1, 1, 1] pad:SAME act:relu\n","  [TL] Conv2dLayer vgg_conv/conv4_2: shape:[3, 3, 512, 512] strides:[1, 1, 1, 1] pad:SAME act:relu\n","  [TL] Conv2dLayer vgg_conv/conv4_3: shape:[3, 3, 512, 512] strides:[1, 1, 1, 1] pad:SAME act:relu\n","  [TL] PoolLayer   vgg_conv/pool4: ksize:[1, 2, 2, 1] strides:[1, 2, 2, 1] padding:SAME pool:max_pool\n","  [TL] Conv2dLayer vgg_conv/conv5_1: shape:[3, 3, 512, 512] strides:[1, 1, 1, 1] pad:SAME act:relu\n","  [TL] Conv2dLayer vgg_conv/conv5_2: shape:[3, 3, 512, 512] strides:[1, 1, 1, 1] pad:SAME act:relu\n","  [TL] Conv2dLayer vgg_conv/conv5_3: shape:[3, 3, 512, 512] strides:[1, 1, 1, 1] pad:SAME act:relu\n","  [TL] PoolLayer   vgg_conv/pool5: ksize:[1, 2, 2, 1] strides:[1, 2, 2, 1] padding:SAME pool:max_pool\n","  [TL] FlattenLayer vgg_fc/flatten: 25088\n","  [TL] DenseLayer  vgg_fc/fc1_relu: 4096 relu\n","  [TL] DenseLayer  vgg_fc/fc2_relu: 4096 relu\n","  [TL] DenseLayer  vgg_fc/fc3_relu: 1000 identity\n","  [TL] InputLayer  input2: (64, 224, 224, 3)\n","  [TL] Conv2dLayer vgg_conv/conv1_1: shape:[3, 3, 3, 64] strides:[1, 1, 1, 1] pad:SAME act:relu\n","  [TL] Conv2dLayer vgg_conv/conv1_2: shape:[3, 3, 64, 64] strides:[1, 1, 1, 1] pad:SAME act:relu\n","  [TL] PoolLayer   vgg_conv/pool1: ksize:[1, 2, 2, 1] strides:[1, 2, 2, 1] padding:SAME pool:max_pool\n","  [TL] Conv2dLayer vgg_conv/conv2_1: shape:[3, 3, 64, 128] strides:[1, 1, 1, 1] pad:SAME act:relu\n","  [TL] Conv2dLayer vgg_conv/conv2_2: shape:[3, 3, 128, 128] strides:[1, 1, 1, 1] pad:SAME act:relu\n","  [TL] PoolLayer   vgg_conv/pool2: ksize:[1, 2, 2, 1] strides:[1, 2, 2, 1] padding:SAME pool:max_pool\n","  [TL] Conv2dLayer vgg_conv/conv3_1: shape:[3, 3, 128, 256] strides:[1, 1, 1, 1] pad:SAME act:relu\n","  [TL] Conv2dLayer vgg_conv/conv3_2: shape:[3, 3, 256, 256] strides:[1, 1, 1, 1] pad:SAME act:relu\n","  [TL] Conv2dLayer vgg_conv/conv3_3: shape:[3, 3, 256, 256] strides:[1, 1, 1, 1] pad:SAME act:relu\n","  [TL] PoolLayer   vgg_conv/pool3: ksize:[1, 2, 2, 1] strides:[1, 2, 2, 1] padding:SAME pool:max_pool\n","  [TL] Conv2dLayer vgg_conv/conv4_1: shape:[3, 3, 256, 512] strides:[1, 1, 1, 1] pad:SAME act:relu\n","  [TL] Conv2dLayer vgg_conv/conv4_2: shape:[3, 3, 512, 512] strides:[1, 1, 1, 1] pad:SAME act:relu\n","  [TL] Conv2dLayer vgg_conv/conv4_3: shape:[3, 3, 512, 512] strides:[1, 1, 1, 1] pad:SAME act:relu\n","  [TL] PoolLayer   vgg_conv/pool4: ksize:[1, 2, 2, 1] strides:[1, 2, 2, 1] padding:SAME pool:max_pool\n","  [TL] Conv2dLayer vgg_conv/conv5_1: shape:[3, 3, 512, 512] strides:[1, 1, 1, 1] pad:SAME act:relu\n","  [TL] Conv2dLayer vgg_conv/conv5_2: shape:[3, 3, 512, 512] strides:[1, 1, 1, 1] pad:SAME act:relu\n","  [TL] Conv2dLayer vgg_conv/conv5_3: shape:[3, 3, 512, 512] strides:[1, 1, 1, 1] pad:SAME act:relu\n","  [TL] PoolLayer   vgg_conv/pool5: ksize:[1, 2, 2, 1] strides:[1, 2, 2, 1] padding:SAME pool:max_pool\n","  [TL] FlattenLayer vgg_fc/flatten: 25088\n","  [TL] DenseLayer  vgg_fc/fc1_relu: 4096 relu\n","  [TL] DenseLayer  vgg_fc/fc2_relu: 4096 relu\n","  [TL] DenseLayer  vgg_fc/fc3_relu: 1000 identity\n","  [TL] InputLayer  inputFid: (64, 224, 224, 3)\n","  [TL] Conv2dLayer vgg_conv/conv1_1: shape:[3, 3, 3, 64] strides:[1, 1, 1, 1] pad:SAME act:relu\n","  [TL] Conv2dLayer vgg_conv/conv1_2: shape:[3, 3, 64, 64] strides:[1, 1, 1, 1] pad:SAME act:relu\n","  [TL] PoolLayer   vgg_conv/pool1: ksize:[1, 2, 2, 1] strides:[1, 2, 2, 1] padding:SAME pool:max_pool\n","  [TL] Conv2dLayer vgg_conv/conv2_1: shape:[3, 3, 64, 128] strides:[1, 1, 1, 1] pad:SAME act:relu\n","  [TL] Conv2dLayer vgg_conv/conv2_2: shape:[3, 3, 128, 128] strides:[1, 1, 1, 1] pad:SAME act:relu\n","  [TL] PoolLayer   vgg_conv/pool2: ksize:[1, 2, 2, 1] strides:[1, 2, 2, 1] padding:SAME pool:max_pool\n","  [TL] Conv2dLayer vgg_conv/conv3_1: shape:[3, 3, 128, 256] strides:[1, 1, 1, 1] pad:SAME act:relu\n","  [TL] Conv2dLayer vgg_conv/conv3_2: shape:[3, 3, 256, 256] strides:[1, 1, 1, 1] pad:SAME act:relu\n","  [TL] Conv2dLayer vgg_conv/conv3_3: shape:[3, 3, 256, 256] strides:[1, 1, 1, 1] pad:SAME act:relu\n","  [TL] PoolLayer   vgg_conv/pool3: ksize:[1, 2, 2, 1] strides:[1, 2, 2, 1] padding:SAME pool:max_pool\n","  [TL] Conv2dLayer vgg_conv/conv4_1: shape:[3, 3, 256, 512] strides:[1, 1, 1, 1] pad:SAME act:relu\n","  [TL] Conv2dLayer vgg_conv/conv4_2: shape:[3, 3, 512, 512] strides:[1, 1, 1, 1] pad:SAME act:relu\n","  [TL] Conv2dLayer vgg_conv/conv4_3: shape:[3, 3, 512, 512] strides:[1, 1, 1, 1] pad:SAME act:relu\n","  [TL] PoolLayer   vgg_conv/pool4: ksize:[1, 2, 2, 1] strides:[1, 2, 2, 1] padding:SAME pool:max_pool\n","  [TL] Conv2dLayer vgg_conv/conv5_1: shape:[3, 3, 512, 512] strides:[1, 1, 1, 1] pad:SAME act:relu\n","  [TL] Conv2dLayer vgg_conv/conv5_2: shape:[3, 3, 512, 512] strides:[1, 1, 1, 1] pad:SAME act:relu\n","  [TL] Conv2dLayer vgg_conv/conv5_3: shape:[3, 3, 512, 512] strides:[1, 1, 1, 1] pad:SAME act:relu\n","  [TL] PoolLayer   vgg_conv/pool5: ksize:[1, 2, 2, 1] strides:[1, 2, 2, 1] padding:SAME pool:max_pool\n","  [TL] FlattenLayer vgg_fc/flatten: 25088\n","  [TL] DenseLayer  vgg_fc/fc1_relu: 4096 relu\n","  [TL] DenseLayer  vgg_fc/fc2_relu: 4096 relu\n","  [TL] DenseLayer  vgg_fc/fc3_relu: 1000 identity\n","  [TL] InputLayer  generator/g/in: (64, 100)\n","  [TL] DenseLayer  generator/g/h0/lin: 4096 identity\n","  [TL] ReshapeLayer generator/g/h0/reshape: (64, 4, 4, 256)\n","  [TL] BatchNormLayer generator/g/h0/batch_norm: decay:0.900000 epsilon:0.000010 act:<lambda> is_train:False\n","  [TL] UpSampling2dLayer g/h1/upsample2d: is_scale:False size:[8, 8] method:1 align_corners:False\n","  [TL] Conv2dLayer generator/g/h1/conv2d: shape:[3, 3, 256, 128] strides:[1, 1, 1, 1] pad:SAME act:identity\n","  [TL] BatchNormLayer generator/g/h1/batch_norm: decay:0.900000 epsilon:0.000010 act:<lambda> is_train:False\n","  [TL] UpSampling2dLayer g/h2/upsample2d: is_scale:False size:[16, 16] method:1 align_corners:False\n","  [TL] Conv2dLayer generator/g/h2/conv2d: shape:[3, 3, 128, 64] strides:[1, 1, 1, 1] pad:SAME act:identity\n","  [TL] BatchNormLayer generator/g/h2/batch_norm: decay:0.900000 epsilon:0.000010 act:<lambda> is_train:False\n","  [TL] UpSampling2dLayer g/h3/upsample2d: is_scale:False size:[32, 32] method:1 align_corners:False\n","  [TL] Conv2dLayer generator/g/h3/conv2d: shape:[3, 3, 64, 32] strides:[1, 1, 1, 1] pad:SAME act:identity\n","  [TL] BatchNormLayer generator/g/h3/batch_norm: decay:0.900000 epsilon:0.000010 act:<lambda> is_train:False\n","  [TL] UpSampling2dLayer g/h4/upsample2d: is_scale:False size:[64, 64] method:1 align_corners:False\n","  [TL] Conv2dLayer generator/g/h4/conv2d: shape:[3, 3, 32, 3] strides:[1, 1, 1, 1] pad:SAME act:identity\n","  [TL] InputLayer  generator/g/in: (64, 100)\n","  [TL] DenseLayer  generator/g/h0/lin: 4096 identity\n","  [TL] ReshapeLayer generator/g/h0/reshape: (64, 4, 4, 256)\n","  [TL] BatchNormLayer generator/g/h0/batch_norm: decay:0.900000 epsilon:0.000010 act:<lambda> is_train:False\n","  [TL] UpSampling2dLayer g/h1/upsample2d: is_scale:False size:[8, 8] method:1 align_corners:False\n","  [TL] Conv2dLayer generator/g/h1/conv2d: shape:[3, 3, 256, 128] strides:[1, 1, 1, 1] pad:SAME act:identity\n","  [TL] BatchNormLayer generator/g/h1/batch_norm: decay:0.900000 epsilon:0.000010 act:<lambda> is_train:False\n","  [TL] UpSampling2dLayer g/h2/upsample2d: is_scale:False size:[16, 16] method:1 align_corners:False\n","  [TL] Conv2dLayer generator/g/h2/conv2d: shape:[3, 3, 128, 64] strides:[1, 1, 1, 1] pad:SAME act:identity\n","  [TL] BatchNormLayer generator/g/h2/batch_norm: decay:0.900000 epsilon:0.000010 act:<lambda> is_train:False\n","  [TL] UpSampling2dLayer g/h3/upsample2d: is_scale:False size:[32, 32] method:1 align_corners:False\n","  [TL] Conv2dLayer generator/g/h3/conv2d: shape:[3, 3, 64, 32] strides:[1, 1, 1, 1] pad:SAME act:identity\n","  [TL] BatchNormLayer generator/g/h3/batch_norm: decay:0.900000 epsilon:0.000010 act:<lambda> is_train:False\n","  [TL] UpSampling2dLayer g/h4/upsample2d: is_scale:False size:[64, 64] method:1 align_corners:False\n","  [TL] Conv2dLayer generator/g/h4/conv2d: shape:[3, 3, 32, 3] strides:[1, 1, 1, 1] pad:SAME act:identity\n","  [TL] InputLayer  generator/g/in: (64, 100)\n","  [TL] DenseLayer  generator/g/h0/lin: 4096 identity\n","  [TL] ReshapeLayer generator/g/h0/reshape: (64, 4, 4, 256)\n","  [TL] BatchNormLayer generator/g/h0/batch_norm: decay:0.900000 epsilon:0.000010 act:<lambda> is_train:False\n","  [TL] UpSampling2dLayer g/h1/upsample2d: is_scale:False size:[8, 8] method:1 align_corners:False\n","  [TL] Conv2dLayer generator/g/h1/conv2d: shape:[3, 3, 256, 128] strides:[1, 1, 1, 1] pad:SAME act:identity\n","  [TL] BatchNormLayer generator/g/h1/batch_norm: decay:0.900000 epsilon:0.000010 act:<lambda> is_train:False\n","  [TL] UpSampling2dLayer g/h2/upsample2d: is_scale:False size:[16, 16] method:1 align_corners:False\n","  [TL] Conv2dLayer generator/g/h2/conv2d: shape:[3, 3, 128, 64] strides:[1, 1, 1, 1] pad:SAME act:identity\n","  [TL] BatchNormLayer generator/g/h2/batch_norm: decay:0.900000 epsilon:0.000010 act:<lambda> is_train:False\n","  [TL] UpSampling2dLayer g/h3/upsample2d: is_scale:False size:[32, 32] method:1 align_corners:False\n","  [TL] Conv2dLayer generator/g/h3/conv2d: shape:[3, 3, 64, 32] strides:[1, 1, 1, 1] pad:SAME act:identity\n","  [TL] BatchNormLayer generator/g/h3/batch_norm: decay:0.900000 epsilon:0.000010 act:<lambda> is_train:False\n","  [TL] UpSampling2dLayer g/h4/upsample2d: is_scale:False size:[64, 64] method:1 align_corners:False\n","  [TL] Conv2dLayer generator/g/h4/conv2d: shape:[3, 3, 32, 3] strides:[1, 1, 1, 1] pad:SAME act:identity\n","() <class 'tensorflow.python.framework.ops.Tensor'>\n","() <class 'tensorflow.python.framework.ops.Tensor'>\n","  [*] geting variables with encoder\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorlayer/layers.py:169: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n","\n","  got   0: encoder/en/h0/conv2d/W_conv2d:0   (4, 4, 3, 32)\n","  got   1: encoder/en/h0/conv2d/b_conv2d:0   (32,)\n","  got   2: encoder/en/h0/batch_norm/beta:0   (32,)\n","  got   3: encoder/en/h0/batch_norm/gamma:0   (32,)\n","  got   4: encoder/en/h1/conv2d/W_conv2d:0   (4, 4, 32, 64)\n","  got   5: encoder/en/h1/conv2d/b_conv2d:0   (64,)\n","  got   6: encoder/en/h1/batch_norm/beta:0   (64,)\n","  got   7: encoder/en/h1/batch_norm/gamma:0   (64,)\n","  got   8: encoder/en/h2/conv2d/W_conv2d:0   (4, 4, 64, 128)\n","  got   9: encoder/en/h2/conv2d/b_conv2d:0   (128,)\n","  got  10: encoder/en/h2/batch_norm/beta:0   (128,)\n","  got  11: encoder/en/h2/batch_norm/gamma:0   (128,)\n","  got  12: encoder/en/h3/conv2d/W_conv2d:0   (4, 4, 128, 256)\n","  got  13: encoder/en/h3/conv2d/b_conv2d:0   (256,)\n","  got  14: encoder/en/h3/batch_norm/beta:0   (256,)\n","  got  15: encoder/en/h3/batch_norm/gamma:0   (256,)\n","  got  16: encoder/en/out1/lin_sigmoid/W:0   (4096, 100)\n","  got  17: encoder/en/out1/lin_sigmoid/b:0   (100,)\n","  got  18: encoder/en/out2/lin_sigmoid/W:0   (4096, 100)\n","  got  19: encoder/en/out2/lin_sigmoid/b:0   (100,)\n","  [*] geting variables with generator\n","  got   0: generator/g/h0/lin/W:0   (100, 4096)\n","  got   1: generator/g/h0/lin/b:0   (4096,)\n","  got   2: generator/g/h0/batch_norm/beta:0   (256,)\n","  got   3: generator/g/h0/batch_norm/gamma:0   (256,)\n","  got   4: generator/g/h1/conv2d/W_conv2d:0   (3, 3, 256, 128)\n","  got   5: generator/g/h1/conv2d/b_conv2d:0   (128,)\n","  got   6: generator/g/h1/batch_norm/beta:0   (128,)\n","  got   7: generator/g/h1/batch_norm/gamma:0   (128,)\n","  got   8: generator/g/h2/conv2d/W_conv2d:0   (3, 3, 128, 64)\n","  got   9: generator/g/h2/conv2d/b_conv2d:0   (64,)\n","  got  10: generator/g/h2/batch_norm/beta:0   (64,)\n","  got  11: generator/g/h2/batch_norm/gamma:0   (64,)\n","  got  12: generator/g/h3/conv2d/W_conv2d:0   (3, 3, 64, 32)\n","  got  13: generator/g/h3/conv2d/b_conv2d:0   (32,)\n","  got  14: generator/g/h3/batch_norm/beta:0   (32,)\n","  got  15: generator/g/h3/batch_norm/gamma:0   (32,)\n","  got  16: generator/g/h4/conv2d/W_conv2d:0   (3, 3, 32, 3)\n","  got  17: generator/g/h4/conv2d/b_conv2d:0   (3,)\n","-------encoder-------\n","  param   0: encoder/en/h0/conv2d/W_conv2d:0 (4, 4, 3, 32)      float32_ref\n","  param   1: encoder/en/h0/conv2d/b_conv2d:0 (32,)              float32_ref\n","  param   2: encoder/en/h0/batch_norm/beta:0 (32,)              float32_ref\n","  param   3: encoder/en/h0/batch_norm/gamma:0 (32,)              float32_ref\n","  param   4: encoder/en/h0/batch_norm/moving_mean:0 (32,)              float32_ref\n","  param   5: encoder/en/h0/batch_norm/moving_variance:0 (32,)              float32_ref\n","  param   6: encoder/en/h1/conv2d/W_conv2d:0 (4, 4, 32, 64)     float32_ref\n","  param   7: encoder/en/h1/conv2d/b_conv2d:0 (64,)              float32_ref\n","  param   8: encoder/en/h1/batch_norm/beta:0 (64,)              float32_ref\n","  param   9: encoder/en/h1/batch_norm/gamma:0 (64,)              float32_ref\n","  param  10: encoder/en/h1/batch_norm/moving_mean:0 (64,)              float32_ref\n","  param  11: encoder/en/h1/batch_norm/moving_variance:0 (64,)              float32_ref\n","  param  12: encoder/en/h2/conv2d/W_conv2d:0 (4, 4, 64, 128)    float32_ref\n","  param  13: encoder/en/h2/conv2d/b_conv2d:0 (128,)             float32_ref\n","  param  14: encoder/en/h2/batch_norm/beta:0 (128,)             float32_ref\n","  param  15: encoder/en/h2/batch_norm/gamma:0 (128,)             float32_ref\n","  param  16: encoder/en/h2/batch_norm/moving_mean:0 (128,)             float32_ref\n","  param  17: encoder/en/h2/batch_norm/moving_variance:0 (128,)             float32_ref\n","  param  18: encoder/en/h3/conv2d/W_conv2d:0 (4, 4, 128, 256)    float32_ref\n","  param  19: encoder/en/h3/conv2d/b_conv2d:0 (256,)             float32_ref\n","  param  20: encoder/en/h3/batch_norm/beta:0 (256,)             float32_ref\n","  param  21: encoder/en/h3/batch_norm/gamma:0 (256,)             float32_ref\n","  param  22: encoder/en/h3/batch_norm/moving_mean:0 (256,)             float32_ref\n","  param  23: encoder/en/h3/batch_norm/moving_variance:0 (256,)             float32_ref\n","  param  24: encoder/en/out1/lin_sigmoid/W:0 (4096, 100)        float32_ref\n","  param  25: encoder/en/out1/lin_sigmoid/b:0 (100,)             float32_ref\n","  num of params: 1101764\n","-------generator-------\n","  param   0: generator/g/h0/lin/W:0 (100, 4096)        float32_ref\n","  param   1: generator/g/h0/lin/b:0 (4096,)            float32_ref\n","  param   2: generator/g/h0/batch_norm/beta:0 (256,)             float32_ref\n","  param   3: generator/g/h0/batch_norm/gamma:0 (256,)             float32_ref\n","  param   4: generator/g/h0/batch_norm/moving_mean:0 (256,)             float32_ref\n","  param   5: generator/g/h0/batch_norm/moving_variance:0 (256,)             float32_ref\n","  param   6: generator/g/h1/conv2d/W_conv2d:0 (3, 3, 256, 128)    float32_ref\n","  param   7: generator/g/h1/conv2d/b_conv2d:0 (128,)             float32_ref\n","  param   8: generator/g/h1/batch_norm/beta:0 (128,)             float32_ref\n","  param   9: generator/g/h1/batch_norm/gamma:0 (128,)             float32_ref\n","  param  10: generator/g/h1/batch_norm/moving_mean:0 (128,)             float32_ref\n","  param  11: generator/g/h1/batch_norm/moving_variance:0 (128,)             float32_ref\n","  param  12: generator/g/h2/conv2d/W_conv2d:0 (3, 3, 128, 64)    float32_ref\n","  param  13: generator/g/h2/conv2d/b_conv2d:0 (64,)              float32_ref\n","  param  14: generator/g/h2/batch_norm/beta:0 (64,)              float32_ref\n","  param  15: generator/g/h2/batch_norm/gamma:0 (64,)              float32_ref\n","  param  16: generator/g/h2/batch_norm/moving_mean:0 (64,)              float32_ref\n","  param  17: generator/g/h2/batch_norm/moving_variance:0 (64,)              float32_ref\n","  param  18: generator/g/h3/conv2d/W_conv2d:0 (3, 3, 64, 32)     float32_ref\n","  param  19: generator/g/h3/conv2d/b_conv2d:0 (32,)              float32_ref\n","  param  20: generator/g/h3/batch_norm/beta:0 (32,)              float32_ref\n","  param  21: generator/g/h3/batch_norm/gamma:0 (32,)              float32_ref\n","  param  22: generator/g/h3/batch_norm/moving_mean:0 (32,)              float32_ref\n","  param  23: generator/g/h3/batch_norm/moving_variance:0 (32,)              float32_ref\n","  param  24: generator/g/h4/conv2d/W_conv2d:0 (3, 3, 32, 3)      float32_ref\n","  param  25: generator/g/h4/conv2d/b_conv2d:0 (3,)               float32_ref\n","  num of params: 803779\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"nW2PpcTKRlqr","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"error","timestamp":1600879563435,"user_tz":-120,"elapsed":73832,"user":{"displayName":"WASP Drive","photoUrl":"","userId":"11895298268124410342"}},"outputId":"f1fc72d6-89ce-47ef-e37c-22f44ec4430d"},"source":["#-------------------------------- Load VGG network parameters --------------------------------#\n","if START_TF_SESSION:\n","  sess = tf.InteractiveSession()\n","  tl.layers.initialize_global_variables(sess)\n","\n","if LOAD_VGG_WEIGHTS:\n","  npz = np.load(LOAD_VGG_WEIGHTS_DIR)\n","  params = []\n","  for val in sorted( npz.items() ):\n","      print(\"  Loading %s\" % str(val[1].shape))\n","      params.append(val[1])\n","  tl.files.assign_params(sess, params, vgg1)\n","  tl.files.assign_params(sess, params, vgg2)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorlayer/layers.py:261: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n","\n"],"name":"stdout"},{"output_type":"error","ename":"InvalidArgumentError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)","\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1364\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1365\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1366\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1349\u001b[0m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[0;32m-> 1350\u001b[0;31m                                       target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1442\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1443\u001b[0;31m                                             run_metadata)\n\u001b[0m\u001b[1;32m   1444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mInvalidArgumentError\u001b[0m: Cannot assign a device for operation encoder/en/h0/conv2d/W_conv2d/Initializer/random_normal/RandomStandardNormal: Could not satisfy explicit device specification '' because the node {{colocation_node encoder/en/h0/conv2d/W_conv2d/Initializer/random_normal/RandomStandardNormal}} was colocated with a group of nodes that required incompatible device '/device:GPU:0'. All available devices [/job:localhost/replica:0/task:0/device:CPU:0, /job:localhost/replica:0/task:0/device:XLA_CPU:0]. \nColocation Debug Info:\nColocation group had the following types and supported devices: \nRoot Member(assigned_device_name_index_=-1 requested_device_name_='/device:GPU:0' assigned_device_name_='' resource_device_name_='/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]\nAdd: CPU XLA_CPU \nRandomStandardNormal: CPU XLA_CPU \nVariableV2: CPU \nFill: CPU XLA_CPU \nConst: CPU XLA_CPU \nMul: CPU XLA_CPU \nAssign: CPU \n\nColocation members, user-requested devices, and framework assigned devices, if any:\n  encoder/en/h0/conv2d/W_conv2d/Initializer/random_normal/shape (Const) \n  encoder/en/h0/conv2d/W_conv2d/Initializer/random_normal/mean (Const) \n  encoder/en/h0/conv2d/W_conv2d/Initializer/random_normal/stddev (Const) \n  encoder/en/h0/conv2d/W_conv2d/Initializer/random_normal/RandomStandardNormal (RandomStandardNormal) \n  encoder/en/h0/conv2d/W_conv2d/Initializer/random_normal/mul (Mul) \n  encoder/en/h0/conv2d/W_conv2d/Initializer/random_normal (Add) \n  encoder/en/h0/conv2d/W_conv2d (VariableV2) /device:GPU:0\n  encoder/en/h0/conv2d/W_conv2d/Assign (Assign) /device:GPU:0\n  encoder/en/h0/conv2d/W_conv2d/Adam/Initializer/zeros/shape_as_tensor (Const) /device:GPU:0\n  encoder/en/h0/conv2d/W_conv2d/Adam/Initializer/zeros/Const (Const) /device:GPU:0\n  encoder/en/h0/conv2d/W_conv2d/Adam/Initializer/zeros (Fill) /device:GPU:0\n  encoder/en/h0/conv2d/W_conv2d/Adam (VariableV2) /device:GPU:0\n  encoder/en/h0/conv2d/W_conv2d/Adam/Assign (Assign) /device:GPU:0\n  encoder/en/h0/conv2d/W_conv2d/Adam_1/Initializer/zeros/shape_as_tensor (Const) /device:GPU:0\n  encoder/en/h0/conv2d/W_conv2d/Adam_1/Initializer/zeros/Const (Const) /device:GPU:0\n  encoder/en/h0/conv2d/W_conv2d/Adam_1/Initializer/zeros (Fill) /device:GPU:0\n  encoder/en/h0/conv2d/W_conv2d/Adam_1 (VariableV2) /device:GPU:0\n  encoder/en/h0/conv2d/W_conv2d/Adam_1/Assign (Assign) /device:GPU:0\n\n\t [[{{node encoder/en/h0/conv2d/W_conv2d/Initializer/random_normal/RandomStandardNormal}}]]","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)","\u001b[0;32m<ipython-input-6-a9d655244569>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mSTART_TF_SESSION\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0msess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInteractiveSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0mtl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialize_global_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mLOAD_VGG_WEIGHTS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorlayer/layers.py\u001b[0m in \u001b[0;36minitialize_global_variables\u001b[0;34m(sess)\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0msess\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m     \u001b[0;31m# try:    # TF12+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 261\u001b[0;31m     \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_variables_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    262\u001b[0m     \u001b[0;31m# except: # TF11\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m     \u001b[0;31m#     sess.run(tf.initialize_all_variables())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    954\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    955\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 956\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    957\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    958\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1180\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1181\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1357\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1359\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1360\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1382\u001b[0m                     \u001b[0;34m'\\nsession_config.graph_options.rewrite_options.'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1383\u001b[0m                     'disable_meta_optimizer = True')\n\u001b[0;32m-> 1384\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mInvalidArgumentError\u001b[0m: Cannot assign a device for operation encoder/en/h0/conv2d/W_conv2d/Initializer/random_normal/RandomStandardNormal: Could not satisfy explicit device specification '' because the node node encoder/en/h0/conv2d/W_conv2d/Initializer/random_normal/RandomStandardNormal (defined at /tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/ops.py:1748) placed on device Device assignments active during op 'encoder/en/h0/conv2d/W_conv2d/Initializer/random_normal/RandomStandardNormal' creation:\n  with tf.device(None): </tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/variables.py:1816>\n  with tf.device(/gpu:0): <<ipython-input-5-8a9c9507d409>:77>  was colocated with a group of nodes that required incompatible device '/device:GPU:0'. All available devices [/job:localhost/replica:0/task:0/device:CPU:0, /job:localhost/replica:0/task:0/device:XLA_CPU:0]. \nColocation Debug Info:\nColocation group had the following types and supported devices: \nRoot Member(assigned_device_name_index_=-1 requested_device_name_='/device:GPU:0' assigned_device_name_='' resource_device_name_='/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]\nAdd: CPU XLA_CPU \nRandomStandardNormal: CPU XLA_CPU \nVariableV2: CPU \nFill: CPU XLA_CPU \nConst: CPU XLA_CPU \nMul: CPU XLA_CPU \nAssign: CPU \n\nColocation members, user-requested devices, and framework assigned devices, if any:\n  encoder/en/h0/conv2d/W_conv2d/Initializer/random_normal/shape (Const) \n  encoder/en/h0/conv2d/W_conv2d/Initializer/random_normal/mean (Const) \n  encoder/en/h0/conv2d/W_conv2d/Initializer/random_normal/stddev (Const) \n  encoder/en/h0/conv2d/W_conv2d/Initializer/random_normal/RandomStandardNormal (RandomStandardNormal) \n  encoder/en/h0/conv2d/W_conv2d/Initializer/random_normal/mul (Mul) \n  encoder/en/h0/conv2d/W_conv2d/Initializer/random_normal (Add) \n  encoder/en/h0/conv2d/W_conv2d (VariableV2) /device:GPU:0\n  encoder/en/h0/conv2d/W_conv2d/Assign (Assign) /device:GPU:0\n  encoder/en/h0/conv2d/W_conv2d/Adam/Initializer/zeros/shape_as_tensor (Const) /device:GPU:0\n  encoder/en/h0/conv2d/W_conv2d/Adam/Initializer/zeros/Const (Const) /device:GPU:0\n  encoder/en/h0/conv2d/W_conv2d/Adam/Initializer/zeros (Fill) /device:GPU:0\n  encoder/en/h0/conv2d/W_conv2d/Adam (VariableV2) /device:GPU:0\n  encoder/en/h0/conv2d/W_conv2d/Adam/Assign (Assign) /device:GPU:0\n  encoder/en/h0/conv2d/W_conv2d/Adam_1/Initializer/zeros/shape_as_tensor (Const) /device:GPU:0\n  encoder/en/h0/conv2d/W_conv2d/Adam_1/Initializer/zeros/Const (Const) /device:GPU:0\n  encoder/en/h0/conv2d/W_conv2d/Adam_1/Initializer/zeros (Fill) /device:GPU:0\n  encoder/en/h0/conv2d/W_conv2d/Adam_1 (VariableV2) /device:GPU:0\n  encoder/en/h0/conv2d/W_conv2d/Adam_1/Assign (Assign) /device:GPU:0\n\n\t [[node encoder/en/h0/conv2d/W_conv2d/Initializer/random_normal/RandomStandardNormal (defined at /tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/ops.py:1748) ]]Additional information about colocations:No node-device colocations were active during op 'encoder/en/h0/conv2d/W_conv2d/Initializer/random_normal/RandomStandardNormal' creation.\nDevice assignments active during op 'encoder/en/h0/conv2d/W_conv2d/Initializer/random_normal/RandomStandardNormal' creation:\n  with tf.device(None): </tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/variables.py:1816>\n  with tf.device(/gpu:0): <<ipython-input-5-8a9c9507d409>:77>\n\nOriginal stack trace for 'encoder/en/h0/conv2d/W_conv2d/Initializer/random_normal/RandomStandardNormal':\n  File \"/usr/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.6/dist-packages/traitlets/config/application.py\", line 664, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelapp.py\", line 499, in start\n    self.io_loop.start()\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/platform/asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"/usr/lib/python3.6/asyncio/base_events.py\", line 438, in run_forever\n    self._run_once()\n  File \"/usr/lib/python3.6/asyncio/base_events.py\", line 1451, in _run_once\n    handle._run()\n  File \"/usr/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/ioloop.py\", line 758, in _run_callback\n    ret = callback()\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 548, in <lambda>\n    self.io_loop.add_callback(lambda : self._handle_events(self.socket, 0))\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 462, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 492, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 444, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2822, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-5-8a9c9507d409>\", line 91, in <module>\n    net_out1, net_out2, z_mean, z_log_sigma_sq = encoder(input_imgs, is_train=True, reuse=False)\n  File \"<ipython-input-5-8a9c9507d409>\", line 16, in encoder\n    net_h0 = Conv2d(net_in, ef_dim, (4, 4), (2, 2), act=None, padding='SAME', W_init=w_init, name='en/h0/conv2d')\n  File \"/usr/local/lib/python3.6/dist-packages/tensorlayer/layers.py\", line 2292, in Conv2d\n    name = name)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorlayer/layers.py\", line 1385, in __init__\n    W = tf.get_variable(name='W_conv2d', shape=shape, initializer=W_init, **W_init_args )\n  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/variable_scope.py\", line 1500, in get_variable\n    aggregation=aggregation)\n  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/variable_scope.py\", line 1243, in get_variable\n    aggregation=aggregation)\n  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/variable_scope.py\", line 567, in get_variable\n    aggregation=aggregation)\n  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/variable_scope.py\", line 519, in _true_getter\n    aggregation=aggregation)\n  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/variable_scope.py\", line 933, in _get_single_variable\n    aggregation=aggregation)\n  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/variables.py\", line 258, in __call__\n    return cls._variable_v1_call(*args, **kwargs)\n  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/variables.py\", line 219, in _variable_v1_call\n    shape=shape)\n  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/variables.py\", line 197, in <lambda>\n    previous_getter = lambda **kwargs: default_variable_creator(None, **kwargs)\n  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/variable_scope.py\", line 2519, in default_variable_creator\n    shape=shape)\n  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/variables.py\", line 262, in __call__\n    return super(VariableMetaclass, cls).__call__(*args, **kwargs)\n  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/variables.py\", line 1688, in __init__\n    shape=shape)\n  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/variables.py\", line 1818, in _init_from_args\n    initial_value(), name=\"initial_value\", dtype=dtype)\n  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/variable_scope.py\", line 905, in <lambda>\n    partition_info=partition_info)\n  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/init_ops.py\", line 323, in __call__\n    shape, self.mean, self.stddev, dtype, seed=self.seed)\n  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/random_ops.py\", line 74, in random_normal\n    shape_tensor, dtype, seed=seed1, seed2=seed2)\n  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/gen_random_ops.py\", line 729, in random_standard_normal\n    seed2=seed2, name=name)\n  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/op_def_library.py\", line 794, in _apply_op_helper\n    op_def=op_def)\n  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/ops.py\", line 3357, in create_op\n    attrs, op_def, compute_device)\n  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/ops.py\", line 3426, in _create_op_internal\n    op_def=op_def)\n  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/ops.py\", line 1748, in __init__\n    self._traceback = tf_stack.extract_stack()\n"]}]},{"cell_type":"code","metadata":{"id":"vepEQBC8w9OS","colab_type":"code","colab":{}},"source":["#-------------------------------- Load encoder and decoder paramters --------------------------------#\n","if LOAD_PRETRAIN == True:\n","    np_load_old = np.load\n","    np.load = lambda *a,**k: np_load_old(*a, **k, allow_pickle=True)\n","    load_e1_params = tl.files.load_npz(path=LOAD_PRETRAIN_DIR, name=LOAD_PRETRAIN_ENCODER1_PARAMS_NAME)\n","    tl.files.assign_params(sess, load_e1_params, net_out1)\n","    load_e2_params = tl.files.load_npz(path=LOAD_PRETRAIN_DIR, name=LOAD_PRETRAIN_ENCODER2_PARAMS_NAME)\n","    tl.files.assign_params(sess, load_e2_params, net_out2)\n","    load_g_params = tl.files.load_npz(path=LOAD_PRETRAIN_DIR, name=LOAD_PRETRAIN_DECODER_PARAMS_NAME)\n","    tl.files.assign_params(sess, load_g_params, gen0)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"R09ZDQBRUsDf","colab_type":"code","colab":{}},"source":["#-------------------------------- Make list of CelebA picture paths for data extraction --------------------------------#\n","DATA_FILES = glob(os.path.join(\"./{}\".format(DIR_FOR_UNPACKING_CELEBA_ZIP_FILE), 'img_align_celeba', \"*.jpg\"))\n","DATA_FILES = sorted(DATA_FILES)\n","DATA_FILES = np.array(DATA_FILES)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1IhWYcrMzIeq","colab_type":"code","colab":{}},"source":["#-------------------------------- Train main VAE --------------------------------#\n","if TRAIN_MAIN_VAE == True:\n","  iter_counter = 0\n","  training_start_time = time.time()\n","  for epoch in range(EPOCHS):\n","      minibatch = tl.iterate.minibatches(inputs=DATA_FILES, targets=DATA_FILES, batch_size=BATCH_SIZE, shuffle=True)\n","      idx = 0\n","      batch_idxs = len(DATA_FILES) // BATCH_SIZE\n","      while True:\n","          try:\n","              batch_files,_ = next(minibatch)\n","              batch = [\n","                get_image(batch_file, IMAGE_SIZE, is_crop=IS_CROP, resize_w=OUTPUT_SIZE, is_grayscale = 0)\n","                for batch_file in batch_files\n","              ]\n","              batch_images = np.array(batch).astype(np.float32)\n","              vae_current_lr = LEARNING_RATE\n","\n","              # update\n","              p, p1, p2, p3, kl, sse, errE, _ = sess.run([p_loss,p1_loss,p2_loss,p3_loss,KL_loss,SSE_loss,VAE_loss,vae_optim], feed_dict={input_imgs: batch_images, lr_vae:vae_current_lr})\n","              print(\n","                  \"Epoch: [%2d/%2d] [%4d/%4d] time: %4.4f, vae_loss:%.8f, kl_loss:%.8f, sse_loss:%.8f, p1_loss:%.8f, p2_loss:%.8f, p3_loss:%.8f, p_loss:%.8f\" \\\n","                  % (epoch, EPOCHS, idx, batch_idxs, time.time() - training_start_time, errE, kl, sse, p1, p2, p3, p))\n","              sys.stdout.flush()\n","\n","              # save samples\n","              if np.mod(iter_counter, CHECKPOINT_STEP) == 0:\n","                  img1, img2 = sess.run([gen2.outputs, gen3.outputs], feed_dict={input_imgs: batch_images})\n","                  save_images(img1, [8, 8], TRAINING_SAMPLES_DIR + '/{}_recon.png'.format(iter_counter))\n","                  save_images(img2, [8, 8], TRAINING_SAMPLES_DIR + '/{}_random.png'.format(iter_counter))\n","                  save_images(batch_images,[8, 8],TRAINING_SAMPLES_DIR + '/{}_input_recon.png'.format(iter_counter))\n","                  print(\"[Sample] sample generated!!!\")\n","                  sys.stdout.flush()\n","                  \n","                  # save checkpoint\n","                  tl.files.save_npz(net_out1.all_params, name=TRAINING_PARAMETERS_DIR + '/net_e1.npz', sess=sess)\n","                  tl.files.save_npz(net_out2.all_params, name=TRAINING_PARAMETERS_DIR + '/net_e2.npz', sess=sess)\n","                  tl.files.save_npz(gen0.all_params, name=TRAINING_PARAMETERS_DIR + '/net_g.npz', sess=sess)\n","                  tl.files.save_npz(net_out1.all_params, name=TRAINING_PARAMETERS_DIR + '/net_e1_{}.npz'.format(iter_counter), sess=sess)\n","                  tl.files.save_npz(net_out2.all_params, name=TRAINING_PARAMETERS_DIR + '/net_e2_{}.npz'.format(iter_counter), sess=sess)\n","                  tl.files.save_npz(gen0.all_params, name=TRAINING_PARAMETERS_DIR + '/net_g_{}.npz'.format(iter_counter), sess=sess)\n","                  print(\"[*] Saving checkpoints SUCCESS!\")\n","              if iter_counter == NO_TRAIN_STEPS:\n","                break\n","              iter_counter += 1\n","              idx += 1\n","          except StopIteration:\n","              print('one epoch finished')\n","              break\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aVdsUyrHCVBG","colab_type":"code","colab":{}},"source":["#-------------------------------- Inspect parameter values of main VAE --------------------------------#\n","#import pprint\n","#vars = tf.trainable_variables()\n","#encoder_vars = [var for var in vars if 'encoder' in var.name] \n","#decoder_vars = [var for var in vars if 'generator' in var.name]\n","#pprint.pprint(vars)\n","#print('FIRST ROW PARAMETERS IN ENCODER LAYERS')\n","#for idx, var in enumerate(vars):\n","#  if 'encoder' in var.name:\n","#    tmp = sess.run(var)\n","#    if len(tmp) == 1:\n","#      printing = tmp\n","#    else:\n","#      printing = tmp[0]\n","#    print('layer num ', idx)\n","#    print(var.name)\n","#    print(tmp)\n","#    print(' ')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Qofr5sHexqoa","colab_type":"code","colab":{}},"source":["#-------------------------------- Sample reconstruction and random samples from loaded VAE --------------------------------#\n","if SAMPLE_IMAGES == True:\n","  minibatch = tl.iterate.minibatches(inputs=DATA_FILES, targets=DATA_FILES, batch_size=BATCH_SIZE, shuffle=True)\n","  for pict_no in range(NO_SAMPLE_PICTURES):\n","    batch_files,_ = next(minibatch)\n","    batch = [\n","      get_image(batch_file, IMAGE_SIZE, is_crop=IS_CROP, resize_w=OUTPUT_SIZE, is_grayscale = 0)\n","      for batch_file in batch_files\n","    ]\n","    batch_images = np.array(batch).astype(np.float32)\n","    img_recon, img_random = sess.run([gen2.outputs, gen3.outputs], feed_dict={input_imgs: batch_images})\n","    save_images(img_recon, [8, 8], (DIR_FOR_SAMPLING+'/{}_recon.png').format(pict_no))\n","    save_images(img_random, [8, 8], (DIR_FOR_SAMPLING+'/{}_random.png').format(pict_no))\n","    sys.stdout.flush()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SVurtjylIYLo","colab_type":"code","colab":{}},"source":["#-------------------------------- Define functions for test function NN --------------------------------#\n","from tensorflow.keras.datasets import mnist\n","from tensorflow.keras.layers import Dense, Conv2D, MaxPool2D, Input, Conv2DTranspose, Flatten, Reshape\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.constraints import Constraint\n","import numpy as np\n","from numpy import save\n","\n","def loss_f(y,x):\n","    return tf.math.reduce_mean(tf.math.multiply(y,x))\n","    \n","def get_test_function(latent_dim, c, sigmoid = True):\n","    inp_layer = Input(shape=(latent_dim,))\n","    lay_1 = Dense(200, activation = 'tanh', kernel_constraint=Between(-c,c),bias_constraint=Between(-c,c))(inp_layer)\n","    lay_2 = Dense(20, activation = 'relu', kernel_constraint=Between(-c,c),bias_constraint=Between(-c,c))(lay_1)\n","    if sigmoid:\n","        out = Dense(1,activation='sigmoid',kernel_constraint=Between(-c,c),bias_constraint=Between(-c,c))(lay_2)\n","    else:\n","        out = Dense(1,kernel_constraint=Between(-c,c),bias_constraint=Between(-c,c))(lay_2)\n","    test_function = Model(inp_layer, out)\n","    test_function.compile(optimizer='adam', loss='binary_crossentropy')\n","    return test_function\n","\n","def get_test_function1(latent_dim, c, sigmoid = True):\n","    inp_layer = Input(shape=(latent_dim,))\n","    lay_1 = Dense(500, activation = 'relu', kernel_constraint=Between(-c,c),bias_constraint=Between(-c,c))(inp_layer)\n","    lay_2 = Dense(300, activation = 'relu', kernel_constraint=Between(-c,c),bias_constraint=Between(-c,c))(lay_1)\n","    lay_3 = Dense(100, activation = 'relu', kernel_constraint=Between(-c,c),bias_constraint=Between(-c,c))(lay_2)\n","    lay_4 = Dense(50, activation = 'relu', kernel_constraint=Between(-c,c),bias_constraint=Between(-c,c))(lay_3)\n","    lay_5 = Dense(10, activation = 'relu', kernel_constraint=Between(-c,c),bias_constraint=Between(-c,c))(lay_4)\n","    if sigmoid:\n","        out = Dense(1,activation='sigmoid',kernel_constraint=Between(-c,c),bias_constraint=Between(-c,c))(lay_5)\n","    else:\n","        out = Dense(1,kernel_constraint=Between(-c,c),bias_constraint=Between(-c,c))(lay_6)\n","    test_function = Model(inp_layer, out)\n","    test_function.compile(optimizer='adam', loss='binary_crossentropy')\n","    return test_function\n","\n","def get_test_function2(latent_dim, c, sigmoid = True):\n","    inp_layer = Input(shape=(latent_dim,))\n","    lay_1 = Dense(2500, activation = 'tanh')(inp_layer)\n","    lay_2 = Dense(2000, activation = 'relu')(lay_1)\n","    lay_3 = Dense(1500, activation = 'relu')(lay_2)\n","    lay_4 = Dense(1000, activation = 'relu')(lay_3)\n","    lay_5 = Dense(100, activation = 'relu')(lay_4)\n","    lay_6 = Dense(10, activation = 'relu')(lay_5)\n","    if sigmoid:\n","        out = Dense(1,activation='sigmoid')(lay_6)\n","    else:\n","        out = Dense(1)(lay_2)\n","    test_function = Model(inp_layer, out)\n","    test_function.compile(optimizer='adam', loss=loss_f)\n","    return test_function\n","\n","def get_latent_datapoints(batch_size):\n","    minibatch = tl.iterate.minibatches(inputs=DATA_FILES, targets=DATA_FILES, batch_size=batch_size, shuffle=False)\n","    idx = 0\n","    lz_means_and_vars = []\n","    while True:\n","      try:\n","        batch_files,_ = next(minibatch)\n","        batch = [\n","            get_image(batch_file, IMAGE_SIZE, is_crop=IS_CROP, resize_w=OUTPUT_SIZE, is_grayscale = 0)\n","            for batch_file in batch_files\n","        ]\n","        batch_images = np.array(batch).astype(np.float32)\n","        lz_means, lz_vars  = sess.run([z_mean, z_log_sigma_sq], feed_dict={input_imgs: batch_images})\n","        lz_means_and_vars += list(zip(lz_means.tolist(), lz_vars.tolist()))\n","        idx +=1 \n","        if idx % 150 == 0:\n","          print(idx)\n","          save(CREATE_LATENT_DATA_SAVE_DIR, np.array(lz_means_and_vars))\n","      except StopIteration:\n","          print('All latent representations saved')\n","          save(CREATE_LATENT_DATA_SAVE_DIR, np.array(lz_means_and_vars))\n","          break\n","    return lz_means_and_vars\n","\n","class Between(Constraint):\n","    def __init__(self, min_value, max_value):\n","        self.min_value = min_value\n","        self.max_value = max_value\n","\n","    def __call__(self, w):\n","        return tf.keras.backend.clip(w, self.min_value, self.max_value)\n","\n","    def get_config(self):\n","        return {'min_value': self.min_value,\n","                'max_value': self.max_value}\n","\n","def train(epochs, latent_dim, test_function, batch_size, all_latent_data):\n","  iter = 0\n","  for epoch in range(epochs):\n","    minibatch = tl.iterate.minibatches(\n","        inputs=all_latent_data,\n","        targets=all_latent_data,\n","        batch_size=batch_size,\n","        shuffle=True\n","    )\n","    while True:\n","      try:\n","        lz_param_sample, _ = next(minibatch)\n","        lz_sample = []\n","        for sample in lz_param_sample:\n","          z_mean = sample[0]\n","          z_sigma = np.sqrt(np.exp(sample[1]))\n","          normals = np.random.normal(size=z_sigma.shape)\n","          lz_sample.append((z_mean + np.multiply(z_sigma, normals)).tolist())\n","        lz_sample = np.array(lz_sample)\n","        z_sample = np.random.normal(size=(batch_size, latent_dim))\n","        y_list = np.zeros((2*batch_size,))\n","        y_list[0:batch_size] = -np.zeros((batch_size,))\n","        y_list[batch_size:] = np.ones((batch_size,))\n","        l3 = test_function.train_on_batch(x = np.concatenate((z_sample, lz_sample)), y = y_list)\n","        iter += 1\n","        print(iter)\n","        print(\"loss: {}\".format(l3))\n","        if iter % 500 == 0:\n","          test_function.save(CREATE_NEW_TEST_FUNCTION_SAVE_DIR)\n","          print(\"epoch finished: {}, loss: {}\".format(epoch, l3))\n","      except StopIteration:\n","          break\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7__ae4oiWh07","colab_type":"code","colab":{}},"source":["#-------------------------------- Actions with test function NN --------------------------------#\n","from numpy import load\n","\n","if CREATE_NEW_TEST_FUNCTION == True:\n","  test_function = get_test_function1(CREATE_NEW_TEST_FUNCTION_LATENT_DIM, 1, True)\n","if LOAD_OLD_TEST_FUNCTION == True:\n","  test_function = tf.keras.models.load_model(LOAD_OLD_TEST_FUNCTION_DIR, custom_objects={'Between': Between})\n","if CREATE_LATENT_DATA == True:\n","  all_latent_data = get_latent_datapoints(BATCH_SIZE)\n","if LOAD_OLD_LATENT_DATA == True:\n","  all_latent_data = load(LOAD_OLD_LATENT_DATA_DIR)\n","  inspect_vars = []\n","  inspect_means = []\n","  for mean_logvar in all_latent_data:\n","    means = np.exp(mean_logvar[0])\n","    vars = np.exp(mean_logvar[1])\n","    inspect_vars.append(\n","          [np.min(vars), np.mean(vars), np.max(vars)]\n","    )\n","    inspect_means.append(\n","          [np.min(means), np.mean(means), np.max(means)]\n","    )\n","  np.savetxt(DRIVE_DIR + 'latent_data_means_min_mean_max.txt', np.array(inspect_means))\n","  np.savetxt(DRIVE_DIR + 'latent_data_vars_min_mean_max.txt', np.array(inspect_vars))\n","if TRAIN_TEST_FUNCTION ==  True:\n","  train(epochs = TRAIN_TEST_FUNCTION_EPOCHS, latent_dim=CREATE_NEW_TEST_FUNCTION_LATENT_DIM, test_function = test_function, batch_size = TRAIN_TEST_FUNCTION_BATCH_SIZE, all_latent_data=all_latent_data)\n","\n","if CHECK_SOME_TEST_F_VALUES == True:\n","  minibatch = tl.iterate.minibatches(inputs=DATA_FILES, targets=DATA_FILES, batch_size=BATCH_SIZE, shuffle=False)\n","  batch_files,_ = next(minibatch)\n","  batch_pics = [\n","      get_image(batch_file, IMAGE_SIZE, is_crop=IS_CROP, resize_w=OUTPUT_SIZE, is_grayscale = 0)\n","      for batch_file in batch_files\n","  ]\n","  latent_rep_pics_mean, latent_rep_pics_logvar  = sess.run([z_mean, z_log_sigma_sq], feed_dict={input_imgs: batch_pics})\n","  normals = np.random.normal(size=latent_rep_pics_logvar.shape)\n","  latent_rep_pics_st = np.sqrt(np.exp(latent_rep_pics_logvar))\n","  latent_rep_pics = latent_rep_pics_mean + np.multiply(latent_rep_pics_st, normals)\n","  latent_rep_random = np.random.normal(size=(64,100))\n","  test_func_values_pics = test_function(latent_rep_pics).eval()\n","  test_func_values_random = test_function(latent_rep_random).eval()\n","  np.savetxt(CHECK_SOME_TEST_F_VALUES_RECON_ALPHAS, test_func_values_pics)\n","  np.savetxt(CHECK_SOME_TEST_F_VALUES_RANDOM_ALPHAS, test_func_values_random)\n","  reconstruction_pics = sess.run(gen4.outputs, feed_dict={z_custom: latent_rep_pics})\n","  reconstruction_random = sess.run(gen4.outputs, feed_dict={z_custom: latent_rep_random})\n","  save_images(reconstruction_pics, [8, 8], CHECK_SOME_TEST_F_VALUES_RECON_IMG)\n","  save_images(reconstruction_random, [8, 8], CHECK_SOME_TEST_F_VALUES_RANDOM_IMG)\n","\n","\n","\n","if SAMPLE_TEST_FUNCTION == True:\n","  def sample_f(f, a, b, samples):\n","    z_sample = sess.run(z_p, feed_dict={})\n","    alphas = test_function(z_sample).eval()\n","    good_samples = z_sample[alphas.T[0] > a]\n","    while len(good_samples) < samples:\n","        z_sample = sess.run(z_p, feed_dict={})\n","        alphas = test_function(z_sample).eval()\n","        good_samples = np.concatenate((good_samples, z_sample[alphas.T[0] > a]))\n","    bad_samples = z_sample[alphas.T[0] < b]\n","    while len(bad_samples) < samples:\n","        z_sample = sess.run(z_p, feed_dict={})\n","        alphas = test_function(z_sample).eval()\n","        bad_samples = np.concatenate((bad_samples, z_sample[alphas.T[0] < b]))\n","    return good_samples[:samples], bad_samples[:samples]\n","  good_samples, bad_samples = sample_f(test_function, SAMPLE_TEST_FUNCTION_ALPHA, SAMPLE_TEST_FUNCTION_BETA, BATCH_SIZE)\n","  good_images = sess.run(gen4.outputs, feed_dict={z_custom: good_samples})\n","  bad_images = sess.run(gen4.outputs, feed_dict={z_custom: bad_samples})\n","  save_images(good_images[:64], [8, 8], SAMPLE_TEST_FUNCTION_GOOD_IMAGES)\n","  save_images(bad_images[:64], [8, 8], SAMPLE_TEST_FUNCTION_BAD_IMAGES)\n","  good_samples_values = test_function(good_samples).eval()\n","  bad_samples_values = test_function(bad_samples).eval()\n","  np.savetxt(SAMPLE_TEST_FUNCTION_GOOD_IMAGES_ALPHAS, good_samples_values)\n","  np.savetxt(SAMPLE_TEST_FUNCTION_BAD_IMAGES_ALPHAS, bad_samples_values)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"omGpixrhhyhU","colab_type":"code","colab":{}},"source":["import itertools\n","from numpy import save\n","\n","def get_gaussian_process_path(x0, xT, samples, T):\n","    alpha = 4\n","    beta = 2.5\n","    def k(t, s):\n","        return np.exp(\n","            -beta * (np.abs(t-s) ** alpha)\n","        )\n","    times = np.linspace(0, T, samples)\n","    no_time_steps = len(times)\n","    covariances = []\n","    for item in itertools.product(times, repeat=2):\n","        covariances.append(k(*item))\n","    sigma = np.array(covariances).reshape(no_time_steps, no_time_steps)\n","    mu = np.zeros(no_time_steps)\n","\n","    tmp_mu = np.roll(mu, -1, axis=0)\n","    B = np.roll(np.eye(len(mu)), -1, axis=0)\n","    tmp_sigma = np.matmul(np.matmul(B, sigma), B.T)\n","    tmp_sigma_11 = tmp_sigma[:-2, :-2]\n","    tmp_sigma_12 = tmp_sigma[:-2, -2:]\n","    tmp_sigma_21 = tmp_sigma[-2:, :-2]\n","    tmp_sigma_22 = tmp_sigma[-2:, -2:]\n","    tmp_sigma_22_inv = np.linalg.inv(tmp_sigma_22)\n","    sigma_bar = tmp_sigma_11 - np.matmul(\n","        np.matmul(tmp_sigma_12, tmp_sigma_22_inv), tmp_sigma_21\n","    )\n","    inputs = []\n","    for start, end in zip(x0, xT):\n","        a = np.array([\n","            [end],\n","            [start]\n","        ])\n","        mu_bar = np.expand_dims(tmp_mu[:-2], axis=0).T + np.matmul(\n","            np.matmul(tmp_sigma_12, tmp_sigma_22_inv),\n","            (a - np.expand_dims(tmp_mu[-2:], axis=0).T)\n","        )\n","        mid_sample = np.random.multivariate_normal(mu_bar.T[0], sigma_bar)\n","        sample = np.append(np.append(start, mid_sample), end)\n","        inputs.append(list(sample))\n","    inputs = np.array(inputs).T\n","    return inputs\n","\n","if PERFORM_NORMAL_INTERPOLATION == True:\n","  start_pics_files = DATA_FILES[INTERPOLATION_START_PIC_IDX:(INTERPOLATION_START_PIC_IDX+BATCH_SIZE)]\n","  end_pics_files = DATA_FILES[INTERPOLATION_END_PIC_IDX:(INTERPOLATION_END_PIC_IDX+BATCH_SIZE)]\n","  start_pics = [get_image(file_name, IMAGE_SIZE, is_crop=IS_CROP, resize_w=OUTPUT_SIZE, is_grayscale = 0)\n","                for file_name in start_pics_files]\n","  end_pics = [get_image(file_name, IMAGE_SIZE, is_crop=IS_CROP, resize_w=OUTPUT_SIZE, is_grayscale = 0)\n","                for file_name in end_pics_files]\n","  start_pics_latent_reps = sess.run(z_mean, feed_dict={input_imgs: start_pics})\n","  end_pics_latent_reps = sess.run(z_mean, feed_dict={input_imgs: end_pics})\n","  latent_interpolation_paths = []\n","  for start_latent_rep, end_latent_rep in zip(start_pics_latent_reps, end_pics_latent_reps):\n","    latent_interpolation_path = get_gaussian_process_path(start_latent_rep, end_latent_rep, 8, TIME)\n","    latent_interpolation_paths += latent_interpolation_path.tolist()\n","  batcher = tl.iterate.minibatches(inputs=latent_interpolation_paths, targets=latent_interpolation_paths, batch_size=BATCH_SIZE, shuffle=False)\n","  image_no = 0\n","  while True:\n","    try:\n","      interpolation_paths_batch,_ = next(batcher)\n","      interpolation_paths = sess.run(gen4.outputs, feed_dict={z_custom: interpolation_paths_batch})\n","      save_images(interpolation_paths[:64], [8, 8], PERFORM_NORMAL_INTERPOLATION_SAMPLES_PATH.format(image_no, SAMPLE_LABEL))\n","      image_no += 1\n","    except StopIteration:\n","      break\n","\n","if PERFORM_NORMAL_INTERPOLATION_SAVE_MIDDLE:\n","  for middle_run_idx in range(PERFORM_NORMAL_INTERPOLATION_SAVE_MIDDLE_ITERS):\n","    IDX_START = np.random.choice(len(DATA_FILES) - 2 * BATCH_SIZE)\n","    IDX_END = np.random.choice(len(DATA_FILES) - 2 * BATCH_SIZE)\n","    start_pics_files = DATA_FILES[IDX_START:(IDX_START+BATCH_SIZE)]\n","    end_pics_files = DATA_FILES[IDX_END:(IDX_END+BATCH_SIZE)]\n","    start_pics = [get_image(file_name, IMAGE_SIZE, is_crop=IS_CROP, resize_w=OUTPUT_SIZE, is_grayscale = 0)\n","                  for file_name in start_pics_files]\n","    end_pics = [get_image(file_name, IMAGE_SIZE, is_crop=IS_CROP, resize_w=OUTPUT_SIZE, is_grayscale = 0)\n","                  for file_name in end_pics_files]\n","    start_pics_latent_reps = sess.run(z_mean, feed_dict={input_imgs: start_pics})\n","    end_pics_latent_reps = sess.run(z_mean, feed_dict={input_imgs: end_pics})\n","    latent_middle_reps = []\n","    for start_latent_rep, end_latent_rep in zip(start_pics_latent_reps, end_pics_latent_reps):\n","      latent_interpolation_path = get_gaussian_process_path(start_latent_rep, end_latent_rep, 8, TIME)\n","      middle = len(latent_interpolation_path) / 2\n","      idx = round(middle)\n","      latent_middle_reps += latent_interpolation_path.tolist()[idx:(idx+2)]\n","    save(PERFORM_NORMAL_INTERPOLATION_SAVE_MIDDLE_PATH + 'latent_representations/{}{}'.format(middle_run_idx, SAMPLE_LABEL), np.array(latent_middle_reps))\n","    batcher_middle_images = tl.iterate.minibatches(inputs=latent_middle_reps, targets=latent_middle_reps, batch_size=BATCH_SIZE, shuffle=False)\n","    image_no_middle = 0\n","    middle_recon_reps = []\n","    middle_vgg_reps = []\n","    while True:\n","      try:\n","        middle_batch,_ = next(batcher_middle_images)\n","        middle_images = sess.run(gen4.outputs, feed_dict={z_custom: middle_batch})\n","        middle_recon_reps += middle_images.tolist()\n","        save_images(middle_images, [8, 8], PERFORM_NORMAL_INTERPOLATION_SAVE_MIDDLE_PATH + 'recon_images/{}{}.png'.format(middle_run_idx, SAMPLE_LABEL, image_no_middle))\n","        middle_vgg_reps_batch = sess.run(l5_fid, feed_dict={input_imgs1: middle_images})\n","        middle_vgg_reps += middle_vgg_reps_batch.tolist()\n","        image_no_middle += 1\n","      except StopIteration:\n","        save(PERFORM_NORMAL_INTERPOLATION_SAVE_MIDDLE_PATH + 'recon_representations/{}{}'.format(middle_run_idx, SAMPLE_LABEL), np.array(middle_recon_reps))\n","        save(PERFORM_NORMAL_INTERPOLATION_SAVE_MIDDLE_PATH + 'vgg_representations/{}{}'.format(middle_run_idx, SAMPLE_LABEL), np.array(middle_vgg_reps))\n","        break"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"d_5Xo185Tr_S","colab_type":"code","colab":{}},"source":["import itertools\n","\n","def k(x,x_p,l):\n","    \n","    return np.exp(-1/(2*l)*(-2*np.dot(x,x_p.T) + np.square(x) + np.square(x_p).T))\n","\n","def pick_interpolation_with_shortest_jump_idx(z_list, N):\n","  max_distances = []\n","  for i in range(N):\n","    path = np.array(z_list)[:, i, :]\n","    max_distance = [np.sum(np.square(j-i)) for i, j in zip(path, path[1:])]\n","    max_distances.append(max(max_distance))\n","  max_distance_idx = max_distances.index(max(max_distances))\n","  return max_distance_idx\n","\n","def pick_interpolation_with_highest_average_f(z_list, N):\n","  f_means = []\n","  for i in range(N):\n","    path = np.array(z_list)[:, i, :]\n","    f_values = test_function.predict(path)\n","    f_means.append(np.mean(f_values[1:-1]))\n","  max_mean_idx = f_means.index(max(f_means))\n","  return max_mean_idx\n","\n","\n","def particle_filter(z_0,z_1, nr_images,N,d,l):\n","    z_0 = np.expand_dims(z_0, 0)\n","    z_1 = np.expand_dims(z_1, 0)\n","    z_list = np.zeros((nr_images,N,d))\n","    z_list_hist = np.zeros((nr_images,N,d))\n","    ancest_list = np.zeros((nr_images,N))\n","    t_list = np.array([np.linspace(0,1,nr_images)])\n","    z_list[0,:,:] = np.repeat(z_0,N,axis = 0)\n","    z_list[-1,:,:] = np.repeat(z_1,N,axis = 0)\n","    z_list_hist[0,:,:] = np.repeat(z_0,N,axis = 0)\n","    z_list_hist[-1,:,:] = np.repeat(z_1,N,axis = 0)\n","    ancest_list[0] = np.arange(0,N).reshape((N))\n","    index_c = [False for k in range(nr_images)]\n","    index_c[0] = True\n","    index_c[-1] = True\n","    sq_sq = 0.001\n","    for i in range(1,nr_images-1):\n","        z_prop = np.zeros((N,d))\n","        k_tt = k(t_list[:,i:i+1].T,t_list[:,i:i+1].T,l)\n","        k_tc = k(t_list[:,i:i+1].T,t_list[:,index_c].T,l)\n","        k_cc = k(t_list[:,index_c].T,t_list[:,index_c].T,l)\n","        SIGMA = k_tt - np.matmul(np.matmul(k_tc,np.linalg.inv(k_cc+sq_sq*np.eye(i+1))),k_tc.T)\n","        for j in range(N):\n","            m = np.matmul(np.matmul(k_tc,np.linalg.inv(k_cc+sq_sq*np.eye(i+1))),z_list[index_c,j,:])\n","            z_prop[j] = np.random.multivariate_normal(m.reshape(d),SIGMA*np.eye(d)).reshape((d))\n","        z_list[i,:,:] = z_prop\n","        z_list_hist[i,:,:] = z_prop\n","        f_list = test_function.predict([z_prop])[:,0]\n","        attempt = 0\n","        while True:\n","          f_list_p = np.power(f_list, PERFORM_PARTICLE_FILTER_INTERPOLATION_ALPHA - attempt)\n","          if np.sum(f_list_p) > 0.0001:\n","            f_list = f_list_p/(np.sum(f_list_p))\n","            break\n","          print('too high alpha', attempt)\n","          attempt += 1\n","        resample_index = np.random.choice(N,N,p = f_list)\n","        z_list[:,:,:] = z_list[:,resample_index,:]\n","        ancest_list[i,:] = resample_index\n","        index_c[i] = True\n","    return z_list, z_list_hist, ancest_list\n","\n","if PERFORM_PARTICLE_FILTER_INTERPOLATION == True:\n","  start_pics_files = DATA_FILES[INTERPOLATION_START_PIC_IDX:(INTERPOLATION_START_PIC_IDX+BATCH_SIZE)]\n","  end_pics_files = DATA_FILES[INTERPOLATION_END_PIC_IDX:(INTERPOLATION_END_PIC_IDX+BATCH_SIZE)]\n","  start_pics = [get_image(file_name, IMAGE_SIZE, is_crop=IS_CROP, resize_w=OUTPUT_SIZE, is_grayscale = 0)\n","                for file_name in start_pics_files]\n","  end_pics = [get_image(file_name, IMAGE_SIZE, is_crop=IS_CROP, resize_w=OUTPUT_SIZE, is_grayscale = 0)\n","                for file_name in end_pics_files]\n","  start_pics_latent_reps = sess.run(z_mean, feed_dict={input_imgs: start_pics})\n","  end_pics_latent_reps = sess.run(z_mean, feed_dict={input_imgs: end_pics})\n","  latent_interpolation_paths = []\n","  for start_latent_rep, end_latent_rep in zip(start_pics_latent_reps, end_pics_latent_reps):\n","    latent_interpolation_path, _, _ = particle_filter(start_latent_rep, end_latent_rep, 8, 1000, 100, 0.1)\n","    best_idx = pick_interpolation_with_highest_average_f(latent_interpolation_path, 1000)\n","    latent_interpolation_paths += latent_interpolation_path[:, best_idx, :].tolist()\n","  batcher = tl.iterate.minibatches(inputs=latent_interpolation_paths, targets=latent_interpolation_paths, batch_size=BATCH_SIZE, shuffle=False)\n","  image_no = 0\n","  while True:\n","    try:\n","      interpolation_paths_batch,_ = next(batcher)\n","      interpolation_paths = sess.run(gen4.outputs, feed_dict={z_custom: interpolation_paths_batch})\n","      save_images(interpolation_paths[:64], [8, 8], PERFORM_PARTICLE_FILTER_INTERPOLATION_SAMPLES_PATH.format(image_no, SAMPLE_LABEL))\n","      image_no += 1\n","    except StopIteration:\n","      break\n","\n","if PERFORM_PARTICLE_FILTER_INTERPOLATION_SAVE_MIDDLE:\n","  for middle_run_idx in range(PERFORM_PARTICLE_FILTER_INTERPOLATION_SAVE_MIDDLE_ITERS):\n","    print(middle_run_idx)\n","    IDX_START = np.random.choice(len(DATA_FILES) - 2 * BATCH_SIZE)\n","    IDX_END = np.random.choice(len(DATA_FILES) - 2 * BATCH_SIZE)\n","    start_pics_files = DATA_FILES[IDX_START:(IDX_START+BATCH_SIZE)]\n","    end_pics_files = DATA_FILES[IDX_END:(IDX_END+BATCH_SIZE)]\n","    start_pics = [get_image(file_name, IMAGE_SIZE, is_crop=IS_CROP, resize_w=OUTPUT_SIZE, is_grayscale = 0)\n","                  for file_name in start_pics_files]\n","    end_pics = [get_image(file_name, IMAGE_SIZE, is_crop=IS_CROP, resize_w=OUTPUT_SIZE, is_grayscale = 0)\n","                  for file_name in end_pics_files]\n","    start_pics_latent_reps = sess.run(z_mean, feed_dict={input_imgs: start_pics})\n","    end_pics_latent_reps = sess.run(z_mean, feed_dict={input_imgs: end_pics})\n","    latent_middle_reps = []\n","    for start_latent_rep, end_latent_rep in zip(start_pics_latent_reps, end_pics_latent_reps):\n","      latent_interpolation_path, _, _ = particle_filter(start_latent_rep, end_latent_rep, 8, 1000, 100, 0.1)\n","      print('particle filter done')\n","      best_idx = pick_interpolation_with_highest_average_f(latent_interpolation_path, 1000)\n","      latent_interpolation_path = latent_interpolation_path[:, best_idx, :].tolist()\n","      middle = len(latent_interpolation_path) / 2\n","      idx = round(middle)\n","      latent_middle_reps += latent_interpolation_path[idx:(idx+2)]\n","    save(PERFORM_PARTICLE_FILTER_INTERPOLATION_SAVE_MIDDLE_PATH + 'latent_representations/{}{}'.format(middle_run_idx, SAMPLE_LABEL), np.array(latent_middle_reps))\n","    batcher_middle_images = tl.iterate.minibatches(inputs=latent_middle_reps, targets=latent_middle_reps, batch_size=BATCH_SIZE, shuffle=False)\n","    image_no_middle = 0\n","    middle_recon_reps = []\n","    middle_vgg_reps = []\n","    while True:\n","      try:\n","        middle_batch,_ = next(batcher_middle_images)\n","        middle_images = sess.run(gen4.outputs, feed_dict={z_custom: middle_batch})\n","        middle_recon_reps += middle_images.tolist()\n","        save_images(middle_images, [8, 8], PERFORM_PARTICLE_FILTER_INTERPOLATION_SAVE_MIDDLE_PATH + 'recon_images/{}{}.png'.format(middle_run_idx, SAMPLE_LABEL, image_no_middle))\n","        middle_vgg_reps_batch = sess.run(l5_fid, feed_dict={input_imgs1: middle_images})\n","        print(middle_vgg_reps_batch.shape)\n","        middle_vgg_reps += middle_vgg_reps_batch.tolist()\n","        image_no_middle += 1\n","      except StopIteration:\n","        save(PERFORM_PARTICLE_FILTER_INTERPOLATION_SAVE_MIDDLE_PATH + 'recon_representations/{}{}'.format(middle_run_idx, SAMPLE_LABEL), np.array(middle_recon_reps))\n","        save(PERFORM_PARTICLE_FILTER_INTERPOLATION_SAVE_MIDDLE_PATH + 'vgg_representations/{}{}'.format(middle_run_idx, SAMPLE_LABEL), np.array(middle_vgg_reps))\n","        break"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Bb7NaZQscWNv","colab_type":"code","colab":{}},"source":["def create_linear_path(start, end, samples):\n","    direction = end - start\n","    times = np.linspace(0, 1, samples)\n","    direction_step = direction\n","    path = []\n","    for t in times:\n","        path.append(start + t * direction_step)\n","    return np.array(path)\n","\n","if PERFORM_LINEAR_INTERPOLATION == True:\n","  start_pics_files = DATA_FILES[INTERPOLATION_START_PIC_IDX:(INTERPOLATION_START_PIC_IDX+BATCH_SIZE)]\n","  end_pics_files = DATA_FILES[INTERPOLATION_END_PIC_IDX:(INTERPOLATION_END_PIC_IDX+BATCH_SIZE)]\n","  start_pics = [get_image(file_name, IMAGE_SIZE, is_crop=IS_CROP, resize_w=OUTPUT_SIZE, is_grayscale = 0)\n","                for file_name in start_pics_files]\n","  end_pics = [get_image(file_name, IMAGE_SIZE, is_crop=IS_CROP, resize_w=OUTPUT_SIZE, is_grayscale = 0)\n","                for file_name in end_pics_files]\n","  start_pics_latent_reps = sess.run(z_mean, feed_dict={input_imgs: start_pics})\n","  end_pics_latent_reps = sess.run(z_mean, feed_dict={input_imgs: end_pics})\n","  latent_interpolation_paths = []\n","  for start_latent_rep, end_latent_rep in zip(start_pics_latent_reps, end_pics_latent_reps):\n","    latent_interpolation_path = create_linear_path(start_latent_rep, end_latent_rep, 8)\n","    latent_interpolation_paths += latent_interpolation_path.tolist()\n","  batcher = tl.iterate.minibatches(inputs=latent_interpolation_paths, targets=latent_interpolation_paths, batch_size=BATCH_SIZE, shuffle=False)\n","  image_no = 0\n","  while True:\n","    try:\n","      interpolation_paths_batch,_ = next(batcher)\n","      interpolation_paths = sess.run(gen4.outputs, feed_dict={z_custom: interpolation_paths_batch})\n","      save_images(interpolation_paths[:64], [8, 8], PERFORM_LINEAR_INTERPOLATION_SAMPLES_PATH.format(image_no, SAMPLE_LABEL))\n","      image_no += 1\n","    except StopIteration:\n","      break\n","\n","if PERFORM_LINEAR_INTERPOLATION_SAVE_MIDDLE:\n","  for middle_run_idx in range(PERFORM_LINEAR_INTERPOLATION_SAVE_MIDDLE_ITERS):\n","    IDX_START = np.random.choice(len(DATA_FILES) - 2 * BATCH_SIZE)\n","    IDX_END = np.random.choice(len(DATA_FILES) - 2 * BATCH_SIZE)\n","    start_pics_files = DATA_FILES[IDX_START:(IDX_START+BATCH_SIZE)]\n","    end_pics_files = DATA_FILES[IDX_END:(IDX_END+BATCH_SIZE)]\n","    start_pics = [get_image(file_name, IMAGE_SIZE, is_crop=IS_CROP, resize_w=OUTPUT_SIZE, is_grayscale = 0)\n","                  for file_name in start_pics_files]\n","    end_pics = [get_image(file_name, IMAGE_SIZE, is_crop=IS_CROP, resize_w=OUTPUT_SIZE, is_grayscale = 0)\n","                  for file_name in end_pics_files]\n","    start_pics_latent_reps = sess.run(z_mean, feed_dict={input_imgs: start_pics})\n","    end_pics_latent_reps = sess.run(z_mean, feed_dict={input_imgs: end_pics})\n","    latent_middle_reps = []\n","    for start_latent_rep, end_latent_rep in zip(start_pics_latent_reps, end_pics_latent_reps):\n","      latent_interpolation_path = create_linear_path(start_latent_rep, end_latent_rep, 8)\n","      middle = len(latent_interpolation_path) / 2\n","      idx = round(middle)\n","      latent_middle_reps += latent_interpolation_path.tolist()[idx:(idx+2)]\n","    save(PERFORM_LINEAR_INTERPOLATION_SAVE_MIDDLE_PATH + 'latent_representations/{}{}'.format(middle_run_idx, SAMPLE_LABEL), np.array(latent_middle_reps))\n","    batcher_middle_images = tl.iterate.minibatches(inputs=latent_middle_reps, targets=latent_middle_reps, batch_size=BATCH_SIZE, shuffle=False)\n","    image_no_middle = 0\n","    middle_recon_reps = []\n","    while True:\n","      try:\n","        middle_batch,_ = next(batcher_middle_images)\n","        middle_images = sess.run(gen4.outputs, feed_dict={z_custom: middle_batch})\n","        middle_recon_reps += middle_images.tolist()\n","        save_images(middle_images, [8, 8], PERFORM_LINEAR_INTERPOLATION_SAVE_MIDDLE_PATH + 'recon_images/{}{}.png'.format(middle_run_idx, SAMPLE_LABEL, image_no_middle))\n","        middle_vgg_reps_batch = sess.run(l5_fid, feed_dict={input_imgs1: middle_images})\n","        middle_vgg_reps += middle_vgg_reps_batch.tolist()        \n","        image_no_middle += 1\n","      except StopIteration:\n","        save(PERFORM_LINEAR_INTERPOLATION_SAVE_MIDDLE_PATH + 'recon_representations/{}{}'.format(middle_run_idx, SAMPLE_LABEL), np.array(middle_recon_reps))\n","        save(PERFORM_LINEAR_INTERPOLATION_SAVE_MIDDLE_PATH + 'vgg_representations/{}{}'.format(middle_run_idx, SAMPLE_LABEL), np.array(middle_vgg_reps))\n","        break"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fO8m1jsTU5WW","colab_type":"code","colab":{}},"source":["\n","if GET_SAMPLE_OF_VGG_REPS_ORIGINAL_DATA:\n","  minibatch = tl.iterate.minibatches(inputs=DATA_FILES, targets=DATA_FILES, batch_size=BATCH_SIZE, shuffle=True)\n","  for iter in range(GET_SAMPLE_OF_VGG_REPS_ORIGINAL_DATA_ITER):\n","    batch_files,_ = next(minibatch)\n","    batch = [\n","      get_image(batch_file, IMAGE_SIZE, is_crop=IS_CROP, resize_w=OUTPUT_SIZE, is_grayscale = 0)\n","      for batch_file in batch_files\n","    ]\n","    batch_images = np.array(batch).astype(np.float32)\n","    middle_vgg_reps_batch = sess.run(l5_fid, feed_dict={input_imgs1: batch_images})\n","    save((GET_SAMPLE_OF_VGG_REPS_ORIGINAL_DATA_SAVE_PATH + '{}').format(iter), np.array(middle_vgg_reps_batch))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"einoH1SdA4Pi","colab_type":"code","colab":{}},"source":["CALCULATE_WASSERSTEIN_DISTANCE = True\n","WASSERSTEIN_REAL_DIRECTORY = '/content/drive/My Drive/VaeOnCelebA/dfc_real_data_representations/vgg_representations/'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FHFR-EYAOYHC","colab_type":"code","colab":{}},"source":["from numpy import load\n","from os import listdir\n","if CALCULATE_WASSERSTEIN_DISTANCE:\n","  real_vgg_data = []\n","  file_names = listdir(WASSERSTEIN_REAL_DIRECTORY)\n","  for file_name in file_names[:78]:\n","    print(file_name)\n","    real_vgg_data += load(WASSERSTEIN_REAL_DIRECTORY + file_name).tolist()\n","  import pdb\n","  pdb.set_trace()\n","  real_vgg_data = np.array([obs.flatten().tolist() for obs in np.array(real_vgg_data)])\n","  real_cov = numpy.cov(real_vgg_data, rowvar=False)\n","  real_mean = numpy.mean(real_vgg_data, axis=0)\n","  for dir in WASSERSTEIN_FAKE_DIRECTORIES:\n","    fake_vgg_data = []\n","    file_names = listdir(dir)\n","    for file_name in file_names:\n","      fake_vgg_data += load(dir + file_name).tolist()\n","    fake_vgg_data = np.array([obs.flatten().tolist() for obs in np.array(fake_vgg_data)])\n","    fake_cov = numpy.cov(real_vgg_data, rowvar=False)\n","    fake_mean = numpy.mean(real_vgg_data, axis=0)\n","\n","    wassterstein_mean = np.linalg.norm(fake_mean, real_mean)**2\n","    wassterstein_cov = numpy.trace(\n","      fake_cov + real_cov - 2 * numpy.linalg.sqrtm(numpy.matmul(fake_cov, real_cov))\n","    )\n","    wasserstein = wassterstein_mean + wassterstein_cov\n","    print(wasserstein)\n","\n","  \n"],"execution_count":null,"outputs":[]}]}