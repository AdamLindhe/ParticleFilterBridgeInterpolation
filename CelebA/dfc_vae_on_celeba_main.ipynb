{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"dfc_vae_on_celeba_main.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1Hg4wzSm0PtA_oPMdiadk_FcMMikVyj3r","authorship_tag":"ABX9TyOalG6U9hZcb/SlEeQZoQTA"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"tdVrX0VRpfw9","colab_type":"text"},"source":["\n","\n","Install dependencies and download data. Extract zipped data\n","\n"]},{"cell_type":"code","metadata":{"id":"zntfsa00pgmF","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":663},"executionInfo":{"status":"ok","timestamp":1593360604337,"user_tz":-120,"elapsed":82824,"user":{"displayName":"carl ringqvist","photoUrl":"","userId":"02526215521042317496"}},"outputId":"90a9913e-8449-4adc-cb1e-d92e969d5da4"},"source":["!pip3 install tensorlayer==1.7.1\n","!pip install scipy==1.1.0\n","!mkdir data_faces\n","#!mkdir data_faces && wget https://s3-us-west-1.amazonaws.com/udacity-dlnfd/datasets/celeba.zip\n","#with zipfile.ZipFile(\"celeba.zip\",\"r\") as zip_ref:\n","#  zip_ref.extractall(\"data_faces/\")\n","from google.colab import drive\n","drive.mount('/content/drive')\n","import zipfile\n","with zipfile.ZipFile(\"/content/drive/My Drive/VaeOnCelebA/celeba.zip\",\"r\") as zip_ref:\n","  zip_ref.extractall(\"data_faces/\")"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Collecting tensorlayer==1.7.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/46/b2/10003c598077fe1034d565a1a6a15a9eea56e4e921b8999ffb3bb67b7b39/tensorlayer-1.7.1.zip (257kB)\n","\r\u001b[K     |█▎                              | 10kB 18.0MB/s eta 0:00:01\r\u001b[K     |██▌                             | 20kB 4.5MB/s eta 0:00:01\r\u001b[K     |███▉                            | 30kB 5.8MB/s eta 0:00:01\r\u001b[K     |█████                           | 40kB 6.0MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 51kB 5.1MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 61kB 5.7MB/s eta 0:00:01\r\u001b[K     |█████████                       | 71kB 6.2MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 81kB 6.2MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 92kB 6.5MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 102kB 6.8MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 112kB 6.8MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 122kB 6.8MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 133kB 6.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 143kB 6.8MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 153kB 6.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 163kB 6.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 174kB 6.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 184kB 6.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 194kB 6.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 204kB 6.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 215kB 6.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 225kB 6.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 235kB 6.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 245kB 6.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 256kB 6.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 266kB 6.8MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from tensorlayer==1.7.1) (1.18.5)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from tensorlayer==1.7.1) (1.4.1)\n","Requirement already satisfied: scikit-image in /usr/local/lib/python3.6/dist-packages (from tensorlayer==1.7.1) (0.16.2)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from tensorlayer==1.7.1) (3.2.2)\n","Requirement already satisfied: pillow>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->tensorlayer==1.7.1) (7.0.0)\n","Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->tensorlayer==1.7.1) (1.1.1)\n","Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->tensorlayer==1.7.1) (2.4)\n","Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->tensorlayer==1.7.1) (2.4.1)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->tensorlayer==1.7.1) (2.8.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->tensorlayer==1.7.1) (0.10.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->tensorlayer==1.7.1) (1.2.0)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->tensorlayer==1.7.1) (2.4.7)\n","Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=2.0->scikit-image->tensorlayer==1.7.1) (4.4.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.1->matplotlib->tensorlayer==1.7.1) (1.12.0)\n","Building wheels for collected packages: tensorlayer\n","  Building wheel for tensorlayer (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for tensorlayer: filename=tensorlayer-1.7.1-cp36-none-any.whl size=256475 sha256=448774ecda29b94e4159dcf9aae58a414481826b7cacd6b77ddc63976c102747\n","  Stored in directory: /root/.cache/pip/wheels/f9/c0/50/7e910fcbcd85d3de5c0504bd3d4d3fc5425c72b096bd310b45\n","Successfully built tensorlayer\n","Installing collected packages: tensorlayer\n","Successfully installed tensorlayer-1.7.1\n","Collecting scipy==1.1.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a8/0b/f163da98d3a01b3e0ef1cab8dd2123c34aee2bafbb1c5bffa354cc8a1730/scipy-1.1.0-cp36-cp36m-manylinux1_x86_64.whl (31.2MB)\n","\u001b[K     |████████████████████████████████| 31.2MB 101kB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python3.6/dist-packages (from scipy==1.1.0) (1.18.5)\n","\u001b[31mERROR: umap-learn 0.4.4 has requirement scipy>=1.3.1, but you'll have scipy 1.1.0 which is incompatible.\u001b[0m\n","\u001b[31mERROR: tensorflow 2.2.0 has requirement scipy==1.4.1; python_version >= \"3\", but you'll have scipy 1.1.0 which is incompatible.\u001b[0m\n","\u001b[31mERROR: plotnine 0.6.0 has requirement scipy>=1.2.0, but you'll have scipy 1.1.0 which is incompatible.\u001b[0m\n","\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n","Installing collected packages: scipy\n","  Found existing installation: scipy 1.4.1\n","    Uninstalling scipy-1.4.1:\n","      Successfully uninstalled scipy-1.4.1\n","Successfully installed scipy-1.1.0\n","Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"FC1Mxcyypm7d","colab_type":"text"},"source":["Import necessary packages, mount google drive and import necessary auxiliary python files"]},{"cell_type":"code","metadata":{"id":"19Hgmo9ipxc-","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":102},"executionInfo":{"status":"ok","timestamp":1593360619497,"user_tz":-120,"elapsed":7912,"user":{"displayName":"carl ringqvist","photoUrl":"","userId":"02526215521042317496"}},"outputId":"a4094f10-38d3-42c5-f753-6079fc306fdd"},"source":["import os\n","import scipy.misc\n","import pprint\n","import numpy as np\n","import time\n","import sys\n","sys.path.append('/content/drive/My Drive/VaeOnCelebA/')\n","import math\n","%tensorflow_version 1.x\n","import tensorflow as tf\n","import tensorlayer as tl\n","from tensorlayer.layers import *\n","from glob import glob\n","from random import shuffle\n","from google.colab import files\n","from utils import *\n","from vgg_loss import *"],"execution_count":2,"outputs":[{"output_type":"stream","text":["TensorFlow 1.x selected.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorlayer/layers.py:28: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorlayer/layers.py:4056: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"9TASmGfiqAjX","colab_type":"text"},"source":["Check that GPU is found. Make sure to enable GPU under \"edit\""]},{"cell_type":"code","metadata":{"id":"QlAVEsTiVhu6","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1593360623905,"user_tz":-120,"elapsed":2655,"user":{"displayName":"carl ringqvist","photoUrl":"","userId":"02526215521042317496"}},"outputId":"828db8eb-49fe-459a-d768-59c1aa0cd022"},"source":["device_name = tf.test.gpu_device_name()\n","print(device_name)"],"execution_count":3,"outputs":[{"output_type":"stream","text":["/device:GPU:0\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"YnpUTrSQqGVQ","colab_type":"text"},"source":["Setup model parameters"]},{"cell_type":"code","metadata":{"id":"cFITsk7arWry","colab_type":"code","colab":{}},"source":["os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n","os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CjCQmy4Lrec-","colab_type":"code","colab":{}},"source":["flags = tf.app.flags\n","flags.DEFINE_integer(\"epoch\", 50, \"Epoch to train [5]\") \n","flags.DEFINE_float(\"learning_rate\", 0.0005, \"Learning rate of for adam [0.001]\")\n","flags.DEFINE_float(\"beta1\", 0.5, \"Momentum term of adam [0.5]\")\n","flags.DEFINE_integer(\"train_size\", 40000000000000, \"The size of train images [np.inf]\")\n","flags.DEFINE_integer(\"batch_size\", 64, \"The number of batch images [64]\")\n","flags.DEFINE_integer(\"image_size\", 148, \"The size of image to use (will be center cropped) [108]\")\n","flags.DEFINE_integer(\"output_size\", 64, \"The size of the output images to produce [64]\")\n","flags.DEFINE_integer(\"sample_size\", 64, \"The number of sample images [64]\")\n","flags.DEFINE_integer(\"c_dim\", 3, \"Dimension of image color. [3]\")\n","flags.DEFINE_integer(\"z_dim\", 100, \"Dimension of latent representation vector from. [2048]\")\n","flags.DEFINE_integer(\"sample_step\", 900, \"The interval of generating sample. [300]\")\n","flags.DEFINE_integer(\"save_step\", 900, \"The interval of saveing checkpoints. [500]\")\n","flags.DEFINE_string(\"dataset\", \"celebA\", \"The name of dataset [celebA]\")\n","flags.DEFINE_string(\"test_name\", \"dfc_vae3\", \"The number of experiment [test2]\")\n","flags.DEFINE_string(\"checkpoint_dir\", \"parameters_dfc\", \"Directory name to save the checkpoints [checkpoint]\")\n","flags.DEFINE_string(\"sample_dir\", \"samples_dfc\", \"Directory name to save the image samples [samples]\")\n","flags.DEFINE_boolean(\"is_train\", False, \"True for training, False for testing [False]\")\n","flags.DEFINE_boolean(\"is_crop\", True, \"True for training, False for testing [False]\")\n","flags.DEFINE_boolean(\"load_pretrain\",True, \"Default to False;If start training on a pretrained net, choose True\")\n","FLAGS = flags.FLAGS\n","samples_dir = FLAGS['sample_dir'].value + \"/\" + FLAGS['test_name'].value\n","parameters_dir = FLAGS['checkpoint_dir'].value + \"/\" + FLAGS['test_name'].value\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"i_rEoMYqyQsq","colab_type":"code","colab":{}},"source":["\n","def encoder(input_imgs, is_train = True, reuse = False):\n","    '''\n","    input_imgs: the input images to be encoded into a vector as latent representation. size here is [b_size,64,64,3]\n","    '''\n","    z_dim = FLAGS['z_dim'].value # 100\n","    ef_dim = 32 # encoder filter number\n","\n","    w_init = tf.random_normal_initializer(stddev=0.02)\n","    gamma_init = tf.random_normal_initializer(1., 0.02)\n","\n","    with tf.variable_scope(\"encoder\", reuse = reuse):\n","        tl.layers.set_name_reuse(reuse)\n","\n","        net_in = InputLayer(input_imgs, name='en/in') # (b_size,64,64,3)\n","        net_h0 = Conv2d(net_in, ef_dim, (4, 4), (2, 2), act=None,\n","                padding='SAME', W_init=w_init, name='en/h0/conv2d')\n","        net_h0 = BatchNormLayer(net_h0, act=lambda x: tl.act.lrelu(x, 0.2),\n","                is_train=is_train, gamma_init=gamma_init, name='en/h0/batch_norm')\n","\n","        net_h1 = Conv2d(net_h0, ef_dim*2, (4, 4), (2, 2), act=None,\n","                padding='SAME', W_init=w_init, name='en/h1/conv2d')\n","        net_h1 = BatchNormLayer(net_h1, act=lambda x: tl.act.lrelu(x, 0.2),\n","                is_train=is_train, gamma_init=gamma_init, name='en/h1/batch_norm')\n","\n","        net_h2 = Conv2d(net_h1, ef_dim*4, (4, 4), (2, 2), act=None,\n","                padding='SAME', W_init=w_init, name='en/h2/conv2d')\n","        net_h2 = BatchNormLayer(net_h2, act=lambda x: tl.act.lrelu(x, 0.2),\n","                is_train=is_train, gamma_init=gamma_init, name='en/h2/batch_norm')\n","\n","        net_h3 = Conv2d(net_h2, ef_dim*8, (4, 4), (2, 2), act=None,\n","                padding='SAME', W_init=w_init, name='en/h3/conv2d')\n","        net_h3 = BatchNormLayer(net_h3, act=lambda x: tl.act.lrelu(x, 0.2),\n","                is_train=is_train, gamma_init=gamma_init, name='en/h3/batch_norm')\n","\n","        # mean of z\n","        net_h4 = FlattenLayer(net_h3, name='en/h4/flatten')\n","        net_out1 = DenseLayer(net_h4, n_units=z_dim, act=tf.identity,\n","                W_init = w_init, name='en/out1/lin_sigmoid')\n","        z_mean = net_out1.outputs # (b_size,100)\n","\n","        # log of variance of z(covariance matrix is diagonal)\n","        net_h5 = FlattenLayer(net_h3, name='en/h5/flatten')\n","        net_out2 = DenseLayer(net_h5, n_units=z_dim, act=tf.identity,\n","                W_init = w_init, name='en/out2/lin_sigmoid')\n","        z_log_sigma_sq = net_out2.outputs + 1e-6\n","\n","    return net_out1, net_out2, z_mean, z_log_sigma_sq\n","\n","def generator(inputs, is_train = True, reuse = False):\n","    image_size = FLAGS['output_size'].value # 64 the output size of generator\n","    s2, s4, s8, s16 = int(image_size/2), int(image_size/4), int(image_size/8), int(image_size/16) # 32,16,8,4\n","    gf_dim = 32\n","    c_dim = FLAGS['c_dim'].value # n_color 3\n","    batch_size = FLAGS['batch_size'].value # 64\n","\n","    w_init = tf.random_normal_initializer(stddev=0.02)\n","    gamma_init = tf.random_normal_initializer(1., 0.02)\n","\n","    with tf.variable_scope(\"generator\", reuse = reuse):\n","        tl.layers.set_name_reuse(reuse)\n","\n","        net_in = InputLayer(inputs, name='g/in')\n","        net_h0 = DenseLayer(net_in, n_units=gf_dim*8*s16*s16, W_init=w_init,\n","                act = tf.identity, name='g/h0/lin')\n","        net_h0 = ReshapeLayer(net_h0, shape=[-1, s16, s16, gf_dim*8], name='g/h0/reshape')\n","        net_h0 = BatchNormLayer(net_h0, act=lambda x: tl.act.lrelu(x, 0.2), is_train=is_train,\n","                gamma_init=gamma_init, name='g/h0/batch_norm')\n","\n","        # upsampling\n","        net_h1 = UpSampling2dLayer(net_h0, size=[8, 8], is_scale=False, method=1, \n","                                    align_corners=False, name='g/h1/upsample2d')\n","        net_h1 = Conv2d(net_h1, gf_dim*4, (3, 3), (1, 1), padding='SAME', W_init=w_init, name='g/h1/conv2d')\n","        net_h1 = BatchNormLayer(net_h1, act=lambda x: tl.act.lrelu(x, 0.2), is_train=is_train,\n","                gamma_init=gamma_init, name='g/h1/batch_norm')\n","\n","        net_h2 = UpSampling2dLayer(net_h1, size=[16, 16], is_scale=False, method=1, \n","                                    align_corners=False, name='g/h2/upsample2d')\n","        net_h2 = Conv2d(net_h2, gf_dim*2, (3, 3), (1, 1), padding='SAME', W_init=w_init, name='g/h2/conv2d')\n","        net_h2 = BatchNormLayer(net_h2, act=lambda x: tl.act.lrelu(x, 0.2), is_train=is_train,\n","                gamma_init=gamma_init, name='g/h2/batch_norm')\n","\n","        net_h3 = UpSampling2dLayer(net_h2, size=[32, 32], is_scale=False, method=1, \n","                                    align_corners=False, name='g/h3/upsample2d')\n","        net_h3 = Conv2d(net_h3, gf_dim, (3, 3), (1, 1), padding='SAME', W_init=w_init, name='g/h3/conv2d')\n","        net_h3 = BatchNormLayer(net_h3, act=lambda x: tl.act.lrelu(x, 0.2), is_train=is_train,\n","                gamma_init=gamma_init, name='g/h3/batch_norm')\n","        net_h4 = UpSampling2dLayer(net_h3, size=[64, 64], is_scale=False, method=1, \n","                                    align_corners=False, name='g/h4/upsample2d')\n","        net_h4 = Conv2d(net_h4, c_dim, (3, 3), (1, 1), padding='SAME', W_init=w_init, name='g/h4/conv2d')\n","        logits = net_h4.outputs\n","        net_h4.outputs = tf.nn.tanh(net_h4.outputs)\n","    return net_h4, logits"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gREFh2e-qsAb","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1593190022808,"user_tz":-120,"elapsed":3793,"user":{"displayName":"carl ringqvist","photoUrl":"","userId":"02526215521042317496"}},"outputId":"44c8a696-d57f-4eba-b6fd-7c40a62fad4c"},"source":["\n","with tf.device(\"/gpu:0\"):\n","  ##========================= DEFINE MODEL ===========================##\n","  # The input_imgs are input for both encoder and discriminator\n","  input_imgs = tf.placeholder(tf.float32,[FLAGS['batch_size'].value, FLAGS['output_size'].value, \n","      FLAGS['output_size'].value, FLAGS['c_dim'].value], name='real_images')\n","\n","  # Normal distribution for generator\n","  z_p = tf.random_normal(shape=(FLAGS['batch_size'].value, FLAGS['z_dim'].value), mean=0.0, stddev=1.0)\n","  # Normal distribution for reparameterization trick\n","  eps = tf.random_normal(shape=(FLAGS['batch_size'].value, FLAGS['z_dim'].value), mean=0.0, stddev=1.0)\n","  lr_vae = tf.placeholder(tf.float32, shape=[])\n","\n","  # ----------------------encoder----------------------\n","  net_out1, net_out2, z_mean, z_log_sigma_sq = encoder(input_imgs, is_train=True, reuse=False)\n","\n","  # ----------------------decoder----------------------\n","  # decode z \n","  # z = z_mean + z_sigma * eps\n","  z = tf.add(z_mean, tf.multiply(tf.sqrt(tf.exp(z_log_sigma_sq)), eps)) # using reparameterization tricks\n","  gen0, gen0_logits = generator(z, is_train=True, reuse=False) # reconstruction\n","\n","  # ----------------------vgg net--------------------------\n","  vgg1_input = tf.image.resize_images(input_imgs,[224,224])\n","  net_in_real = InputLayer(vgg1_input, name='input1')\n","  conv1,l1_r,l2_r,l3_r,_,_ = conv_layers_simple_api(net_in_real, reuse=False)\n","  vgg1 = fc_layers(conv1,reuse=False)\n","\n","  vgg2_input = tf.image.resize_images(gen0.outputs,[224,224])\n","  net_in_fake = InputLayer(vgg2_input, name='input2')\n","  conv2,l1,l2,l3,_,_ = conv_layers_simple_api(net_in_fake, reuse=True)\n","  vgg2 = fc_layers(conv2,reuse=True)\n","\n","\n","  # ----------------------for samples----------------------\n","  gen2, gen2_logits = generator(z, is_train=False, reuse=True)\n","  gen3, gen3_logits = generator(z_p, is_train=False, reuse=True)\n","  z_custom = tf.placeholder(tf.float32, [FLAGS['batch_size'].value, FLAGS['z_dim'].value], name='z_custom')\n","  gen4, gen3_logits = generator(z_custom, is_train=False, reuse=True)\n","\n","  ##========================= DEFINE TRAIN OPS =======================##\n","\n","  SSE_loss = tf.reduce_mean(tf.reduce_sum(tf.square(gen0.outputs - input_imgs),[1,2,3]))\n","  print(SSE_loss.get_shape(),type(SSE_loss))\n","\n","  # perceptual loss in feature space in VGG net\n","  p1_loss = tf.reduce_mean(tf.reduce_sum(tf.square(l1 - l1_r), [1,2,3]))\n","  p2_loss = tf.reduce_mean(tf.reduce_sum(tf.square(l2 - l2_r), [1,2,3]))\n","  p3_loss = tf.reduce_mean(tf.reduce_sum(tf.square(l3 - l3_r), [1,2,3]))\n","  p_loss = p1_loss + p2_loss + p3_loss\n","\n","  # train_vae\n","  KL_loss = tf.reduce_mean(- 0.5 * tf.reduce_sum(1 + z_log_sigma_sq - tf.square(z_mean) - tf.exp(z_log_sigma_sq),1))\n","  print(KL_loss.get_shape(), type(KL_loss))\n","\n","  ### important points! ###\n","  style_content_weight = 3e-5 # you may need to tweak this weight for a different dataset\n","  VAE_loss = KL_loss + style_content_weight*p_loss\n","\n","  e_vars = tl.layers.get_variables_with_name('encoder',True,True)\n","  g_vars = tl.layers.get_variables_with_name('generator', True, True)\n","  vae_vars = e_vars + g_vars\n","\n","  print(\"-------encoder-------\")\n","  net_out1.print_params(False)\n","  print(\"-------generator-------\")\n","  gen0.print_params(False)\n","\n","\n","  # optimizers for updating encoder and generator\n","  vae_optim = tf.train.AdamOptimizer(lr_vae, beta1=FLAGS['beta1'].value) \\\n","                      .minimize(VAE_loss, var_list=vae_vars)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorlayer/layers.py:288: The name tf.get_variable_scope is deprecated. Please use tf.compat.v1.get_variable_scope instead.\n","\n","  [TL] InputLayer  encoder/en/in: (64, 64, 64, 3)\n","  [TL] Conv2dLayer encoder/en/h0/conv2d: shape:[4, 4, 3, 32] strides:[1, 2, 2, 1] pad:SAME act:identity\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorlayer/layers.py:1385: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n","\n","  [TL] BatchNormLayer encoder/en/h0/batch_norm: decay:0.900000 epsilon:0.000010 act:<lambda> is_train:True\n","  [TL] Conv2dLayer encoder/en/h1/conv2d: shape:[4, 4, 32, 64] strides:[1, 2, 2, 1] pad:SAME act:identity\n","  [TL] BatchNormLayer encoder/en/h1/batch_norm: decay:0.900000 epsilon:0.000010 act:<lambda> is_train:True\n","  [TL] Conv2dLayer encoder/en/h2/conv2d: shape:[4, 4, 64, 128] strides:[1, 2, 2, 1] pad:SAME act:identity\n","  [TL] BatchNormLayer encoder/en/h2/batch_norm: decay:0.900000 epsilon:0.000010 act:<lambda> is_train:True\n","  [TL] Conv2dLayer encoder/en/h3/conv2d: shape:[4, 4, 128, 256] strides:[1, 2, 2, 1] pad:SAME act:identity\n","  [TL] BatchNormLayer encoder/en/h3/batch_norm: decay:0.900000 epsilon:0.000010 act:<lambda> is_train:True\n","  [TL] FlattenLayer encoder/en/h4/flatten: 4096\n","  [TL] DenseLayer  encoder/en/out1/lin_sigmoid: 100 identity\n","  [TL] FlattenLayer encoder/en/h5/flatten: 4096\n","  [TL] DenseLayer  encoder/en/out2/lin_sigmoid: 100 identity\n","  [TL] InputLayer  generator/g/in: (64, 100)\n","  [TL] DenseLayer  generator/g/h0/lin: 4096 identity\n","  [TL] ReshapeLayer generator/g/h0/reshape: (64, 4, 4, 256)\n","  [TL] BatchNormLayer generator/g/h0/batch_norm: decay:0.900000 epsilon:0.000010 act:<lambda> is_train:True\n","  [TL] UpSampling2dLayer g/h1/upsample2d: is_scale:False size:[8, 8] method:1 align_corners:False\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorlayer/layers.py:1670: The name tf.image.resize_images is deprecated. Please use tf.image.resize instead.\n","\n","  [TL] Conv2dLayer generator/g/h1/conv2d: shape:[3, 3, 256, 128] strides:[1, 1, 1, 1] pad:SAME act:identity\n","  [TL] BatchNormLayer generator/g/h1/batch_norm: decay:0.900000 epsilon:0.000010 act:<lambda> is_train:True\n","  [TL] UpSampling2dLayer g/h2/upsample2d: is_scale:False size:[16, 16] method:1 align_corners:False\n","  [TL] Conv2dLayer generator/g/h2/conv2d: shape:[3, 3, 128, 64] strides:[1, 1, 1, 1] pad:SAME act:identity\n","  [TL] BatchNormLayer generator/g/h2/batch_norm: decay:0.900000 epsilon:0.000010 act:<lambda> is_train:True\n","  [TL] UpSampling2dLayer g/h3/upsample2d: is_scale:False size:[32, 32] method:1 align_corners:False\n","  [TL] Conv2dLayer generator/g/h3/conv2d: shape:[3, 3, 64, 32] strides:[1, 1, 1, 1] pad:SAME act:identity\n","  [TL] BatchNormLayer generator/g/h3/batch_norm: decay:0.900000 epsilon:0.000010 act:<lambda> is_train:True\n","  [TL] UpSampling2dLayer g/h4/upsample2d: is_scale:False size:[64, 64] method:1 align_corners:False\n","  [TL] Conv2dLayer generator/g/h4/conv2d: shape:[3, 3, 32, 3] strides:[1, 1, 1, 1] pad:SAME act:identity\n","  [TL] InputLayer  input1: (64, 224, 224, 3)\n","  [TL] Conv2dLayer vgg_conv/conv1_1: shape:[3, 3, 3, 64] strides:[1, 1, 1, 1] pad:SAME act:relu\n","  [TL] Conv2dLayer vgg_conv/conv1_2: shape:[3, 3, 64, 64] strides:[1, 1, 1, 1] pad:SAME act:relu\n","  [TL] PoolLayer   vgg_conv/pool1: ksize:[1, 2, 2, 1] strides:[1, 2, 2, 1] padding:SAME pool:max_pool\n","  [TL] Conv2dLayer vgg_conv/conv2_1: shape:[3, 3, 64, 128] strides:[1, 1, 1, 1] pad:SAME act:relu\n","  [TL] Conv2dLayer vgg_conv/conv2_2: shape:[3, 3, 128, 128] strides:[1, 1, 1, 1] pad:SAME act:relu\n","  [TL] PoolLayer   vgg_conv/pool2: ksize:[1, 2, 2, 1] strides:[1, 2, 2, 1] padding:SAME pool:max_pool\n","  [TL] Conv2dLayer vgg_conv/conv3_1: shape:[3, 3, 128, 256] strides:[1, 1, 1, 1] pad:SAME act:relu\n","  [TL] Conv2dLayer vgg_conv/conv3_2: shape:[3, 3, 256, 256] strides:[1, 1, 1, 1] pad:SAME act:relu\n","  [TL] Conv2dLayer vgg_conv/conv3_3: shape:[3, 3, 256, 256] strides:[1, 1, 1, 1] pad:SAME act:relu\n","  [TL] PoolLayer   vgg_conv/pool3: ksize:[1, 2, 2, 1] strides:[1, 2, 2, 1] padding:SAME pool:max_pool\n","  [TL] Conv2dLayer vgg_conv/conv4_1: shape:[3, 3, 256, 512] strides:[1, 1, 1, 1] pad:SAME act:relu\n","  [TL] Conv2dLayer vgg_conv/conv4_2: shape:[3, 3, 512, 512] strides:[1, 1, 1, 1] pad:SAME act:relu\n","  [TL] Conv2dLayer vgg_conv/conv4_3: shape:[3, 3, 512, 512] strides:[1, 1, 1, 1] pad:SAME act:relu\n","  [TL] PoolLayer   vgg_conv/pool4: ksize:[1, 2, 2, 1] strides:[1, 2, 2, 1] padding:SAME pool:max_pool\n","  [TL] Conv2dLayer vgg_conv/conv5_1: shape:[3, 3, 512, 512] strides:[1, 1, 1, 1] pad:SAME act:relu\n","  [TL] Conv2dLayer vgg_conv/conv5_2: shape:[3, 3, 512, 512] strides:[1, 1, 1, 1] pad:SAME act:relu\n","  [TL] Conv2dLayer vgg_conv/conv5_3: shape:[3, 3, 512, 512] strides:[1, 1, 1, 1] pad:SAME act:relu\n","  [TL] PoolLayer   vgg_conv/pool5: ksize:[1, 2, 2, 1] strides:[1, 2, 2, 1] padding:SAME pool:max_pool\n","  [TL] FlattenLayer vgg_fc/flatten: 25088\n","  [TL] DenseLayer  vgg_fc/fc1_relu: 4096 relu\n","  [TL] DenseLayer  vgg_fc/fc2_relu: 4096 relu\n","  [TL] DenseLayer  vgg_fc/fc3_relu: 1000 identity\n","  [TL] InputLayer  input2: (64, 224, 224, 3)\n","  [TL] Conv2dLayer vgg_conv/conv1_1: shape:[3, 3, 3, 64] strides:[1, 1, 1, 1] pad:SAME act:relu\n","  [TL] Conv2dLayer vgg_conv/conv1_2: shape:[3, 3, 64, 64] strides:[1, 1, 1, 1] pad:SAME act:relu\n","  [TL] PoolLayer   vgg_conv/pool1: ksize:[1, 2, 2, 1] strides:[1, 2, 2, 1] padding:SAME pool:max_pool\n","  [TL] Conv2dLayer vgg_conv/conv2_1: shape:[3, 3, 64, 128] strides:[1, 1, 1, 1] pad:SAME act:relu\n","  [TL] Conv2dLayer vgg_conv/conv2_2: shape:[3, 3, 128, 128] strides:[1, 1, 1, 1] pad:SAME act:relu\n","  [TL] PoolLayer   vgg_conv/pool2: ksize:[1, 2, 2, 1] strides:[1, 2, 2, 1] padding:SAME pool:max_pool\n","  [TL] Conv2dLayer vgg_conv/conv3_1: shape:[3, 3, 128, 256] strides:[1, 1, 1, 1] pad:SAME act:relu\n","  [TL] Conv2dLayer vgg_conv/conv3_2: shape:[3, 3, 256, 256] strides:[1, 1, 1, 1] pad:SAME act:relu\n","  [TL] Conv2dLayer vgg_conv/conv3_3: shape:[3, 3, 256, 256] strides:[1, 1, 1, 1] pad:SAME act:relu\n","  [TL] PoolLayer   vgg_conv/pool3: ksize:[1, 2, 2, 1] strides:[1, 2, 2, 1] padding:SAME pool:max_pool\n","  [TL] Conv2dLayer vgg_conv/conv4_1: shape:[3, 3, 256, 512] strides:[1, 1, 1, 1] pad:SAME act:relu\n","  [TL] Conv2dLayer vgg_conv/conv4_2: shape:[3, 3, 512, 512] strides:[1, 1, 1, 1] pad:SAME act:relu\n","  [TL] Conv2dLayer vgg_conv/conv4_3: shape:[3, 3, 512, 512] strides:[1, 1, 1, 1] pad:SAME act:relu\n","  [TL] PoolLayer   vgg_conv/pool4: ksize:[1, 2, 2, 1] strides:[1, 2, 2, 1] padding:SAME pool:max_pool\n","  [TL] Conv2dLayer vgg_conv/conv5_1: shape:[3, 3, 512, 512] strides:[1, 1, 1, 1] pad:SAME act:relu\n","  [TL] Conv2dLayer vgg_conv/conv5_2: shape:[3, 3, 512, 512] strides:[1, 1, 1, 1] pad:SAME act:relu\n","  [TL] Conv2dLayer vgg_conv/conv5_3: shape:[3, 3, 512, 512] strides:[1, 1, 1, 1] pad:SAME act:relu\n","  [TL] PoolLayer   vgg_conv/pool5: ksize:[1, 2, 2, 1] strides:[1, 2, 2, 1] padding:SAME pool:max_pool\n","  [TL] FlattenLayer vgg_fc/flatten: 25088\n","  [TL] DenseLayer  vgg_fc/fc1_relu: 4096 relu\n","  [TL] DenseLayer  vgg_fc/fc2_relu: 4096 relu\n","  [TL] DenseLayer  vgg_fc/fc3_relu: 1000 identity\n","  [TL] InputLayer  generator/g/in: (64, 100)\n","  [TL] DenseLayer  generator/g/h0/lin: 4096 identity\n","  [TL] ReshapeLayer generator/g/h0/reshape: (64, 4, 4, 256)\n","  [TL] BatchNormLayer generator/g/h0/batch_norm: decay:0.900000 epsilon:0.000010 act:<lambda> is_train:False\n","  [TL] UpSampling2dLayer g/h1/upsample2d: is_scale:False size:[8, 8] method:1 align_corners:False\n","  [TL] Conv2dLayer generator/g/h1/conv2d: shape:[3, 3, 256, 128] strides:[1, 1, 1, 1] pad:SAME act:identity\n","  [TL] BatchNormLayer generator/g/h1/batch_norm: decay:0.900000 epsilon:0.000010 act:<lambda> is_train:False\n","  [TL] UpSampling2dLayer g/h2/upsample2d: is_scale:False size:[16, 16] method:1 align_corners:False\n","  [TL] Conv2dLayer generator/g/h2/conv2d: shape:[3, 3, 128, 64] strides:[1, 1, 1, 1] pad:SAME act:identity\n","  [TL] BatchNormLayer generator/g/h2/batch_norm: decay:0.900000 epsilon:0.000010 act:<lambda> is_train:False\n","  [TL] UpSampling2dLayer g/h3/upsample2d: is_scale:False size:[32, 32] method:1 align_corners:False\n","  [TL] Conv2dLayer generator/g/h3/conv2d: shape:[3, 3, 64, 32] strides:[1, 1, 1, 1] pad:SAME act:identity\n","  [TL] BatchNormLayer generator/g/h3/batch_norm: decay:0.900000 epsilon:0.000010 act:<lambda> is_train:False\n","  [TL] UpSampling2dLayer g/h4/upsample2d: is_scale:False size:[64, 64] method:1 align_corners:False\n","  [TL] Conv2dLayer generator/g/h4/conv2d: shape:[3, 3, 32, 3] strides:[1, 1, 1, 1] pad:SAME act:identity\n","  [TL] InputLayer  generator/g/in: (64, 100)\n","  [TL] DenseLayer  generator/g/h0/lin: 4096 identity\n","  [TL] ReshapeLayer generator/g/h0/reshape: (64, 4, 4, 256)\n","  [TL] BatchNormLayer generator/g/h0/batch_norm: decay:0.900000 epsilon:0.000010 act:<lambda> is_train:False\n","  [TL] UpSampling2dLayer g/h1/upsample2d: is_scale:False size:[8, 8] method:1 align_corners:False\n","  [TL] Conv2dLayer generator/g/h1/conv2d: shape:[3, 3, 256, 128] strides:[1, 1, 1, 1] pad:SAME act:identity\n","  [TL] BatchNormLayer generator/g/h1/batch_norm: decay:0.900000 epsilon:0.000010 act:<lambda> is_train:False\n","  [TL] UpSampling2dLayer g/h2/upsample2d: is_scale:False size:[16, 16] method:1 align_corners:False\n","  [TL] Conv2dLayer generator/g/h2/conv2d: shape:[3, 3, 128, 64] strides:[1, 1, 1, 1] pad:SAME act:identity\n","  [TL] BatchNormLayer generator/g/h2/batch_norm: decay:0.900000 epsilon:0.000010 act:<lambda> is_train:False\n","  [TL] UpSampling2dLayer g/h3/upsample2d: is_scale:False size:[32, 32] method:1 align_corners:False\n","  [TL] Conv2dLayer generator/g/h3/conv2d: shape:[3, 3, 64, 32] strides:[1, 1, 1, 1] pad:SAME act:identity\n","  [TL] BatchNormLayer generator/g/h3/batch_norm: decay:0.900000 epsilon:0.000010 act:<lambda> is_train:False\n","  [TL] UpSampling2dLayer g/h4/upsample2d: is_scale:False size:[64, 64] method:1 align_corners:False\n","  [TL] Conv2dLayer generator/g/h4/conv2d: shape:[3, 3, 32, 3] strides:[1, 1, 1, 1] pad:SAME act:identity\n","  [TL] InputLayer  generator/g/in: (64, 100)\n","  [TL] DenseLayer  generator/g/h0/lin: 4096 identity\n","  [TL] ReshapeLayer generator/g/h0/reshape: (64, 4, 4, 256)\n","  [TL] BatchNormLayer generator/g/h0/batch_norm: decay:0.900000 epsilon:0.000010 act:<lambda> is_train:False\n","  [TL] UpSampling2dLayer g/h1/upsample2d: is_scale:False size:[8, 8] method:1 align_corners:False\n","  [TL] Conv2dLayer generator/g/h1/conv2d: shape:[3, 3, 256, 128] strides:[1, 1, 1, 1] pad:SAME act:identity\n","  [TL] BatchNormLayer generator/g/h1/batch_norm: decay:0.900000 epsilon:0.000010 act:<lambda> is_train:False\n","  [TL] UpSampling2dLayer g/h2/upsample2d: is_scale:False size:[16, 16] method:1 align_corners:False\n","  [TL] Conv2dLayer generator/g/h2/conv2d: shape:[3, 3, 128, 64] strides:[1, 1, 1, 1] pad:SAME act:identity\n","  [TL] BatchNormLayer generator/g/h2/batch_norm: decay:0.900000 epsilon:0.000010 act:<lambda> is_train:False\n","  [TL] UpSampling2dLayer g/h3/upsample2d: is_scale:False size:[32, 32] method:1 align_corners:False\n","  [TL] Conv2dLayer generator/g/h3/conv2d: shape:[3, 3, 64, 32] strides:[1, 1, 1, 1] pad:SAME act:identity\n","  [TL] BatchNormLayer generator/g/h3/batch_norm: decay:0.900000 epsilon:0.000010 act:<lambda> is_train:False\n","  [TL] UpSampling2dLayer g/h4/upsample2d: is_scale:False size:[64, 64] method:1 align_corners:False\n","  [TL] Conv2dLayer generator/g/h4/conv2d: shape:[3, 3, 32, 3] strides:[1, 1, 1, 1] pad:SAME act:identity\n","() <class 'tensorflow.python.framework.ops.Tensor'>\n","() <class 'tensorflow.python.framework.ops.Tensor'>\n","  [*] geting variables with encoder\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorlayer/layers.py:169: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n","\n","  got   0: encoder/en/h0/conv2d/W_conv2d:0   (4, 4, 3, 32)\n","  got   1: encoder/en/h0/conv2d/b_conv2d:0   (32,)\n","  got   2: encoder/en/h0/batch_norm/beta:0   (32,)\n","  got   3: encoder/en/h0/batch_norm/gamma:0   (32,)\n","  got   4: encoder/en/h1/conv2d/W_conv2d:0   (4, 4, 32, 64)\n","  got   5: encoder/en/h1/conv2d/b_conv2d:0   (64,)\n","  got   6: encoder/en/h1/batch_norm/beta:0   (64,)\n","  got   7: encoder/en/h1/batch_norm/gamma:0   (64,)\n","  got   8: encoder/en/h2/conv2d/W_conv2d:0   (4, 4, 64, 128)\n","  got   9: encoder/en/h2/conv2d/b_conv2d:0   (128,)\n","  got  10: encoder/en/h2/batch_norm/beta:0   (128,)\n","  got  11: encoder/en/h2/batch_norm/gamma:0   (128,)\n","  got  12: encoder/en/h3/conv2d/W_conv2d:0   (4, 4, 128, 256)\n","  got  13: encoder/en/h3/conv2d/b_conv2d:0   (256,)\n","  got  14: encoder/en/h3/batch_norm/beta:0   (256,)\n","  got  15: encoder/en/h3/batch_norm/gamma:0   (256,)\n","  got  16: encoder/en/out1/lin_sigmoid/W:0   (4096, 100)\n","  got  17: encoder/en/out1/lin_sigmoid/b:0   (100,)\n","  got  18: encoder/en/out2/lin_sigmoid/W:0   (4096, 100)\n","  got  19: encoder/en/out2/lin_sigmoid/b:0   (100,)\n","  [*] geting variables with generator\n","  got   0: generator/g/h0/lin/W:0   (100, 4096)\n","  got   1: generator/g/h0/lin/b:0   (4096,)\n","  got   2: generator/g/h0/batch_norm/beta:0   (256,)\n","  got   3: generator/g/h0/batch_norm/gamma:0   (256,)\n","  got   4: generator/g/h1/conv2d/W_conv2d:0   (3, 3, 256, 128)\n","  got   5: generator/g/h1/conv2d/b_conv2d:0   (128,)\n","  got   6: generator/g/h1/batch_norm/beta:0   (128,)\n","  got   7: generator/g/h1/batch_norm/gamma:0   (128,)\n","  got   8: generator/g/h2/conv2d/W_conv2d:0   (3, 3, 128, 64)\n","  got   9: generator/g/h2/conv2d/b_conv2d:0   (64,)\n","  got  10: generator/g/h2/batch_norm/beta:0   (64,)\n","  got  11: generator/g/h2/batch_norm/gamma:0   (64,)\n","  got  12: generator/g/h3/conv2d/W_conv2d:0   (3, 3, 64, 32)\n","  got  13: generator/g/h3/conv2d/b_conv2d:0   (32,)\n","  got  14: generator/g/h3/batch_norm/beta:0   (32,)\n","  got  15: generator/g/h3/batch_norm/gamma:0   (32,)\n","  got  16: generator/g/h4/conv2d/W_conv2d:0   (3, 3, 32, 3)\n","  got  17: generator/g/h4/conv2d/b_conv2d:0   (3,)\n","-------encoder-------\n","  param   0: encoder/en/h0/conv2d/W_conv2d:0 (4, 4, 3, 32)      float32_ref\n","  param   1: encoder/en/h0/conv2d/b_conv2d:0 (32,)              float32_ref\n","  param   2: encoder/en/h0/batch_norm/beta:0 (32,)              float32_ref\n","  param   3: encoder/en/h0/batch_norm/gamma:0 (32,)              float32_ref\n","  param   4: encoder/en/h0/batch_norm/moving_mean:0 (32,)              float32_ref\n","  param   5: encoder/en/h0/batch_norm/moving_variance:0 (32,)              float32_ref\n","  param   6: encoder/en/h1/conv2d/W_conv2d:0 (4, 4, 32, 64)     float32_ref\n","  param   7: encoder/en/h1/conv2d/b_conv2d:0 (64,)              float32_ref\n","  param   8: encoder/en/h1/batch_norm/beta:0 (64,)              float32_ref\n","  param   9: encoder/en/h1/batch_norm/gamma:0 (64,)              float32_ref\n","  param  10: encoder/en/h1/batch_norm/moving_mean:0 (64,)              float32_ref\n","  param  11: encoder/en/h1/batch_norm/moving_variance:0 (64,)              float32_ref\n","  param  12: encoder/en/h2/conv2d/W_conv2d:0 (4, 4, 64, 128)    float32_ref\n","  param  13: encoder/en/h2/conv2d/b_conv2d:0 (128,)             float32_ref\n","  param  14: encoder/en/h2/batch_norm/beta:0 (128,)             float32_ref\n","  param  15: encoder/en/h2/batch_norm/gamma:0 (128,)             float32_ref\n","  param  16: encoder/en/h2/batch_norm/moving_mean:0 (128,)             float32_ref\n","  param  17: encoder/en/h2/batch_norm/moving_variance:0 (128,)             float32_ref\n","  param  18: encoder/en/h3/conv2d/W_conv2d:0 (4, 4, 128, 256)    float32_ref\n","  param  19: encoder/en/h3/conv2d/b_conv2d:0 (256,)             float32_ref\n","  param  20: encoder/en/h3/batch_norm/beta:0 (256,)             float32_ref\n","  param  21: encoder/en/h3/batch_norm/gamma:0 (256,)             float32_ref\n","  param  22: encoder/en/h3/batch_norm/moving_mean:0 (256,)             float32_ref\n","  param  23: encoder/en/h3/batch_norm/moving_variance:0 (256,)             float32_ref\n","  param  24: encoder/en/out1/lin_sigmoid/W:0 (4096, 100)        float32_ref\n","  param  25: encoder/en/out1/lin_sigmoid/b:0 (100,)             float32_ref\n","  num of params: 1101764\n","-------generator-------\n","  param   0: generator/g/h0/lin/W:0 (100, 4096)        float32_ref\n","  param   1: generator/g/h0/lin/b:0 (4096,)            float32_ref\n","  param   2: generator/g/h0/batch_norm/beta:0 (256,)             float32_ref\n","  param   3: generator/g/h0/batch_norm/gamma:0 (256,)             float32_ref\n","  param   4: generator/g/h0/batch_norm/moving_mean:0 (256,)             float32_ref\n","  param   5: generator/g/h0/batch_norm/moving_variance:0 (256,)             float32_ref\n","  param   6: generator/g/h1/conv2d/W_conv2d:0 (3, 3, 256, 128)    float32_ref\n","  param   7: generator/g/h1/conv2d/b_conv2d:0 (128,)             float32_ref\n","  param   8: generator/g/h1/batch_norm/beta:0 (128,)             float32_ref\n","  param   9: generator/g/h1/batch_norm/gamma:0 (128,)             float32_ref\n","  param  10: generator/g/h1/batch_norm/moving_mean:0 (128,)             float32_ref\n","  param  11: generator/g/h1/batch_norm/moving_variance:0 (128,)             float32_ref\n","  param  12: generator/g/h2/conv2d/W_conv2d:0 (3, 3, 128, 64)    float32_ref\n","  param  13: generator/g/h2/conv2d/b_conv2d:0 (64,)              float32_ref\n","  param  14: generator/g/h2/batch_norm/beta:0 (64,)              float32_ref\n","  param  15: generator/g/h2/batch_norm/gamma:0 (64,)              float32_ref\n","  param  16: generator/g/h2/batch_norm/moving_mean:0 (64,)              float32_ref\n","  param  17: generator/g/h2/batch_norm/moving_variance:0 (64,)              float32_ref\n","  param  18: generator/g/h3/conv2d/W_conv2d:0 (3, 3, 64, 32)     float32_ref\n","  param  19: generator/g/h3/conv2d/b_conv2d:0 (32,)              float32_ref\n","  param  20: generator/g/h3/batch_norm/beta:0 (32,)              float32_ref\n","  param  21: generator/g/h3/batch_norm/gamma:0 (32,)              float32_ref\n","  param  22: generator/g/h3/batch_norm/moving_mean:0 (32,)              float32_ref\n","  param  23: generator/g/h3/batch_norm/moving_variance:0 (32,)              float32_ref\n","  param  24: generator/g/h4/conv2d/W_conv2d:0 (3, 3, 32, 3)      float32_ref\n","  param  25: generator/g/h4/conv2d/b_conv2d:0 (3,)               float32_ref\n","  num of params: 803779\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"vepEQBC8w9OS","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1593190067827,"user_tz":-120,"elapsed":41053,"user":{"displayName":"carl ringqvist","photoUrl":"","userId":"02526215521042317496"}},"outputId":"8aac40fb-92bd-4f56-fd08-f6d3133c2964"},"source":["sess = tf.InteractiveSession()\n","tl.layers.initialize_global_variables(sess)\n","\n","np_load_old = np.load\n","np.load = lambda *a,**k: np_load_old(*a, **k, allow_pickle=True)\n","if FLAGS['load_pretrain'].value == True:\n","    params_e = '/net_e_47700.npz'\n","    # params_e = '/net_e_28800.npz'\n","    # params_e = '/net_e.npz'\n","    load_e_params = tl.files.load_npz(path='/content/drive/My Drive/VaeOnCelebA/{}'.format('parameters_dfc_saved/dfc_vae3'), name=params_e)\n","    tl.files.assign_params(sess, load_e_params[:24], net_out1)\n","    net_out1.print_params(True)\n","    tl.files.assign_params(sess, np.concatenate((load_e_params[:24], load_e_params[30:]), axis=0), net_out2)\n","    net_out2.print_params(True)\n","    params_g = '/net_g_47700.npz'\n","    # params_g = '/net_g_28800.npz'\n","    # params_g = '/net_g.npz'\n","    load_g_params = tl.files.load_npz(path='/content/drive/My Drive/VaeOnCelebA/{}'.format('parameters_dfc_saved/dfc_vae3'),name=params_g)\n","    tl.files.assign_params(sess, load_g_params, gen0)\n","    gen0.print_params(True)\n","\n","npz = np.load('/content/drive/My Drive/VaeOnCelebA/vgg16_weights.npz')\n","params = []\n","for val in sorted( npz.items() ):\n","    print(\"  Loading %s\" % str(val[1].shape))\n","    params.append(val[1])\n","tl.files.assign_params(sess, params, vgg1)\n","tl.files.assign_params(sess, params, vgg2)\n","\n","# get the list of absolute paths of all images in dataset\n","data_files = glob(os.path.join(\"./data_faces\", 'img_align_celeba', \"*.jpg\"))\n","data_files = sorted(data_files)\n","data_files = np.array(data_files) # for tl.iterate.minibatches"],"execution_count":null,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorlayer/layers.py:261: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n","\n","  param   0: encoder/en/h0/conv2d/W_conv2d:0 (4, 4, 3, 32)      float32_ref (mean: -0.0010348871583119035, median: -0.00022342856391333044, std: 0.09539403766393661)   \n","  param   1: encoder/en/h0/conv2d/b_conv2d:0 (32,)              float32_ref (mean: 0.0288563035428524, median: 0.016868282109498978, std: 0.1034720242023468)   \n","  param   2: encoder/en/h0/batch_norm/beta:0 (32,)              float32_ref (mean: 0.013506166636943817, median: -0.011837906204164028, std: 0.23832306265830994)   \n","  param   3: encoder/en/h0/batch_norm/gamma:0 (32,)              float32_ref (mean: 0.9678258895874023, median: 0.970708966255188 , std: 0.15168710052967072)   \n","  param   4: encoder/en/h0/batch_norm/moving_mean:0 (32,)              float32_ref (mean: 0.0106828473508358, median: 0.00660718884319067, std: 0.15391750633716583)   \n","  param   5: encoder/en/h0/batch_norm/moving_variance:0 (32,)              float32_ref (mean: 0.15614748001098633, median: 0.11551205813884735, std: 0.16005170345306396)   \n","  param   6: encoder/en/h1/conv2d/W_conv2d:0 (4, 4, 32, 64)     float32_ref (mean: -0.010328831151127815, median: -0.0064933584071695805, std: 0.09776859730482101)   \n","  param   7: encoder/en/h1/conv2d/b_conv2d:0 (64,)              float32_ref (mean: 0.0010600726818665862, median: -0.004627396818250418, std: 0.07493037730455399)   \n","  param   8: encoder/en/h1/batch_norm/beta:0 (64,)              float32_ref (mean: -0.27327221632003784, median: -0.25875452160835266, std: 0.3061051368713379)   \n","  param   9: encoder/en/h1/batch_norm/gamma:0 (64,)              float32_ref (mean: 0.9480381011962891, median: 0.9520637392997742, std: 0.08592520654201508)   \n","  param  10: encoder/en/h1/batch_norm/moving_mean:0 (64,)              float32_ref (mean: -1.4570797681808472, median: -1.361228346824646, std: 1.7884048223495483)   \n","  param  11: encoder/en/h1/batch_norm/moving_variance:0 (64,)              float32_ref (mean: 6.830615520477295 , median: 6.200140476226807 , std: 3.7150323390960693)   \n","  param  12: encoder/en/h2/conv2d/W_conv2d:0 (4, 4, 64, 128)    float32_ref (mean: -0.007364343386143446, median: -0.006293101701885462, std: 0.10057768225669861)   \n","  param  13: encoder/en/h2/conv2d/b_conv2d:0 (128,)             float32_ref (mean: -0.0016916688764467835, median: -0.007781974971294403, std: 0.06442044675350189)   \n","  param  14: encoder/en/h2/batch_norm/beta:0 (128,)             float32_ref (mean: -0.26168495416641235, median: -0.2649593949317932, std: 0.16497670114040375)   \n","  param  15: encoder/en/h2/batch_norm/gamma:0 (128,)             float32_ref (mean: 0.9721896648406982, median: 0.9638823866844177, std: 0.0801878497004509)   \n","  param  16: encoder/en/h2/batch_norm/moving_mean:0 (128,)             float32_ref (mean: -1.2257506847381592, median: -1.3465604782104492, std: 1.4841227531433105)   \n","  param  17: encoder/en/h2/batch_norm/moving_variance:0 (128,)             float32_ref (mean: 7.174709320068359 , median: 6.961310386657715 , std: 2.490288734436035 )   \n","  param  18: encoder/en/h3/conv2d/W_conv2d:0 (4, 4, 128, 256)    float32_ref (mean: -0.010787254199385643, median: -0.008241860195994377, std: 0.1032361164689064)   \n","  param  19: encoder/en/h3/conv2d/b_conv2d:0 (256,)             float32_ref (mean: 0.004883896559476852, median: 0.003622682299464941, std: 0.04305277764797211)   \n","  param  20: encoder/en/h3/batch_norm/beta:0 (256,)             float32_ref (mean: -0.05402348190546036, median: -0.051802683621644974, std: 0.018132012337446213)   \n","  param  21: encoder/en/h3/batch_norm/gamma:0 (256,)             float32_ref (mean: 0.10053925216197968, median: 0.09931810200214386, std: 0.015341624617576599)   \n","  param  22: encoder/en/h3/batch_norm/moving_mean:0 (256,)             float32_ref (mean: -2.878495693206787, median: -2.948676109313965, std: 1.283917784690857 )   \n","  param  23: encoder/en/h3/batch_norm/moving_variance:0 (256,)             float32_ref (mean: 20.23468780517578 , median: 19.521095275878906, std: 5.446348667144775 )   \n","  param  24: encoder/en/out1/lin_sigmoid/W:0 (4096, 100)        float32_ref (mean: -6.0104568547103554e-05, median: -8.979820995591581e-05, std: 0.019965864717960358)   \n","  param  25: encoder/en/out1/lin_sigmoid/b:0 (100,)             float32_ref (mean: 0.0               , median: 0.0               , std: 0.0               )   \n","  num of params: 1101764\n","  param   0: encoder/en/h0/conv2d/W_conv2d:0 (4, 4, 3, 32)      float32_ref (mean: -0.0010348871583119035, median: -0.00022342856391333044, std: 0.09539403766393661)   \n","  param   1: encoder/en/h0/conv2d/b_conv2d:0 (32,)              float32_ref (mean: 0.0288563035428524, median: 0.016868282109498978, std: 0.1034720242023468)   \n","  param   2: encoder/en/h0/batch_norm/beta:0 (32,)              float32_ref (mean: 0.013506166636943817, median: -0.011837906204164028, std: 0.23832306265830994)   \n","  param   3: encoder/en/h0/batch_norm/gamma:0 (32,)              float32_ref (mean: 0.9678258895874023, median: 0.970708966255188 , std: 0.15168710052967072)   \n","  param   4: encoder/en/h0/batch_norm/moving_mean:0 (32,)              float32_ref (mean: 0.0106828473508358, median: 0.00660718884319067, std: 0.15391750633716583)   \n","  param   5: encoder/en/h0/batch_norm/moving_variance:0 (32,)              float32_ref (mean: 0.15614748001098633, median: 0.11551205813884735, std: 0.16005170345306396)   \n","  param   6: encoder/en/h1/conv2d/W_conv2d:0 (4, 4, 32, 64)     float32_ref (mean: -0.010328831151127815, median: -0.0064933584071695805, std: 0.09776859730482101)   \n","  param   7: encoder/en/h1/conv2d/b_conv2d:0 (64,)              float32_ref (mean: 0.0010600726818665862, median: -0.004627396818250418, std: 0.07493037730455399)   \n","  param   8: encoder/en/h1/batch_norm/beta:0 (64,)              float32_ref (mean: -0.27327221632003784, median: -0.25875452160835266, std: 0.3061051368713379)   \n","  param   9: encoder/en/h1/batch_norm/gamma:0 (64,)              float32_ref (mean: 0.9480381011962891, median: 0.9520637392997742, std: 0.08592520654201508)   \n","  param  10: encoder/en/h1/batch_norm/moving_mean:0 (64,)              float32_ref (mean: -1.4570797681808472, median: -1.361228346824646, std: 1.7884048223495483)   \n","  param  11: encoder/en/h1/batch_norm/moving_variance:0 (64,)              float32_ref (mean: 6.830615520477295 , median: 6.200140476226807 , std: 3.7150323390960693)   \n","  param  12: encoder/en/h2/conv2d/W_conv2d:0 (4, 4, 64, 128)    float32_ref (mean: -0.007364343386143446, median: -0.006293101701885462, std: 0.10057768225669861)   \n","  param  13: encoder/en/h2/conv2d/b_conv2d:0 (128,)             float32_ref (mean: -0.0016916688764467835, median: -0.007781974971294403, std: 0.06442044675350189)   \n","  param  14: encoder/en/h2/batch_norm/beta:0 (128,)             float32_ref (mean: -0.26168495416641235, median: -0.2649593949317932, std: 0.16497670114040375)   \n","  param  15: encoder/en/h2/batch_norm/gamma:0 (128,)             float32_ref (mean: 0.9721896648406982, median: 0.9638823866844177, std: 0.0801878497004509)   \n","  param  16: encoder/en/h2/batch_norm/moving_mean:0 (128,)             float32_ref (mean: -1.2257506847381592, median: -1.3465604782104492, std: 1.4841227531433105)   \n","  param  17: encoder/en/h2/batch_norm/moving_variance:0 (128,)             float32_ref (mean: 7.174709320068359 , median: 6.961310386657715 , std: 2.490288734436035 )   \n","  param  18: encoder/en/h3/conv2d/W_conv2d:0 (4, 4, 128, 256)    float32_ref (mean: -0.010787254199385643, median: -0.008241860195994377, std: 0.1032361164689064)   \n","  param  19: encoder/en/h3/conv2d/b_conv2d:0 (256,)             float32_ref (mean: 0.004883896559476852, median: 0.003622682299464941, std: 0.04305277764797211)   \n","  param  20: encoder/en/h3/batch_norm/beta:0 (256,)             float32_ref (mean: -0.05402348190546036, median: -0.051802683621644974, std: 0.018132012337446213)   \n","  param  21: encoder/en/h3/batch_norm/gamma:0 (256,)             float32_ref (mean: 0.10053925216197968, median: 0.09931810200214386, std: 0.015341624617576599)   \n","  param  22: encoder/en/h3/batch_norm/moving_mean:0 (256,)             float32_ref (mean: -2.878495693206787, median: -2.948676109313965, std: 1.283917784690857 )   \n","  param  23: encoder/en/h3/batch_norm/moving_variance:0 (256,)             float32_ref (mean: 20.23468780517578 , median: 19.521095275878906, std: 5.446348667144775 )   \n","  param  24: encoder/en/out2/lin_sigmoid/W:0 (4096, 100)        float32_ref (mean: 1.474379359933664e-06, median: -5.631263775285333e-06, std: 0.01999804936349392)   \n","  param  25: encoder/en/out2/lin_sigmoid/b:0 (100,)             float32_ref (mean: 0.0               , median: 0.0               , std: 0.0               )   \n","  num of params: 1101764\n","  param   0: generator/g/h0/lin/W:0 (100, 4096)        float32_ref (mean: 0.00036751918378286064, median: 0.00022171005548443645, std: 0.09824373573064804)   \n","  param   1: generator/g/h0/lin/b:0 (4096,)            float32_ref (mean: -0.05244573950767517, median: -0.04165082797408104, std: 0.3517386019229889)   \n","  param   2: generator/g/h0/batch_norm/beta:0 (256,)             float32_ref (mean: -0.22158464789390564, median: -0.2278268039226532, std: 0.2311118096113205)   \n","  param   3: generator/g/h0/batch_norm/gamma:0 (256,)             float32_ref (mean: 0.972449541091919 , median: 0.9661184549331665, std: 0.07421469688415527)   \n","  param   4: generator/g/h0/batch_norm/moving_mean:0 (256,)             float32_ref (mean: -0.057125162333250046, median: -0.05574516952037811, std: 0.02434271201491356)   \n","  param   5: generator/g/h0/batch_norm/moving_variance:0 (256,)             float32_ref (mean: 1.2105255126953125, median: 1.2117488384246826, std: 0.04185958206653595)   \n","  param   6: generator/g/h1/conv2d/W_conv2d:0 (3, 3, 256, 128)    float32_ref (mean: -0.0004907294642180204, median: 0.0001272851077374071, std: 0.1045801043510437)   \n","  param   7: generator/g/h1/conv2d/b_conv2d:0 (128,)             float32_ref (mean: 0.007479162886738777, median: 0.01158651988953352, std: 0.06723364442586899)   \n","  param   8: generator/g/h1/batch_norm/beta:0 (128,)             float32_ref (mean: -0.3387836813926697, median: -0.3395257890224457, std: 0.19457180798053741)   \n","  param   9: generator/g/h1/batch_norm/gamma:0 (128,)             float32_ref (mean: 0.9584746360778809, median: 0.961886465549469 , std: 0.07178835570812225)   \n","  param  10: generator/g/h1/batch_norm/moving_mean:0 (128,)             float32_ref (mean: -1.157479166984558, median: -0.9440363645553589, std: 1.5693293809890747)   \n","  param  11: generator/g/h1/batch_norm/moving_variance:0 (128,)             float32_ref (mean: 20.541706085205078, median: 16.090694427490234, std: 14.385415077209473)   \n","  param  12: generator/g/h2/conv2d/W_conv2d:0 (3, 3, 128, 64)    float32_ref (mean: -0.002373478841036558, median: -0.001612481428310275, std: 0.09936290234327316)   \n","  param  13: generator/g/h2/conv2d/b_conv2d:0 (64,)              float32_ref (mean: -0.00881220307201147, median: -0.0019600538071244955, std: 0.09549348801374435)   \n","  param  14: generator/g/h2/batch_norm/beta:0 (64,)              float32_ref (mean: -0.2785818576812744, median: -0.3456268906593323, std: 0.27254799008369446)   \n","  param  15: generator/g/h2/batch_norm/gamma:0 (64,)              float32_ref (mean: 0.9619737863540649, median: 0.9614602327346802, std: 0.11803825199604034)   \n","  param  16: generator/g/h2/batch_norm/moving_mean:0 (64,)              float32_ref (mean: -0.620651364326477, median: -0.6099908947944641, std: 0.49049147963523865)   \n","  param  17: generator/g/h2/batch_norm/moving_variance:0 (64,)              float32_ref (mean: 8.983443260192871 , median: 7.428011894226074 , std: 7.138177871704102 )   \n","  param  18: generator/g/h3/conv2d/W_conv2d:0 (3, 3, 64, 32)     float32_ref (mean: -0.004544420167803764, median: -0.003121964866295457, std: 0.09455902874469757)   \n","  param  19: generator/g/h3/conv2d/b_conv2d:0 (32,)              float32_ref (mean: -0.01567418873310089, median: -0.006110067013651133, std: 0.10765371471643448)   \n","  param  20: generator/g/h3/batch_norm/beta:0 (32,)              float32_ref (mean: -0.10291865468025208, median: -0.0649600401520729, std: 0.1562625616788864)   \n","  param  21: generator/g/h3/batch_norm/gamma:0 (32,)              float32_ref (mean: 0.6303727626800537, median: 0.6587095260620117, std: 0.14324860274791718)   \n","  param  22: generator/g/h3/batch_norm/moving_mean:0 (32,)              float32_ref (mean: -0.5585200786590576, median: -0.5921272039413452, std: 0.7387147545814514)   \n","  param  23: generator/g/h3/batch_norm/moving_variance:0 (32,)              float32_ref (mean: 6.4488844871521   , median: 4.163817882537842 , std: 5.697667121887207 )   \n","  param  24: generator/g/h4/conv2d/W_conv2d:0 (3, 3, 32, 3)      float32_ref (mean: -0.002121042925864458, median: -0.0011363880475983024, std: 0.05075519159436226)   \n","  param  25: generator/g/h4/conv2d/b_conv2d:0 (3,)               float32_ref (mean: -0.0907197818160057, median: -0.09455583989620209, std: 0.08221643418073654)   \n","  num of params: 803779\n","  Loading (3, 3, 3, 64)\n","  Loading (64,)\n","  Loading (3, 3, 64, 64)\n","  Loading (64,)\n","  Loading (3, 3, 64, 128)\n","  Loading (128,)\n","  Loading (3, 3, 128, 128)\n","  Loading (128,)\n","  Loading (3, 3, 128, 256)\n","  Loading (256,)\n","  Loading (3, 3, 256, 256)\n","  Loading (256,)\n","  Loading (3, 3, 256, 256)\n","  Loading (256,)\n","  Loading (3, 3, 256, 512)\n","  Loading (512,)\n","  Loading (3, 3, 512, 512)\n","  Loading (512,)\n","  Loading (3, 3, 512, 512)\n","  Loading (512,)\n","  Loading (3, 3, 512, 512)\n","  Loading (512,)\n","  Loading (3, 3, 512, 512)\n","  Loading (512,)\n","  Loading (3, 3, 512, 512)\n","  Loading (512,)\n","  Loading (25088, 4096)\n","  Loading (4096,)\n","  Loading (4096, 4096)\n","  Loading (4096,)\n","  Loading (4096, 1000)\n","  Loading (1000,)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"S6mCPMlWzgx5","colab_type":"code","colab":{}},"source":["## Produce pictures of chosen parameter set\n","no_picture_squares = 2\n","minibatch = tl.iterate.minibatches(inputs=data_files, targets=data_files, batch_size=FLAGS['batch_size'].value, shuffle=True)\n","for pict_no in range(no_picture_squares):\n","  batch_files,_ = next(minibatch)\n","  batch = [\n","    get_image(batch_file, FLAGS['image_size'].value, is_crop=FLAGS['is_crop'].value, resize_w=FLAGS['output_size'].value, is_grayscale = 0)\n","    for batch_file in batch_files\n","  ]\n","  batch_images = np.array(batch).astype(np.float32)\n","\n","  img_recon, img_random = sess.run([gen2.outputs, gen3.outputs], feed_dict={input_imgs: batch_images})\n","  save_images(img_recon, [8, 8], '/content/drive/My Drive/VaeOnCelebA/parameter_samples/{}_recon.png'.format(pict_no))\n","  save_images(img_random, [8, 8], '/content/drive/My Drive/VaeOnCelebA/parameter_samples/{}_random.png'.format(pict_no))\n","  save_images(batch_images, [8, 8],'/content/drive/My Drive/VaeOnCelebA/parameter_samples/{}_original.png'.format(pict_no))\n","  sys.stdout.flush()\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1IhWYcrMzIeq","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"error","timestamp":1593190354230,"user_tz":-120,"elapsed":190317,"user":{"displayName":"carl ringqvist","photoUrl":"","userId":"02526215521042317496"}},"outputId":"e4b0434a-c341-46d8-ed7f-3115954c843a"},"source":["SAMPLE_STEP = 10\n","##========================= TRAIN MODELS ================================##\n","iter_counter = 0\n","\n","training_start_time = time.time()\n","# use all images in dataset in every epoch\n","for epoch in range(FLAGS['epoch'].value):\n","    minibatch = tl.iterate.minibatches(inputs=data_files, targets=data_files, batch_size=FLAGS['batch_size'].value, shuffle=True)\n","    idx = 0\n","    batch_idxs = min(len(data_files), FLAGS['train_size'].value) // FLAGS['batch_size'].value\n","\n","    while True:\n","        try:\n","            batch_files,_ = next(minibatch)\n","            batch = [\n","              get_image(batch_file, FLAGS['image_size'].value, is_crop=FLAGS['is_crop'].value, resize_w=FLAGS['output_size'].value, is_grayscale = 0)\n","              for batch_file in batch_files\n","            ]\n","            batch_images = np.array(batch).astype(np.float32)\n","            vae_current_lr = FLAGS['learning_rate'].value\n","\n","            # update\n","            p, p1, p2, p3, kl, sse, errE, _ = sess.run([p_loss,p1_loss,p2_loss,p3_loss,KL_loss,SSE_loss,VAE_loss,vae_optim], feed_dict={input_imgs: batch_images, lr_vae:vae_current_lr})\n","\n","            print(\n","                \"Epoch: [%2d/%2d] [%4d/%4d] time: %4.4f, vae_loss:%.8f, kl_loss:%.8f, sse_loss:%.8f, p1_loss:%.8f, p2_loss:%.8f, p3_loss:%.8f, p_loss:%.8f\" \\\n","                % (epoch, FLAGS['epoch'].value, idx, batch_idxs, time.time() - training_start_time, errE, kl, sse, p1, p2, p3, p))\n","            sys.stdout.flush()\n","\n","            # save samples\n","            if np.mod(iter_counter, SAMPLE_STEP) == 0:\n","                # generate and visualize generated images\n","                img1, img2 = sess.run([gen2.outputs, gen3.outputs], feed_dict={input_imgs: batch_images})\n","                save_images(img1, [8, 8], '/content/drive/My Drive/VaeOnCelebA/{}/{:02d}_{:04d}_recon.png'.format(samples_dir, epoch, iter_counter))\n","\n","                # img2 = sess.run(gen3.outputs, feed_dict={input_imgs: batch_images})\n","                save_images(img2, [8, 8], '/content/drive/My Drive/VaeOnCelebA/{}/{:02d}_{:04d}_random.png'.format(samples_dir, epoch, iter_counter))\n","\n","                # save input image for comparison\n","                save_images(batch_images,[8, 8],'/content/drive/My Drive/VaeOnCelebA/{}/{:02d}_{:04d}_input_recon.png'.format(samples_dir, epoch, iter_counter))\n","                print(\"[Sample] sample generated!!!\")\n","                sys.stdout.flush()\n","            # save checkpoint\n","            if np.mod(iter_counter, SAMPLE_STEP) == 0:\n","                # save current network parameters\n","                print(\"[*] Saving checkpoints...\")\n","                net_e_name = os.path.join('/content/drive/My Drive/VaeOnCelebA/{}'.format(parameters_dir), 'net_e.npz')\n","                net_g_name = os.path.join('/content/drive/My Drive/VaeOnCelebA/{}'.format(parameters_dir), 'net_g.npz')\n","                # this version is for future re-check and visualization analysis\n","                net_e_iter_name = os.path.join('/content/drive/My Drive/VaeOnCelebA/{}'.format(parameters_dir), 'net_e_%d.npz' % iter_counter)\n","                net_g_iter_name = os.path.join('/content/drive/My Drive/VaeOnCelebA/{}'.format(parameters_dir), 'net_g_%d.npz' % iter_counter)\n","                # params of two branches\n","                net_out_params = net_out1.all_params + net_out2.all_params\n","                # remove repeat params\n","                net_out_params = tl.layers.list_remove_repeat(net_out_params)\n","                tl.files.save_npz(net_out_params, name=net_e_name, sess=sess)\n","                tl.files.save_npz(gen0.all_params, name=net_g_name, sess=sess)\n","                tl.files.save_npz(net_out_params, name=net_e_iter_name, sess=sess)\n","                tl.files.save_npz(gen0.all_params, name=net_g_iter_name, sess=sess)\n","\n","                print(\"[*] Saving checkpoints SUCCESS!\")\n","            iter_counter += 1\n","            idx += 1\n","            # print idx\n","        except StopIteration:\n","            print('one epoch finished')\n","            break\n","\n","        \n","\n","\n","training_end_time = time.time()\n","print(\"The processing time of program is : {:.2f}mins\".format((training_end_time-training_start_time)/60.0))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch: [ 0/50] [   0/3165] time: 14.3660, vae_loss:1059.68969727, kl_loss:0.28231126, sse_loss:5543.59814453, p1_loss:622495.62500000, p2_loss:8265309.50000000, p3_loss:26425776.00000000, p_loss:35313580.00000000\n","[Sample] sample generated!!!\n","[*] Saving checkpoints...\n","[*] /content/drive/My Drive/VaeOnCelebA/parameters_dfc/dfc_vae3/net_e.npz saved\n","[*] /content/drive/My Drive/VaeOnCelebA/parameters_dfc/dfc_vae3/net_g.npz saved\n","[*] /content/drive/My Drive/VaeOnCelebA/parameters_dfc/dfc_vae3/net_e_0.npz saved\n","[*] /content/drive/My Drive/VaeOnCelebA/parameters_dfc/dfc_vae3/net_g_0.npz saved\n","[*] Saving checkpoints SUCCESS!\n","Epoch: [ 0/50] [   1/3165] time: 18.3353, vae_loss:1051.64465332, kl_loss:0.30185664, sse_loss:5269.85253906, p1_loss:594916.25000000, p2_loss:8163571.50000000, p3_loss:26286274.00000000, p_loss:35044760.00000000\n","Epoch: [ 0/50] [   2/3165] time: 20.8711, vae_loss:1019.64971924, kl_loss:0.36232477, sse_loss:5291.20507812, p1_loss:582199.25000000, p2_loss:7876669.00000000, p3_loss:25517382.00000000, p_loss:33976248.00000000\n","Epoch: [ 0/50] [   3/3165] time: 23.4159, vae_loss:977.21984863, kl_loss:0.48792085, sse_loss:4428.05273438, p1_loss:515331.53125000, p2_loss:7494633.00000000, p3_loss:24547768.00000000, p_loss:32557732.00000000\n","Epoch: [ 0/50] [   4/3165] time: 25.9042, vae_loss:915.37341309, kl_loss:0.60560048, sse_loss:4050.11401367, p1_loss:479746.62500000, p2_loss:6981227.00000000, p3_loss:23031288.00000000, p_loss:30492262.00000000\n","Epoch: [ 0/50] [   5/3165] time: 28.4273, vae_loss:903.52551270, kl_loss:0.76663947, sse_loss:4033.96069336, p1_loss:497302.68750000, p2_loss:6864896.00000000, p3_loss:22729764.00000000, p_loss:30091962.00000000\n","Epoch: [ 0/50] [   6/3165] time: 30.9532, vae_loss:896.85815430, kl_loss:0.92177898, sse_loss:3891.84570312, p1_loss:454782.18750000, p2_loss:6754439.00000000, p3_loss:22655326.00000000, p_loss:29864548.00000000\n","Epoch: [ 0/50] [   7/3165] time: 33.4938, vae_loss:876.11431885, kl_loss:1.20455706, sse_loss:3712.11645508, p1_loss:432850.18750000, p2_loss:6579329.50000000, p3_loss:22151480.00000000, p_loss:29163660.00000000\n","Epoch: [ 0/50] [   8/3165] time: 36.0099, vae_loss:877.06500244, kl_loss:1.34021771, sse_loss:3578.87475586, p1_loss:452138.81250000, p2_loss:6612512.00000000, p3_loss:22126178.00000000, p_loss:29190828.00000000\n","Epoch: [ 0/50] [   9/3165] time: 38.5620, vae_loss:880.49896240, kl_loss:1.71094108, sse_loss:3568.63671875, p1_loss:430361.34375000, p2_loss:6585113.00000000, p3_loss:22277460.00000000, p_loss:29292934.00000000\n","Epoch: [ 0/50] [  10/3165] time: 41.0966, vae_loss:863.41314697, kl_loss:1.85082328, sse_loss:3935.83935547, p1_loss:483719.18750000, p2_loss:6533378.00000000, p3_loss:21701648.00000000, p_loss:28718744.00000000\n","[Sample] sample generated!!!\n","[*] Saving checkpoints...\n","[*] /content/drive/My Drive/VaeOnCelebA/parameters_dfc/dfc_vae3/net_e.npz saved\n","[*] /content/drive/My Drive/VaeOnCelebA/parameters_dfc/dfc_vae3/net_g.npz saved\n","[*] /content/drive/My Drive/VaeOnCelebA/parameters_dfc/dfc_vae3/net_e_10.npz saved\n","[*] /content/drive/My Drive/VaeOnCelebA/parameters_dfc/dfc_vae3/net_g_10.npz saved\n","[*] Saving checkpoints SUCCESS!\n","Epoch: [ 0/50] [  11/3165] time: 44.2326, vae_loss:837.37518311, kl_loss:2.29828167, sse_loss:3255.67724609, p1_loss:393813.37500000, p2_loss:6254605.00000000, p3_loss:21187480.00000000, p_loss:27835898.00000000\n","Epoch: [ 0/50] [  12/3165] time: 46.7835, vae_loss:803.49975586, kl_loss:2.64719391, sse_loss:3375.56591797, p1_loss:395163.56250000, p2_loss:6002186.00000000, p3_loss:20297736.00000000, p_loss:26695086.00000000\n","Epoch: [ 0/50] [  13/3165] time: 49.3011, vae_loss:820.11743164, kl_loss:2.85739994, sse_loss:3851.63232422, p1_loss:442720.56250000, p2_loss:6165469.00000000, p3_loss:20633810.00000000, p_loss:27242000.00000000\n","Epoch: [ 0/50] [  14/3165] time: 51.8605, vae_loss:840.28839111, kl_loss:3.03757739, sse_loss:3149.44848633, p1_loss:393954.25000000, p2_loss:6263542.50000000, p3_loss:21250862.00000000, p_loss:27908360.00000000\n","Epoch: [ 0/50] [  15/3165] time: 54.4068, vae_loss:797.51940918, kl_loss:3.70515871, sse_loss:2972.45483398, p1_loss:358967.12500000, p2_loss:5891209.50000000, p3_loss:20210300.00000000, p_loss:26460476.00000000\n","Epoch: [ 0/50] [  16/3165] time: 56.9734, vae_loss:825.38256836, kl_loss:3.73337555, sse_loss:3223.40820312, p1_loss:401971.46875000, p2_loss:6125282.00000000, p3_loss:20861052.00000000, p_loss:27388306.00000000\n","Epoch: [ 0/50] [  17/3165] time: 59.4836, vae_loss:829.87207031, kl_loss:3.75916529, sse_loss:3530.87988281, p1_loss:404715.96875000, p2_loss:6164580.00000000, p3_loss:20967802.00000000, p_loss:27537098.00000000\n","Epoch: [ 0/50] [  18/3165] time: 62.0248, vae_loss:822.14251709, kl_loss:4.43750143, sse_loss:2933.85766602, p1_loss:361712.18750000, p2_loss:6064828.00000000, p3_loss:20830294.00000000, p_loss:27256834.00000000\n","Epoch: [ 0/50] [  19/3165] time: 64.5515, vae_loss:826.69964600, kl_loss:4.82832241, sse_loss:3265.54174805, p1_loss:383795.18750000, p2_loss:6111209.00000000, p3_loss:20900708.00000000, p_loss:27395712.00000000\n","Epoch: [ 0/50] [  20/3165] time: 67.1160, vae_loss:804.82336426, kl_loss:4.78634644, sse_loss:3056.21093750, p1_loss:367109.43750000, p2_loss:5929206.00000000, p3_loss:20371586.00000000, p_loss:26667902.00000000\n","[Sample] sample generated!!!\n","[*] Saving checkpoints...\n","[*] /content/drive/My Drive/VaeOnCelebA/parameters_dfc/dfc_vae3/net_e.npz saved\n","[*] /content/drive/My Drive/VaeOnCelebA/parameters_dfc/dfc_vae3/net_g.npz saved\n","[*] /content/drive/My Drive/VaeOnCelebA/parameters_dfc/dfc_vae3/net_e_20.npz saved\n","[*] /content/drive/My Drive/VaeOnCelebA/parameters_dfc/dfc_vae3/net_g_20.npz saved\n","[*] Saving checkpoints SUCCESS!\n","Epoch: [ 0/50] [  21/3165] time: 70.2373, vae_loss:801.65252686, kl_loss:4.86887074, sse_loss:2994.29833984, p1_loss:359918.68750000, p2_loss:5912487.00000000, p3_loss:20287050.00000000, p_loss:26559456.00000000\n","Epoch: [ 0/50] [  22/3165] time: 72.7776, vae_loss:802.22406006, kl_loss:5.25497150, sse_loss:2934.47607422, p1_loss:363444.37500000, p2_loss:5985389.00000000, p3_loss:20216804.00000000, p_loss:26565638.00000000\n","Epoch: [ 0/50] [  23/3165] time: 75.3129, vae_loss:820.23718262, kl_loss:5.61399269, sse_loss:2594.08569336, p1_loss:325692.43750000, p2_loss:6029165.50000000, p3_loss:20799248.00000000, p_loss:27154106.00000000\n","Epoch: [ 0/50] [  24/3165] time: 77.8387, vae_loss:803.89794922, kl_loss:5.39122248, sse_loss:2981.51293945, p1_loss:380899.25000000, p2_loss:6050472.00000000, p3_loss:20185522.00000000, p_loss:26616892.00000000\n","Epoch: [ 0/50] [  25/3165] time: 80.3918, vae_loss:788.45501709, kl_loss:6.58804655, sse_loss:2626.23242188, p1_loss:327240.21875000, p2_loss:5807268.00000000, p3_loss:19927724.00000000, p_loss:26062232.00000000\n","Epoch: [ 0/50] [  26/3165] time: 82.9467, vae_loss:751.70788574, kl_loss:7.00584698, sse_loss:2514.79467773, p1_loss:308669.12500000, p2_loss:5516472.50000000, p3_loss:18998260.00000000, p_loss:24823402.00000000\n","Epoch: [ 0/50] [  27/3165] time: 85.4579, vae_loss:786.27874756, kl_loss:6.57136726, sse_loss:2704.06054688, p1_loss:336185.06250000, p2_loss:5774550.00000000, p3_loss:19879512.00000000, p_loss:25990248.00000000\n","Epoch: [ 0/50] [  28/3165] time: 87.9944, vae_loss:800.37969971, kl_loss:6.88070631, sse_loss:2603.57128906, p1_loss:333036.18750000, p2_loss:5887496.00000000, p3_loss:20229436.00000000, p_loss:26449968.00000000\n","Epoch: [ 0/50] [  29/3165] time: 90.5225, vae_loss:765.81176758, kl_loss:7.04088783, sse_loss:2563.12353516, p1_loss:322638.56250000, p2_loss:5640270.50000000, p3_loss:19329454.00000000, p_loss:25292364.00000000\n","Epoch: [ 0/50] [  30/3165] time: 93.0659, vae_loss:764.11566162, kl_loss:7.67144537, sse_loss:2309.42968750, p1_loss:300379.84375000, p2_loss:5618377.00000000, p3_loss:19296052.00000000, p_loss:25214808.00000000\n","[Sample] sample generated!!!\n","[*] Saving checkpoints...\n","[*] /content/drive/My Drive/VaeOnCelebA/parameters_dfc/dfc_vae3/net_e.npz saved\n","[*] /content/drive/My Drive/VaeOnCelebA/parameters_dfc/dfc_vae3/net_g.npz saved\n","[*] /content/drive/My Drive/VaeOnCelebA/parameters_dfc/dfc_vae3/net_e_30.npz saved\n","[*] /content/drive/My Drive/VaeOnCelebA/parameters_dfc/dfc_vae3/net_g_30.npz saved\n","[*] Saving checkpoints SUCCESS!\n","Epoch: [ 0/50] [  31/3165] time: 96.2379, vae_loss:800.09954834, kl_loss:7.63533688, sse_loss:2695.36962891, p1_loss:338320.59375000, p2_loss:5921440.00000000, p3_loss:20155716.00000000, p_loss:26415476.00000000\n","Epoch: [ 0/50] [  32/3165] time: 98.7632, vae_loss:758.07672119, kl_loss:8.24244404, sse_loss:2250.54150391, p1_loss:281752.75000000, p2_loss:5515084.00000000, p3_loss:19197640.00000000, p_loss:24994476.00000000\n","Epoch: [ 0/50] [  33/3165] time: 101.3019, vae_loss:767.36206055, kl_loss:8.31732655, sse_loss:2318.97338867, p1_loss:299848.00000000, p2_loss:5651109.00000000, p3_loss:19350534.00000000, p_loss:25301492.00000000\n","Epoch: [ 0/50] [  34/3165] time: 103.8284, vae_loss:772.54711914, kl_loss:8.05392838, sse_loss:2409.42675781, p1_loss:310373.93750000, p2_loss:5692974.00000000, p3_loss:19479758.00000000, p_loss:25483106.00000000\n","Epoch: [ 0/50] [  35/3165] time: 106.3772, vae_loss:730.60681152, kl_loss:9.33110619, sse_loss:2044.10229492, p1_loss:267286.62500000, p2_loss:5316066.50000000, p3_loss:18459170.00000000, p_loss:24042524.00000000\n","Epoch: [ 0/50] [  36/3165] time: 108.8942, vae_loss:779.17468262, kl_loss:9.09379196, sse_loss:2332.34521484, p1_loss:323096.87500000, p2_loss:5731384.00000000, p3_loss:19614882.00000000, p_loss:25669364.00000000\n","Epoch: [ 0/50] [  37/3165] time: 111.4336, vae_loss:705.06134033, kl_loss:10.12144852, sse_loss:1945.80102539, p1_loss:249125.07812500, p2_loss:5076670.50000000, p3_loss:17838868.00000000, p_loss:23164664.00000000\n","Epoch: [ 0/50] [  38/3165] time: 113.9616, vae_loss:745.64227295, kl_loss:9.61218262, sse_loss:2226.32250977, p1_loss:281855.68750000, p2_loss:5478449.00000000, p3_loss:18774032.00000000, p_loss:24534336.00000000\n","Epoch: [ 0/50] [  39/3165] time: 116.5226, vae_loss:745.14904785, kl_loss:10.41388035, sse_loss:2189.27587891, p1_loss:294476.25000000, p2_loss:5436135.00000000, p3_loss:18760560.00000000, p_loss:24491172.00000000\n","Epoch: [ 0/50] [  40/3165] time: 119.0400, vae_loss:732.64501953, kl_loss:10.85863304, sse_loss:1972.07373047, p1_loss:254550.35937500, p2_loss:5339306.00000000, p3_loss:18465690.00000000, p_loss:24059546.00000000\n","[Sample] sample generated!!!\n","[*] Saving checkpoints...\n","[*] /content/drive/My Drive/VaeOnCelebA/parameters_dfc/dfc_vae3/net_e.npz saved\n","[*] /content/drive/My Drive/VaeOnCelebA/parameters_dfc/dfc_vae3/net_g.npz saved\n","[*] /content/drive/My Drive/VaeOnCelebA/parameters_dfc/dfc_vae3/net_e_40.npz saved\n","[*] /content/drive/My Drive/VaeOnCelebA/parameters_dfc/dfc_vae3/net_g_40.npz saved\n","[*] Saving checkpoints SUCCESS!\n","Epoch: [ 0/50] [  41/3165] time: 122.1847, vae_loss:720.13104248, kl_loss:10.98659325, sse_loss:1970.38977051, p1_loss:258490.64062500, p2_loss:5256116.00000000, p3_loss:18123544.00000000, p_loss:23638150.00000000\n","Epoch: [ 0/50] [  42/3165] time: 124.6993, vae_loss:737.03857422, kl_loss:11.62149239, sse_loss:1822.29797363, p1_loss:241766.21875000, p2_loss:5352182.00000000, p3_loss:18586622.00000000, p_loss:24180570.00000000\n","Epoch: [ 0/50] [  43/3165] time: 127.2115, vae_loss:755.79364014, kl_loss:11.80430603, sse_loss:2017.82568359, p1_loss:285428.06250000, p2_loss:5555188.00000000, p3_loss:18959028.00000000, p_loss:24799644.00000000\n","Epoch: [ 0/50] [  44/3165] time: 129.7113, vae_loss:732.69244385, kl_loss:12.16961288, sse_loss:1915.83898926, p1_loss:256911.48437500, p2_loss:5349816.00000000, p3_loss:18410700.00000000, p_loss:24017428.00000000\n","Epoch: [ 0/50] [  45/3165] time: 132.2769, vae_loss:729.51715088, kl_loss:13.19680977, sse_loss:1788.55102539, p1_loss:227031.43750000, p2_loss:5290724.50000000, p3_loss:18359588.00000000, p_loss:23877344.00000000\n","Epoch: [ 0/50] [  46/3165] time: 134.7983, vae_loss:715.06048584, kl_loss:13.39122486, sse_loss:1682.32055664, p1_loss:240167.78125000, p2_loss:5182903.00000000, p3_loss:17965904.00000000, p_loss:23388976.00000000\n","Epoch: [ 0/50] [  47/3165] time: 137.3410, vae_loss:746.61437988, kl_loss:13.51478386, sse_loss:1846.72412109, p1_loss:246600.29687500, p2_loss:5436923.50000000, p3_loss:18753130.00000000, p_loss:24436654.00000000\n","Epoch: [ 0/50] [  48/3165] time: 139.8819, vae_loss:707.16864014, kl_loss:13.39585304, sse_loss:1824.20581055, p1_loss:245005.06250000, p2_loss:5150477.50000000, p3_loss:17730278.00000000, p_loss:23125760.00000000\n","Epoch: [ 0/50] [  49/3165] time: 142.4145, vae_loss:702.00213623, kl_loss:14.42379284, sse_loss:1592.22851562, p1_loss:242340.26562500, p2_loss:5126914.50000000, p3_loss:17550024.00000000, p_loss:22919280.00000000\n","Epoch: [ 0/50] [  50/3165] time: 144.9388, vae_loss:681.99169922, kl_loss:15.60795593, sse_loss:1470.04907227, p1_loss:214149.32812500, p2_loss:4927661.00000000, p3_loss:17070982.00000000, p_loss:22212792.00000000\n","[Sample] sample generated!!!\n","[*] Saving checkpoints...\n","[*] /content/drive/My Drive/VaeOnCelebA/parameters_dfc/dfc_vae3/net_e.npz saved\n","[*] /content/drive/My Drive/VaeOnCelebA/parameters_dfc/dfc_vae3/net_g.npz saved\n","[*] /content/drive/My Drive/VaeOnCelebA/parameters_dfc/dfc_vae3/net_e_50.npz saved\n","[*] /content/drive/My Drive/VaeOnCelebA/parameters_dfc/dfc_vae3/net_g_50.npz saved\n","[*] Saving checkpoints SUCCESS!\n","Epoch: [ 0/50] [  51/3165] time: 148.0651, vae_loss:693.09387207, kl_loss:16.20891953, sse_loss:1579.36730957, p1_loss:222287.34375000, p2_loss:5029677.00000000, p3_loss:17310868.00000000, p_loss:22562832.00000000\n","Epoch: [ 0/50] [  52/3165] time: 150.5948, vae_loss:703.72918701, kl_loss:16.45812607, sse_loss:1505.54467773, p1_loss:221011.31250000, p2_loss:5101885.50000000, p3_loss:17586140.00000000, p_loss:22909036.00000000\n","Epoch: [ 0/50] [  53/3165] time: 153.1331, vae_loss:696.85760498, kl_loss:16.45878983, sse_loss:1506.52416992, p1_loss:213989.10937500, p2_loss:5025524.00000000, p3_loss:17440448.00000000, p_loss:22679960.00000000\n","Epoch: [ 0/50] [  54/3165] time: 155.6952, vae_loss:706.32482910, kl_loss:16.36970139, sse_loss:1668.32556152, p1_loss:233044.40625000, p2_loss:5096541.00000000, p3_loss:17668920.00000000, p_loss:22998506.00000000\n","Epoch: [ 0/50] [  55/3165] time: 158.2177, vae_loss:714.24145508, kl_loss:17.86341858, sse_loss:1492.22741699, p1_loss:219029.59375000, p2_loss:5184465.00000000, p3_loss:17809108.00000000, p_loss:23212602.00000000\n","Epoch: [ 0/50] [  56/3165] time: 160.7767, vae_loss:702.04565430, kl_loss:18.02996445, sse_loss:1476.38830566, p1_loss:203265.18750000, p2_loss:5076540.00000000, p3_loss:17520720.00000000, p_loss:22800524.00000000\n","Epoch: [ 0/50] [  57/3165] time: 163.2960, vae_loss:674.94415283, kl_loss:18.98637199, sse_loss:1422.90283203, p1_loss:212169.15625000, p2_loss:4856640.00000000, p3_loss:16796452.00000000, p_loss:21865260.00000000\n","Epoch: [ 0/50] [  58/3165] time: 165.8530, vae_loss:666.94921875, kl_loss:19.29846954, sse_loss:1382.68078613, p1_loss:217336.65625000, p2_loss:4795703.00000000, p3_loss:16575321.00000000, p_loss:21588360.00000000\n","Epoch: [ 0/50] [  59/3165] time: 168.4235, vae_loss:668.01965332, kl_loss:19.98229218, sse_loss:1415.11364746, p1_loss:194808.42187500, p2_loss:4796657.00000000, p3_loss:16609781.00000000, p_loss:21601246.00000000\n","Epoch: [ 0/50] [  60/3165] time: 170.9588, vae_loss:633.80517578, kl_loss:21.14325333, sse_loss:1239.22155762, p1_loss:184465.25000000, p2_loss:4554597.00000000, p3_loss:15683001.00000000, p_loss:20422064.00000000\n","[Sample] sample generated!!!\n","[*] Saving checkpoints...\n","[*] /content/drive/My Drive/VaeOnCelebA/parameters_dfc/dfc_vae3/net_e.npz saved\n","[*] /content/drive/My Drive/VaeOnCelebA/parameters_dfc/dfc_vae3/net_g.npz saved\n","[*] /content/drive/My Drive/VaeOnCelebA/parameters_dfc/dfc_vae3/net_e_60.npz saved\n","[*] /content/drive/My Drive/VaeOnCelebA/parameters_dfc/dfc_vae3/net_g_60.npz saved\n","[*] Saving checkpoints SUCCESS!\n","Epoch: [ 0/50] [  61/3165] time: 174.0703, vae_loss:682.43786621, kl_loss:19.73501968, sse_loss:1486.74462891, p1_loss:220471.00000000, p2_loss:4964531.00000000, p3_loss:16905092.00000000, p_loss:22090094.00000000\n","Epoch: [ 0/50] [  62/3165] time: 176.5905, vae_loss:688.02508545, kl_loss:20.87958908, sse_loss:1394.53808594, p1_loss:207336.12500000, p2_loss:4903101.00000000, p3_loss:17127748.00000000, p_loss:22238184.00000000\n","Epoch: [ 0/50] [  63/3165] time: 179.1749, vae_loss:685.95587158, kl_loss:21.95018768, sse_loss:1375.81323242, p1_loss:211741.40625000, p2_loss:4927513.00000000, p3_loss:16994270.00000000, p_loss:22133524.00000000\n","Epoch: [ 0/50] [  64/3165] time: 181.7767, vae_loss:693.68200684, kl_loss:23.04346085, sse_loss:1401.30468750, p1_loss:210628.09375000, p2_loss:4978809.50000000, p3_loss:17165180.00000000, p_loss:22354618.00000000\n","Epoch: [ 0/50] [  65/3165] time: 184.3316, vae_loss:668.81738281, kl_loss:22.88062477, sse_loss:1409.99047852, p1_loss:200322.15625000, p2_loss:4779617.50000000, p3_loss:16551287.00000000, p_loss:21531226.00000000\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-11-1ed3daecadac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0;31m# update\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m             \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mp_loss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mp1_loss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mp2_loss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mp3_loss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mKL_loss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mSSE_loss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mVAE_loss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvae_optim\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0minput_imgs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr_vae\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mvae_current_lr\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             print(\n","\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    954\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    955\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 956\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    957\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    958\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1180\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1181\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1357\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1359\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1360\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1363\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1364\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1365\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1366\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1367\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1348\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[0;32m-> 1350\u001b[0;31m                                       target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1441\u001b[0m     return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,\n\u001b[1;32m   1442\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1443\u001b[0;31m                                             run_metadata)\n\u001b[0m\u001b[1;32m   1444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1445\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"SVurtjylIYLo","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1592906165103,"user_tz":-120,"elapsed":22256,"user":{"displayName":"carl ringqvist","photoUrl":"","userId":"02526215521042317496"}},"outputId":"8252b369-d4a6-4cec-8997-8a5dbb1fd760"},"source":["##========================= TRAIN ADAMS NN ================================##\n","from tensorflow.keras.datasets import mnist\n","from tensorflow.keras.layers import Dense, Conv2D, MaxPool2D, Input, Conv2DTranspose, Flatten, Reshape\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.constraints import Constraint\n","import numpy as np\n","\n","def loss_f(y,x):\n","    return tf.math.reduce_mean(tf.math.multiply(y,x))\n","    \n","def get_test_function(latent_dim, c, sigmoid = True):\n","    inp_layer = Input(shape=(latent_dim,))\n","    lay_1 = Dense(200, activation = 'tanh', kernel_constraint=Between(-c,c),bias_constraint=Between(-c,c))(inp_layer)\n","    lay_2 = Dense(20, activation = 'relu', kernel_constraint=Between(-c,c),bias_constraint=Between(-c,c))(lay_1)\n","    if sigmoid:\n","        out = Dense(1,activation='sigmoid',kernel_constraint=Between(-c,c),bias_constraint=Between(-c,c))(lay_2)\n","    else:\n","        out = Dense(1,kernel_constraint=Between(-c,c),bias_constraint=Between(-c,c))(lay_2)\n","    test_function = Model(inp_layer, out)\n","    test_function.compile(optimizer='adam', loss=loss_f)\n","    return test_function\n","\n","def get_test_function1(latent_dim, c, sigmoid = True):\n","    inp_layer = Input(shape=(latent_dim,))\n","    lay_1 = Dense(2000, activation = 'relu', kernel_constraint=Between(-c,c),bias_constraint=Between(-c,c))(inp_layer)\n","    lay_2 = Dense(1000, activation = 'relu', kernel_constraint=Between(-c,c),bias_constraint=Between(-c,c))(lay_1)\n","    lay_3 = Dense(500, activation = 'relu', kernel_constraint=Between(-c,c),bias_constraint=Between(-c,c))(lay_2)\n","    lay_4 = Dense(250, activation = 'relu', kernel_constraint=Between(-c,c),bias_constraint=Between(-c,c))(lay_3)\n","    lay_5 = Dense(125, activation = 'relu', kernel_constraint=Between(-c,c),bias_constraint=Between(-c,c))(lay_4)\n","    lay_6 = Dense(60, activation = 'relu', kernel_constraint=Between(-c,c),bias_constraint=Between(-c,c))(lay_5)\n","    lay_7 = Dense(20, activation = 'relu', kernel_constraint=Between(-c,c),bias_constraint=Between(-c,c))(lay_6)\n","    if sigmoid:\n","        out = Dense(1,activation='sigmoid',kernel_constraint=Between(-c,c),bias_constraint=Between(-c,c))(lay_6)\n","    else:\n","        out = Dense(1,kernel_constraint=Between(-c,c),bias_constraint=Between(-c,c))(lay_6)\n","    test_function = Model(inp_layer, out)\n","    test_function.compile(optimizer='adam', loss=loss_f)\n","    return test_function\n","\n","def get_test_function2(latent_dim, c, sigmoid = True):\n","    inp_layer = Input(shape=(latent_dim,))\n","    lay_1 = Dense(2500, activation = 'tanh')(inp_layer)\n","    lay_2 = Dense(2000, activation = 'relu')(lay_1)\n","    lay_3 = Dense(1500, activation = 'relu')(lay_2)\n","    lay_4 = Dense(1000, activation = 'relu')(lay_3)\n","    lay_5 = Dense(100, activation = 'relu')(lay_4)\n","    lay_6 = Dense(10, activation = 'relu')(lay_5)\n","    if sigmoid:\n","        out = Dense(1,activation='sigmoid')(lay_6)\n","    else:\n","        out = Dense(1)(lay_2)\n","    test_function = Model(inp_layer, out)\n","    test_function.compile(optimizer='adam', loss=loss_f)\n","    return test_function\n","\n","def get_latent_datapoints(data_links, batch_size):\n","    minibatch = tl.iterate.minibatches(inputs=data_links, targets=data_links, batch_size=batch_size, shuffle=False)\n","    batch_files,_ = next(minibatch)\n","    batch = [\n","      get_image(\n","            batch_file,\n","            FLAGS['image_size'].value,\n","            is_crop=FLAGS['is_crop'].value,\n","            resize_w=FLAGS['output_size'].value,\n","            is_grayscale = 0\n","      )\n","      for batch_file in batch_files\n","    ]\n","    batch_images = np.array(batch).astype(np.float32)\n","    lz_samples = sess.run(z, feed_dict={input_imgs: batch_images})\n","    idx = 0\n","    while True:\n","      try:\n","        batch_files,_ = next(minibatch)\n","        batch = [get_image(batch_file, FLAGS['image_size'].value, is_crop=FLAGS['is_crop'].value, resize_w=FLAGS['output_size'].value, is_grayscale = 0) for batch_file in batch_files]\n","        batch_images = np.array(batch).astype(np.float32)\n","        lz_samples = np.concatenate(\n","              (\n","                  lz_samples,\n","                  sess.run(z, feed_dict={input_imgs: batch_images})\n","              )\n","        )\n","        idx +=1 \n","        if idx % 150 == 0:\n","          save_data_name = batch_files[-1][-10:]\n","          np.savetxt('/content/drive/My Drive/VaeOnCelebA/dfc_latent_data/' + save_data_name + \".csv\", lz_samples, delimiter=\",\")\n","          print(idx)\n","      except StopIteration:\n","          print('one epoch finished')\n","          break\n","    return lz_samples\n","\n","class Between(Constraint):\n","    def __init__(self, min_value, max_value):\n","        self.min_value = min_value\n","        self.max_value = max_value\n","\n","    def __call__(self, w):\n","        return tf.keras.backend.clip(w, self.min_value, self.max_value)\n","\n","    def get_config(self):\n","        return {'min_value': self.min_value,\n","                'max_value': self.max_value}\n","\n","def train(epochs, latent_dim, test_function, batch_size, all_latent_data):\n","  iter = 0\n","  for epoch in range(epochs):\n","    minibatch = tl.iterate.minibatches(\n","        inputs=all_latent_data,\n","        targets=all_latent_data,\n","        batch_size=batch_size,\n","        shuffle=True\n","    )\n","    while True:\n","      try:\n","        lz_sample, _ = next(minibatch)\n","        z_sample = np.random.normal(size=(batch_size, latent_dim))\n","        y_list = np.zeros((2*batch_size,))\n","        y_list[0:batch_size] = -np.ones((batch_size,))\n","        y_list[batch_size:] = np.ones((batch_size,))\n","        l3 = test_function.train_on_batch(x = np.concatenate((z_sample, lz_sample)), y = y_list)\n","        iter += 1\n","        if iter % 500 == 0:\n","          test_function.save('/content/drive/My Drive/VaeOnCelebA/testfunction1')\n","          print(\"epoch: {}, loss: {}\".format(epoch, -l3))\n","      except StopIteration:\n","          break\n","\n","\"\"\" Create new testfunction \"\"\"\n","# test_function = get_test_function(100, 1, True)\n","# test_function1 = get_test_function1(100, 1, True)\n","\"\"\" Load old testfunction \"\"\"\n","test_function = tf.keras.models.load_model('/content/drive/My Drive/VaeOnCelebA/testfunction1', custom_objects={'Between': Between, 'loss_f': loss_f})\n","\"\"\" Create new latent data \"\"\"\n","# all_latent_data = get_latent_datapoints(data_files, FLAGS['batch_size'].value)\n","\"\"\" Load previously created latent data \"\"\"\n","# all_latent_data = np.loadtxt('/content/drive/My Drive/VaeOnCelebA/dfc_latent_data/201664.jpg.csv', delimiter=\",\")\n","\n","\"\"\" Train test function on data \"\"\"\n","# train(epochs = 10000, latent_dim=100, test_function = test_function1, batch_size = 50000, all_latent_data=all_latent_data)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["' Train test function on data '"]},"metadata":{"tags":[]},"execution_count":35}]},{"cell_type":"code","metadata":{"id":"hvKvc43VIa9e","colab_type":"code","colab":{}},"source":["def sample_f(f, a, samples):\n","  z_sample = sess.run(z_p, feed_dict={})\n","  alphas = test_function(z_p).eval()\n","  good_samples = z_sample[alphas.T[0] > a]\n","  while len(good_samples) < samples:\n","      z_sample = sess.run(z_p, feed_dict={})\n","      alphas = test_function(z_p).eval()\n","      good_samples = np.concatenate((good_samples, z_sample[alphas.T[0] > a]))\n","  return good_samples[:samples]\n","\n","good_samples = sample_f(test_function, 0.95, FLAGS['batch_size'].value)\n","normal_samples = sess.run(z_p, feed_dict={})\n","\n","good_images = sess.run(gen4.outputs, feed_dict={z_custom: good_samples})\n","normal_images = sess.run(gen4.outputs, feed_dict={z_custom: normal_samples})\n","save_images(good_images[:64], [8, 8], '/content/drive/My Drive/VaeOnCelebA/good_images.png')\n","save_images(normal_images[:64], [8, 8], '/content/drive/My Drive/VaeOnCelebA/normal_images.png')\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CRqPevSvHgTi","colab_type":"code","colab":{}},"source":["z_sample = sess.run(z_p, feed_dict={})\n","alphas = test_function(z_p).eval()\n","good_samples = z_sample[alphas.T[0] > 0.95]\n","print(np.sum(alphas.T[0] > 0.95))\n","print(alphas.T[0] > 0.95)\n","print(len(good_samples))\n"],"execution_count":null,"outputs":[]}]}